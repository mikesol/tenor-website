<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>TENOR - International Conference on Technologies for Music Notation and Representation</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>

    <!-- Plugin CSS -->
    <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/creative.min.css" rel="stylesheet">
    <link href="css/tenor.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <!--i class="fa fa-bars"></i-->
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="index.html">TENOR</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="#2017">2017</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2016">2016</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2015">2015</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header>
        <div class="header-content">
            <div class="header-content-inner">
                <a href="index.html"><img src="img/TENORg.png" width=250></a>
                <hr>
                <h1 id="homeHeading">Proceedings</h1>
            </div>
        </div>
    </header>

    <!--section id="2018">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2018</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>
    </section-->

   <section class="proc-altern" id="2017">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2017</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2017/00_Haus_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Digitization of historial music archives: Preserving the past, embracing the future</div>
	<div class='proc-auth'>Goffredo Haus, Luca A. Ludovico</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-1'>Bibtex</span>
	<div id='abstract2017-1' class='collapse proc-abstract'>
Cultural institutions dealing with music (opera houses, conservatories, public and private collections, etc.) often hold huge archives made of music related heterogeneous materials. These subjects can greatly benefit from digitization campaigns and the consequent adoption of ICT techniques as it regards not only the preservation, but also the exploitation and revivification of their content. This paper, that summarizes the keynote speech held at the 3rd  International Conference on Technologies for Music Notation and Representation (TENOR 2017), starts from the experiences of the Teatro alla Scala and the Ricordi Historical Archive in order to show the new possibilities emerging from the adoption of computer-based technologies and approaches.
	</div>
	<pre id='bibtex2017-1' class='collapse proc-bibtex'>
@inproceedings{Haus_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Goffredo Haus and Luca A. Ludovico },
  Title = {Digitization of historial music archives: Preserving the past, embracing the future},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {1--8},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/01_Hajdu_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>MACAQUE — A tool for spectral processing and transcription</div>
	<div class='proc-auth'>George Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-2'>Bibtex</span>
	<div id='abstract2017-2' class='collapse proc-abstract'>
This paper describes Macaque, a tool for spectral processing and transcription, in development since 1996. Macaque was programmed in Max and, in 2013, embedded into the MaxScore ecosystem. Its GUI offers several choices for the processing and transcription of SDIF partial-track files into standard music notation. At the core of partial-track transcription is an algorithm capable of “attracting” partial tracks (and fragments thereof) into single staves, thereby performing an important aspect of “spectral orchestration.”
	</div>
	<pre id='bibtex2017-2' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2017,
  Address = {A Coruña, Spain},
  Author = { George Hajdu },
  Title = {MACAQUE — A tool for spectral processing and transcription},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {9--15},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/02_Calvo-Zaragoza_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> A machine learning framework for the categorization of elements in images of musical documents</div>
	<div class='proc-auth'>Jorge Calvo-Zaragoza, Gabriel Vigliesoni, Ichiro Fujinaga</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-3'>Bibtex</span>
	<div id='abstract2017-3' class='collapse proc-abstract'>
Musical documents may contain heterogeneous information such as music symbols, text, staff lines, ornaments, annotations, and editorial data. Before any attempt at automatically recognizing the information on scores, it is usually necessary to detect and classify each constituent layer of information into different categories. The greatest obstacle of this classification process is the high heterogeneity among music collections, which makes it difficult to propose methods that can be generalizable to a broad range of sources. In this paper we propose a novel machine learning framework that focuses on extracting the different layers within musical documents by categorizing the image at pixel level. The main advantage of our approach is that it can be used regardless of the type of document provided, as long as training data is available. We illustrate some of the capabilities of the framework by showing examples of common tasks that are frequently performed on images of musical documents, for which our approach has shown promising performance. We believe our framework will allow the development of generalizable and scalable automatic music recognition systems from document images, thus facilitating the creation of large-scale browsable and searchable repositories of music documents.
	</div>
	<pre id='bibtex2017-3' class='collapse proc-bibtex'>
@inproceedings{Calvo-Zaragoza_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Jorge Calvo-Zaragoza and Gabriel Vigliesoni and Ichiro Fujinaga },
  Title = { A machine learning framework for the categorization of elements in images of musical documents},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {17--23},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/03_Barate_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A web Interface for the analysis and performance of aleatory music notation</div>
	<div class='proc-auth'>Adriano Baratè, Luca A. Ludovico</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-4'>Bibtex</span>
	<div id='abstract2017-4' class='collapse proc-abstract'>
Black and White n.2 is a collection of 120 exercises for keyboard instrument(s) written by the Italian composer Franco Donatoni. Conceived as aleatory music, this composition adopts a non-conventional way to encode the score where some parameters are fixed and others are left to chance. In this work, we will describe a Web-based framework that, after inserting user-defined scores in Donatoni's notation, is able to automatically produce score versions compatible with the composer's constraints and executable by a human player. This application produces modern staff notation and can perform it via the Web Audio API. The goal is on one side to revive the interest towards aleatory music literature, and Donatoni's repertoire in particular, and on the other to investigate the compositional and computational process that originate a given score out of many aleatory variants.
	</div>
	<pre id='bibtex2017-4' class='collapse proc-bibtex'>
@inproceedings{ Barate_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Adriano Baratè and Luca A. Ludovico },
  Title = {A web Interface for the analysis and performance of aleatory music notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {25--31},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/04_Kim-Boyle_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The 3-D score</div>
	<div class='proc-auth'>David Kin-Boyle</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-5'>Bibtex</span>
	<div id='abstract2017-5' class='collapse proc-abstract'>
This paper examines attempts by composers to transcend the two-dimensional constraints of the printed page in musical notation. The author reviews how material depth in printed media has been explored to help create new structural forms and two of the author’s works which feature real-time, three-dimensional scores are examined. Incumbent technical limitations and constraints of multidimensional notational schemas are discussed and the author concludes by arguing that the reading through of a notational schema affords a new spatial ontology for the works represented.
	</div>
	<pre id='bibtex2017-5' class='collapse proc-bibtex'>
@inproceedings{Kim-Boyle_tenor2017,
  Address = {A Coruña, Spain},
  Author = { David Kin-Boyle },
  Title = {The 3-D score},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {33--38},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/05_Ham_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>An architectural approach to 3D spatial drum notation</div>
	<div class='proc-auth'>Jeremy J. Ham</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-6'>Bibtex</span>
	<div id='abstract2017-6' class='collapse proc-abstract'>
This research has evolved from creative practice focused on inter-disciplinary positioning between the domains of music and architecture. Through engagement in the theories and practice of architectural representation and the computational tools of spatial design, a new form of 3D spatial drum notation is presented. This notation seeks to compliment the capacities of traditional drum notation and overcome issues inherent in a theoretical ‘musico-perspectival hinge’ between the notation and the meaning of the notation. A representational schema of the spatial drum notation is discussed in the first instance in relation to the development of a lexicon of referent drum patterns and phrases and then in the testing of notation on a multi-layered improvised ‘drumscape’ composition. The paper culminates in the extension beyond notation into the realm of music spatialization through 3D printing, digital fabrication and Virtual Reality.
	</div>
	<pre id='bibtex2017-6' class='collapse proc-bibtex'>
@inproceedings{Ham_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Jeremy J. Ham },
  Title = {An architectural approach to 3D spatial drum notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {39--49},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/06_Sluchin_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A CAP for graphic scores. Graphic notation and performance</div>
	<div class='proc-auth'>Benny Sluchin,  Mikhail Malt</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-7'>Bibtex</span>
	<div id='abstract2017-7' class='collapse proc-abstract'>
Many graphic scores use the pitch versus time presentation, as a natural extension of the usual notation. In the general case, it displays discrete pitches, in a fixed timeline. Nevertheless, graphic scores use a lot of continuous lines, and the vertical dimension can be adapted to a particular performance. In such a way, the instrumentation is free, and the actual range of a particular instrument can be adapted according to the notation. The present article is initiated by a search to provide the performer with adequate tools to approach the execution of such works. A computer assisted performance approach helps the player in the preparation process for both: the time and the pitch approximations. The simulation can enhance the performance in approaching the graphical notation.
	</div>
	<pre id='bibtex2017-7' class='collapse proc-bibtex'>
@inproceedings{Sluchin_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Benny Sluchin and Mikhail Malt },
  Title = {A CAP for graphic scores. Graphic notation and performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {51--56},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/07_Miller_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Are scores maps? A cartographic response to Goodman</div>
	<div class='proc-auth'>Daniel Miller</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-8'>Bibtex</span>
	<div id='abstract2017-8' class='collapse proc-abstract'>
Nelson Goodman’s theory of notation attempts to provide an ambitious, unified account of how systems of symbolic representation preserve and transmit information and how they differ from pictorial depiction. However, Goodman’s account of music and dance notation has proven unpopular, with some critics objecting to the rigor with which scores and musical symbols are assumed to designate musical works and their constituent elements. This paper reconsiders a Goodmanian account of a music notation system in the light of recent philosophical work on maps and map-like cognition. Specifically, I propose that scores do not act as compound symbols that uniquely designate musical works. Instead notational components of scores are better understood as contingent surface-level features leveraged by an underlying map-like representational structure. On this account, scores are seen to be highly conventionalized maps, and the notational symbols of scores constitute just one of multiple modes of representation and depiction harnessed by this framework. Finally, I consider several contemporary examples of music notation and discuss how a cartographic theory of notation may provide novel insights into the graphic design considerations of these scores, particularly those that rely on new notation platforms such as graphic design software or animation, where depictive and symbolic strategies are frequently hybridized.
	</div>
	<pre id='bibtex2017-8' class='collapse proc-bibtex'>
@inproceedings{Miller_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Daniel Miller },
  Title = { Are scores maps? A cartographic response to Goodman},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {57--67},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/08_Hunt_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>How can music visualisation techniques reveal different perspectives on musical structure?</div>
	<div class='proc-auth'>Samuel J. Hunt, Tom Mitchell, Chris Nash</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-9'>Bibtex</span>
	<div id='abstract2017-9' class='collapse proc-abstract'>
Standard western notation supports the understanding and performance of music, but has limited provisions for revealing overall musical characteristics and structure. This paper presents several visualisers for highlighting and providing insights into musical structures, including rhythm, pitch, and interval transitions, also noting how these elements modulate over time. The visualisations are presented in the context of Shneiderman’s Visual Information-Seeking Mantra, and terminology from the Cognitive Dimensions of Music Notations usability framework. Such techniques are designed to make understanding musical structure quicker, easier, less error prone, and take better advantage of the intrinsic pattern recognition abilities of humans.
	</div>
	<pre id='bibtex2017-9' class='collapse proc-bibtex'>
@inproceedings{Hunt_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Samuel J. Hunt and Tom Mitchell and Chris Nash },
  Title = {How can music visualisation techniques reveal different perspectives on musical structure?},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {69--78},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/09_Nuss_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Melody retrieval and composer attribution using sequence alignment on RISM incipits</div>
	<div class='proc-auth'>Jelmer van Nuss, Geert-Jan Giezeman, Frans Wiering</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-10'>Bibtex</span>
	<div id='abstract2017-10' class='collapse proc-abstract'>
The RISM A/II database is filled with the musical notations of the beginnings of more than a million melodies. The Monochord search engine can retrieve melodies that are similar to a query melody using several search methods, amongst which pitch raters, weight-based raters and duration-based raters. The performance of all 27 search methods is evaluated using mean average precision metrics and the TREC framework that is suited for retrieval performance analysis. The difference in exact pitch between melodies turns out to be the best factor to search with for musical similarity retrieval. All melodies have metadata such as a composer name, but a portion of the database is labelled as Anonymus. A k-Nearest Neighbours algorithm is optimised for the purpose of deanonymisation and used to classify several Anonymus songs to test the applicability of this classifier for composer labelling. Using a classifier for deanonymisation purposes turns out to be viable with human correction.
	</div>
	<pre id='bibtex2017-10' class='collapse proc-bibtex'>
@inproceedings{Nuss_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Jelmer van Nuss and Geert-Jan Giezeman and Frans Wiering },
  Title = { Melody retrieval and composer attribution using sequence alignment on RISM incipits},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {79--90},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/10_Cherfi_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Formalizing quality rules on music notation. An ontology-based approach.</div>
	<div class='proc-auth'>Samira Cherfi, Fayçal Hamdi, Philippe Rigaux, Virginie Thion, Nicolas Travers</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-11'>Bibtex</span>
	<div id='abstract2017-11' class='collapse proc-abstract'>
We address the issue of expressing and evaluating quality rules on music notation. Since music engraving is a highly flexible process that can hardly be constrained by universal principles and rules, score production still heavily relies on the user expertise in order to make context-dependent decisions. We therefore propose a quality management approach based on a formal modeling of this  expertise.  We show how to use such a  model to express context-aware rules that can be evaluated either a priori to prevent the production of faulty notations, or a posteriori to assess quality indicators regarding a score or a corpus of scores. The paper  proposes a simple ontology for musical notation,  shows how  quality rules can be formally stated and evaluated, and illustrates the approach with examples drawn from a large digital library of scores.
	</div>
	<pre id='bibtex2017-11' class='collapse proc-bibtex'>
@inproceedings{Cherfi_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Samira Cherfi and Fayçal Hamdi and Philippe Rigaux and Virginie Thion and Nicolas Travers },
  Title = { Formalizing quality rules on music notation. An ontology-based approach.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {91--97},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/11_Bell_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>SMARTVOX. A web-based distributed media player as notation tool for choral practices</div>
	<div class='proc-auth'>Jonathan Bell, Benjamin Matuszewski</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-12'>Bibtex</span>
	<div id='abstract2017-12' class='collapse proc-abstract'>
The present paper describes the features and implementation of SmartVox , an application designed to help vocal ensembles learn and perform polyphonic music. Technically, SmartVox  is a distributed web application that delivers audiovisual scores through the performer’s mobile devices. From a singer’s point of view, this setup allows for the synergy between visual and acoustic stimuli, which facilitates the interpretive and performative processes, particularly in polyphonic passages. It also enables spatial separation of the performers (cori spezzati ), and speeds up the learning process of unfamiliar musical materials (e.g. microtonal tuning, texts in a foreign language). The ubiquity of smartphones makes such a distributed system affordable and allows the use of SmartVox  in multiple contexts, from professional ensembles to pedagogical and recreational practices.
	</div>
	<pre id='bibtex2017-12' class='collapse proc-bibtex'>
@inproceedings{Bell_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Jonathan Bell and Benjamin Matuszewski },
  Title = {SMARTVOX. A web-based distributed media player as notation tool for choral practices},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {99--104},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/12_Warren_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notated control as composed liveness in works for digitally extended voice</div>
	<div class='proc-auth'>Kristina Warren</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-13'>Bibtex</span>
	<div id='abstract2017-13' class='collapse proc-abstract'>
This study argues that learning of varying control mappings in digitally extended voice works imbues body and memory into liveness. The author built and uses the Abacus, a unique, microphone-mounted, Arduino-based musical interface, to control granulation of live vocal samples. There are sixteen pre-composed mappings of Abacus control data (eight toggle switches) to granulation parameters, and mapping changes regularly. An animated screen score provides manual toggle control instructions, which didactically supply information on current mapping. The author’s practice is related to other composer-vocalists’ works for digitally extended voice and to a larger context of screen scores and musical games. Extended voice treats vocal presence as body-technology intersection, and screen scores and musical games highlight embodied learning using unchanging control mappings. The author’s work unites these realms, arguing that repeated, notation-driven learning of the action-sound relationship thematizes complex interactions between body, temporality, memory, and presence.
	</div>
	<pre id='bibtex2017-13' class='collapse proc-bibtex'>
@inproceedings{Warren_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Kristina Warren },
  Title = {Notated control as composed liveness in works for digitally extended voice},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {105 --110},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/13_Hron_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notating electroacoustic music for performers from a practitioner's experience</div>
	<div class='proc-auth'>Terri Hron</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-14'>Bibtex</span>
	<div id='abstract2017-14' class='collapse proc-abstract'>
This paper discusses notation practices and experiments within the electroacoustic performance and composition practice of the author. These spring from a performer and performance-oriented position towards notation in a field that has traditionally catered more to notation for analysis and description. As such, the works and experiences discussed offer hybrid solutions and multiple formats to satisfy specific needs for the effective rehearsal and performance of electroacoustic music. The adaptation of tools specific to electroacoustic practice for more contemporary classical performers is discussed using examples from works written for and by the author in collaboration with other performers and composers.
	</div>
	<pre id='bibtex2017-14' class='collapse proc-bibtex'>
@inproceedings{Hron_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Terri Hron },
  Title = {Notating electroacoustic music for performers from a practitioner's experience},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {111--115},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/14_Shafer_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Performer action modeling in real-time notation</div>
	<div class='proc-auth'>Seth Shafer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-15'>Bibtex</span>
	<div id='abstract2017-15' class='collapse proc-abstract'>
This paper discusses the application of action-based music notation, and in particular performer action modeling, to my real-time notation (RTN) work, Terraformation (2016–17), which uses a combination of common practice notation (CPN), fingerboard tablature, and color gradients.
	</div>
	<pre id='bibtex2017-15' class='collapse proc-bibtex'>
@inproceedings{Shafer_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Seth Shafer },
  Title = { Performer action modeling in real-time notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {117--123},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/15_Martinez-Nieto_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Expression marks for programming interactive music.</div>
	<div class='proc-auth'>Juan Carlos Martínez Nieto, Jason Freeman</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-16'>Bibtex</span>
	<div id='abstract2017-16' class='collapse proc-abstract'>
The present work uses common Western music notation to represent logical and systematic behaviours of computer music processes in the context of score-oriented interactive music. The algorithmic representation is described by adding programming annotations in a controlled natural language to a musical staff as expression marks in the score. We implemented a computational environment that is able to translate these expression marks into coding instructions and execute them in real-time during a live performance of an interactive-music piece. A collection of short interactive music exercises for MIDI-controlled piano based on the proposed notation was composed and edited using music engraving software. During the compilation stage, an encoded version of the score in MusicXML format is translated into scripting code, and during live performance the computational environment executes the code in real time in sync with the human-performed parts. This paper introduces the syntax of expression marks for programming interactive music through a classic “Hello World” example in the context of interactive music and explains the technical details behind the implementation of the computational environment. The main motivation behind this work was to evaluate the viability of creating a cohesive symbolic representation of interactive music that is independent of specific software and hardware frameworks, and is strongly connected with the western music tradition.
	</div>
	<pre id='bibtex2017-16' class='collapse proc-bibtex'>
@inproceedings{Martinez-Nieto_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Juan Carlos Martínez Nieto and Jason Freeman },
  Title = {Expression marks for programming interactive music.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {125--130},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/16_Garcia_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Timed sequences: A framework for computer aided composition with temporal structures</div>
	<div class='proc-auth'>Jérémie Garcia, Dimitri Bouche, Jean Bresson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-17'>Bibtex</span>
	<div id='abstract2017-17' class='collapse proc-abstract'>
The software framework we present implements a simple and generic representation of the temporal dimension of musical structures used in computer-aided composition software. These structures are modelled as ordered sets of abstract “timed items” whose actual dates can be set and determined following different strategies. The timed items can be linked to an underlying action scheduling and rendering system, and can also be used as temporal handles to perform time stretching and hierarchical synchronization operations. A graphical user interface associated with this model can be embedded as a component within musical editors. We give several examples of musical objects implemented in this framework, as well as examples of time-domain operations and user interactions.
	</div>
	<pre id='bibtex2017-17' class='collapse proc-bibtex'>
@inproceedings{Garcia_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Jérémie Garcia and Dimitri Bouche and Jean Bresson },
  Title = {Timed sequences: A framework for computer aided composition with temporal structures},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {131--136},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/17_Faraldo_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> The house harmonic filler: Interactive exploration of chord sequences by means of an intuitive representation</div>
	<div class='proc-auth'>Angel Faraldo, Perfecto Herrera, Sergi Jordà</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-18'>Bibtex</span>
	<div id='abstract2017-18' class='collapse proc-abstract'>
In this paper we present an interactive two-dimensional representation of musical chord progressions, integrated into a computer program that generates house music harmonic loops in MIDI format, based on a user's input. Our aim is to encapsulate relevant tonal information and display it in ways that are easy to understand for novices and untrained musicians, facilitating the creative exploration of musical ideas. We briefly reference previous work on tonal visualisation and interaction, and introduce some measures of tonal properties from the literature. We then present our system and describe the two-dimensional harmonic map, before discussing its outcomes and shortcomings, pointing at future lines of research in the conclusions.
	</div>
	<pre id='bibtex2017-18' class='collapse proc-bibtex'>
@inproceedings{Faraldo_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Angel Faraldo and Perfecto Herrera and Sergi Jordà },
  Title = { The house harmonic filler: Interactive exploration of chord sequences by means of an intuitive representation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {137--143},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/18_Jacquemard_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Generating equivalent rhythmic notations based on rhythm tree languages.</div>
	<div class='proc-auth'>Florent Jacquemard, Adrien Ycart, Masahiko Sakai</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-19'>Bibtex</span>
	<div id='abstract2017-19' class='collapse proc-abstract'>
We propose a compact presentation of languages of preferred rhythm notations as formal grammars. It is based on a standard structure of rhythm trees capturing a wide range of rhythms in Western notation. As an application, we then describe a dynamic programming algorithm for the lazy enumeration of equivalent rhythm notations (i.e. notations defining the same durations), from the simplest to the most complex. This procedure, based on the notion of rhythm grammars has been implemented and may be useful in the context of automated music transcription and computer-assistance to composition.
	</div>
	<pre id='bibtex2017-19' class='collapse proc-bibtex'>
@inproceedings{Jacquemard_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Florent Jacquemard and Adrien Ycart and Masahiko Sakai },
  Title = {Generating equivalent rhythmic notations based on rhythm tree languages.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {145--153},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/19_Mendonca_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> “Des pas sur l’invisible”. The octave space and the self-multiplication process.</div>
	<div class='proc-auth'>Silvia Mendonça</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-20'>Bibtex</span>
	<div id='abstract2017-20' class='collapse proc-abstract'>
The purpose of this paper is to describe the process, from a composition standpoint, from which my piece Des pas sur le invisible (2016) for clarinet or solo saxophone, was composed. This work is part of a PhD in music in which I propose a model of composition based on a self-multiplication process, and was created within the context of the Frederico de Freitas Interpretation Prize, Universidade de Aveiro (May 2016 edition). Starting from a pre composing point of view, we will consider the octave musical interval as a metaphor for the self-multiplication process. This reflection allows us to think the octave as a space and therefore, how the attribution of this extended dimension can be rethought in music, leading us to new approaches of the composition practice. The piece Des pas sur le invisible will show how this approach can be accomplished, serving to illustrate a thought that takes place outside the proper world of musical elements and considerations that can be decisive in the musical discourse. It will show how the principle behind the conception of this work can develop perspectives for the composition notation practice and for future research.
	</div>
	<pre id='bibtex2017-20' class='collapse proc-bibtex'>
@inproceedings{Mendonca_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Silvia Mendonça },
  Title = { “Des pas sur l’invisible”. The octave space and the self-multiplication process.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {155-159},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/20_Bhagwati_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Vexations of ephemerality.</div>
	<div class='proc-auth'>Sandeep Bhagwati</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-21'>Bibtex</span>
	<div id='abstract2017-21' class='collapse proc-abstract'>
What do we do when we subject musicians and audiences to music prompted by real-time scores? Such situative scores create a new kind of immanent relationship between performers and audiences, between composers and performers, composers and audiences – a relationship whose ingrained disregard of context, memory, and knowledge has often been ignored. The use of situative scores seems to inscribe itself into a more general societal trend that uses technology to ephemeralize our lives, to decouple presence from its history. While this immanence has often been perceived as a force for the emancipation of performers and spectators, it can also give rise to unaccountability. Do artistic practices that ephemeralize our artistic 'regime of perception, sensation and interpretation' (Rancière) - such as situative scores – foster abuses of immanence?. In this paper, I will look at such questions from the perspective of the performers, the audiences and the makers of such scores – the composers.
	</div>
	<pre id='bibtex2017-21' class='collapse proc-bibtex'>
@inproceedings{Bhagwati_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Sandeep Bhagwati },
  Title = {Vexations of ephemerality.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {161--166},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/21_Antila_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A hierarchic diff algorith for collaborative music document editing.</div>
	<div class='proc-auth'>Christopher Antila, Jeffrey Treviño, Gabriel Weaver</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-22'>Bibtex</span>
	<div id='abstract2017-22' class='collapse proc-abstract'>
We describe an application of hierarchic diff to the collaborative editing of tree-based music representations, using Zhang and Shasha’s tree edit distance algorithm as implemented within the XUDiff tool. The edit distance between two trees is the minimum number of edit operations necessary to transform one tree into the other. We consider common operations on the score tree—deleting, changing, and appending tree nodes—to derive a minimal edit sequence, known as an edit script, and we compare the performance of the widely used Longest Common Subsequence algorithm against our approach. We conclude by summarizing implications for the design of collaborative music document software systems.
	</div>
	<pre id='bibtex2017-22' class='collapse proc-bibtex'>
@inproceedings{Antila_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Christopher Antila and Jeffrey Treviño and Gabriel Weaver },
  Title = {A hierarchic diff algorith for collaborative music document editing.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {167--170},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/22_James_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Establishing connectivity between the existing networked music notation packages Quintet.net, Decibel Score Player and MaxScore.</div>
	<div class='proc-auth'>Stuart James, Cat Hope, Lindsay Vickery, Aaron Wyatt, Ben Carey, Xiao Fu, George Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-23'>Bibtex</span>
	<div id='abstract2017-23' class='collapse proc-abstract'>
In this paper we outline a collaboration where live internet-based and local collaboration between research groups/musicians from Decibel New Music Ensemble (Perth, Australia) and ZM (Hamburg, Germany), was facilitated by novel innovations in customised software solutions employed by both groups. The exchange was funded by the Deutscher Akademischer Austauschdienst and Universities Australia. Both groups were previously engaged in the research and performance of similar musical repertoire such as John Cage’s ‘Five’ (1988) and ‘Variations I — VIII’ (1958-67) among others, the performances of which utilise graphic, animated and extended traditional Western music notation. Preliminary steps were taken to achieve communication between the three existing network music notation packages, the Decibel ScorePlayer, MaxScore and quintet.net, facilitating a merging – and ultimately an extension – of notational approaches previously prescribed by each music notation package. In addition to the technical innovations required to achieve such a project, we consider the outcomes and future directions of the project, as well as their relevance for the wider contemporary music community.
	</div>
	<pre id='bibtex2017-23' class='collapse proc-bibtex'>
@inproceedings{James_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Stuart James and Cat Hope and Lindsay Vickery and Aaron Wyatt and Ben Carey and Xiao Fu and George Hajdu },
  Title = {Establishing connectivity between the existing networked music notation packages Quintet.net, Decibel Score Player and MaxScore.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {171--183},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/23_Marco_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Persiles avista Roma</div>
	<div class='proc-auth'>Tomas Marco</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-24'>Bibtex</span>
	<div id='abstract2017-24' class='collapse proc-abstract'>
“Persiles avista Roma” was commissioned as part of the commemorative events set to homage Cervantes on his 4th Centenary. The composer was inspired by one of the sonnets included in "Los trabajos de Persiles and Segismunda", which was the last novel written by Cervantes, posthumous published in 1617. “The composition is built as a formal dialogue between the structure of the sonnet - taken with a flexible perspective - and its musical expression. The music score is written for baritone and violin soloists which interact as a "duo concertante". The composition proposes a contemporary musical view of Cervantes text, which has an eternal life crystallised in a mythical present.
	</div>
	<pre id='bibtex2017-24' class='collapse proc-bibtex'>
@inproceedings{Marco_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Tomas Marco },
  Title = {Persiles avista Roma},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {185--193},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/24_Palma_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Voice Prints</div>
	<div class='proc-auth'>Helena Palma</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-25'>Bibtex</span>
	<div id='abstract2017-25' class='collapse proc-abstract'>
Voice prints (VP) is a homage to our ancestors and the languages they used as tools to create and expand over large locations powerful civilisations. Where are our ancestors now? Have they disappeared? Those people and the locations they lived in are casted in infinite events created by our thoughts. We can hear the resonances of their voices in the roar of time. In VP the ancestors’ voices are articulated by the voice of a baritone and of a violin who melt their timbre in resonances of the words uttered by a distant father: harmonics 2, 3, 4, 5, 7, and 9 of a fundamental Bb1 tone. VP includes phonemes, words and sentences sung and spoken in Scythian, Greek, Celtiberian, Ubykh, Albanian, Catalan, English, Galician, German, Spanish. Music is set to fragments of poems by Espriu,  Handke and Llamazares.
	</div>
	<pre id='bibtex2017-25' class='collapse proc-bibtex'>
@inproceedings{Palma_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Helena Palma },
  Title = {Voice Prints},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {195--207},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/25_Teles_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Des pas sur l’invisible</div>
	<div class='proc-auth'>Silvia Teles</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-26'>Bibtex</span>
	<div id='abstract2017-26' class='collapse proc-abstract'>
Music score
	</div>
	<pre id='bibtex2017-26' class='collapse proc-bibtex'>
@inproceedings{Teles_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Silvia Teles },
  Title = {Des pas sur l’invisible},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {209--214},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/26_Shafer_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Terraformation</div>
	<div class='proc-auth'>Seth Shafer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-27'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-27'>Bibtex</span>
	<div id='abstract2017-27' class='collapse proc-abstract'>
This paper introduces my real-time notation (RTN) work Terraformation (2016-17) for violin or viola and computer. The piece uses a computer screen to display music notation that changes during the performance based on decisions made by both the musician and the computer. In this way, every performance is unique and unrepeatable. Program notes, performance directions, and two score excerpts from violinist Florian Vlashi's performance on May 25, 2017 at the Third International Conference on Technologies for Music Notation and Representation are included.
	</div>
	<pre id='bibtex2017-27' class='collapse proc-bibtex'>
@inproceedings{Shafer_b_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Seth Shafer },
  Title = {Terraformation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {215--227},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/27_Hoadley_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Homenaje a Cervantes</div>
	<div class='proc-auth'>Richard Hoadley</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-28'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-28'>Bibtex</span>
	<div id='abstract2017-28' class='collapse proc-abstract'>
This is a presentation of the dynamic score “Homenaje a Cervantes”  (Homage to Cervantes) created for violin, computer and projections, originally commissioned for and first performed at the University of A Coruna, Spain in May 2017. The piece has been composed using the software packages SuperCollider and INSCORE; the violin part should be played live from a laptop screen or a projection. The texts used are the original Cervantes text, an English translation and a series of original poems created specially for this project by the poet Phil Terry.
	</div>
	<pre id='bibtex2017-28' class='collapse proc-bibtex'>
@inproceedings{Hoadley_tenor2017,
  Address = {A Coruña, Spain},
  Author = { Richard Hoadley },
  Title = {Homenaje a Cervantes},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2017},
  Pages = {229-238},
  Year = {2017},
  Editor = {Helena LOPEZ PALMA and Mike SOLOMON and Emiliana TUCCI and Carmen LAGE},
  Publisher = {Universidade da Coruña},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
</div>
    </section>

    <section id="2016">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2016</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2016/01_Ghisi_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Real-Time Corpus-Based Concatenative Synthesis for Symbolic Notation</div>
	<div class='proc-auth'>Daniele Ghisi and Carlos Agon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-1'>Bibtex</span>
	<div id='abstract2016-1' class='collapse proc-abstract'>
We introduce a collection of modules designed to segment, analyze, display and sequence symbolic scores in real-time. This mechanism, inspired from CataRT’s corpus-based concatenative synthesis, is implemented as a part of the dada library for Max, currently under development.
	</div>
	<pre id='bibtex2016-1' class='collapse proc-bibtex'>
@inproceedings{Ghisi_tenor2016,
  Address = {Cambridge, UK},
  Author = { Daniele Ghisi and Carlos Agon },
  Title = {Real-Time Corpus-Based Concatenative Synthesis for Symbolic Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {1--7},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/02_Herremans_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Tension ribbons: Quantifying and visualising tonal tension</div>
	<div class='proc-auth'>Dorien Herremans and Elaine Chew</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-2'>Bibtex</span>
	<div id='abstract2016-2' class='collapse proc-abstract'>
Tension is a complex multidimensional concept that is not easily quantified. This research proposes three methods for quantifying aspects of tonal tension based on the spiral array, a model for tonality. The cloud diameter measures the dispersion of clusters of notes in tonal space; the cloud momentum measures the movement of pitch sets in the spiral array; finally, tensile strain measures the distance between the local and global tonal context. The three methods are implemented in a system that displays the results as tension ribbons over the music score to allow for ease of interpretation. All three methods are extensively tested on data ranging from small snippets to phrases with the Tristan chord and larger sections from Beethoven and Schubert piano sonatas. They are further compared to results from an existing empirical experiment.
	</div>
	<pre id='bibtex2016-2' class='collapse proc-bibtex'>
@inproceedings{Herremans_tenor2016,
  Address = {Cambridge, UK},
  Author = { Dorien Herremans and Elaine Chew },
  Title = {Tension ribbons: Quantifying and visualising tonal tension},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {8--18},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/03_Vickery_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Hybrid Real/Mimetic Sound Works</div>
	<div class='proc-auth'>Lindsay Vickery</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-3'>Bibtex</span>
	<div id='abstract2016-3' class='collapse proc-abstract'>
In 2013 I began a project to construct a process allowing for data interchange between visual and sonic media: to create a continuum in which sound could be visualized and then resonified through by both live performers and digital means. A number of processes to aid this visualisation/sonification “ecosystem” were developed. Software was created to create scores based on sonic features of “field recordings” through spectral analysis by rendering the frequency of the strongest detected sinusoidal peak of a recording vertically and its timbral characteristics by luminance, hue and saturation on a scrolling score. Along similar principals a second process was developed to generate a realtime score using graphical symbols to represent detected accents in “found sound” speech recordings. In the other direction software was built to render greyscale images (including sonograms) as sound and a second iteration to generate audio from detected analysis parameters. The imperfections in the various transcription processes are intriguing in themselves as they throw into relief the distinctions between the various forms of representation and in particular the timescales in which they are perceived. The implied circularity of processes also opened the potential for re-interrogation of materials through repeated transmutation. This discussion explores these implications in the context of the analysis of field record-ings to generate visual representations that can be reson-ified using both performative (via notation) and machine (visual data-based) processes, to create hybrid re-al/mimetic sound works through the combination (and recombination) of the processes.
	</div>
	<pre id='bibtex2016-3' class='collapse proc-bibtex'>
@inproceedings{Vickery_tenor2016,
  Address = {Cambridge, UK},
  Author = { Lindsay Vickery },
  Title = {Hybrid Real/Mimetic Sound Works},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {19--24},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/04_Jeong_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Visualizing Music in its Entirety using Acoustic Features: Music Flowgram</div>
	<div class='proc-auth'>Dasaem Jeong and Juhan Nam</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-4'>Bibtex</span>
	<div id='abstract2016-4' class='collapse proc-abstract'>
In this paper, we present an automatic method for visualizing a music audio file from its beginning to end, especially for classical music. Our goal is developing an easy-to-use visualization method that is helpful for listeners and can be used for various kinds of classical music, even for complex orchestral music. To represent musical characteristic, the method uses audio features like volume, onset density, and auditory roughness, which describe loudness, tempo, and dissonance, respectively. These features are visually mapped into static two-dimensional graph, so that users can see how the music changes by time at a look. We have implemented the method with Web Audio API, and it works on recent version of web browsers like Chrome, Firefox, Safari, and Opera. Users can access to the visualization system on their web browser and make visualizations from their own music audio files. Two types of user tests were conducted to verify effects and usefulness of the visualization for classical music listeners. The result shows that it helps listeners to memorize and understand a structure of music, and to easily find a specific part of the music.
	</div>
	<pre id='bibtex2016-4' class='collapse proc-bibtex'>
@inproceedings{Jeong_tenor2016,
  Address = {Cambridge, UK},
  Author = { Dasaem Jeong and Juhan Nam },
  Title = {Visualizing Music in its Entirety using Acoustic Features: Music Flowgram},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {25--32},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/05_Misra_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Swaralipi: A Framework for Transcribing and Rendering Indic Music Sheet</div>
	<div class='proc-auth'>Chandan Misra, Tuhin Chakraborty, Anupam Basu and Baidurya Bhattacharya</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-5'>Bibtex</span>
	<div id='abstract2016-5' class='collapse proc-abstract'>
Creating music in computer system through its music notations requires two primary components. The first one is the mechanisms to encode music notations of respective music genres and the other one is a framework to provide the look and feel of the music written like a published or handwritten music sheet. Popular music scorewriters like Finale, Sibelius, MuseScore can edit, render and playback music transcribed in Staff notation. Being vastly different from the Indic music system in grammar, notation symbols, tonic system and encoding style, the architecture used in the music software for western music cannot cater to the Indic music system. For this reason there is a dearth of such scorewriters for Indic music system which is rich with a variety of musical genres, each different from the others in their unique notation system and language for depicting their lyric. In this paper, we propose a new framework for transcribing and rendering Indic music sheets for different genres of Indic music in computer. This framework is designed to support all major Indic notation systems and Indic language scripts and is explained using three major notation systems and language scripts throughout the paper as a case study.
	</div>
	<pre id='bibtex2016-5' class='collapse proc-bibtex'>
@inproceedings{Misra_tenor2016,
  Address = {Cambridge, UK},
  Author = { Chandan Misra and Tuhin Chakraborty and Anupam Basu and Baidurya Bhattacharya },
  Title = {Swaralipi: A Framework for Transcribing and Rendering Indic Music Sheet},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {33--43},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/06_Hurtado_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notating the Non-Notateable: Digital Notation of Txalaparta Practice</div>
	<div class='proc-auth'>Enrike Hurtado and Thor Magnusson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-6'>Bibtex</span>
	<div id='abstract2016-6' class='collapse proc-abstract'>
This paper explores notation practices related to the ancient Basque musical tradition of the txalaparta. It will firstly present the txalaparta practice, introduce the im-provisational rules of txalaparta playing, and discuss attempts in creating notation systems for the instrument. Due to the nature of txalaparta playing, Common West-ern Notation is not a suitable notation, and we will pre-sent the notation system we have developed as part of the Digital Txalaparta project. This system captures the key parts of playing and serves for both playback and a rich documentation of what players actually perform.
	</div>
	<pre id='bibtex2016-6' class='collapse proc-bibtex'>
@inproceedings{Hurtado_tenor2016,
  Address = {Cambridge, UK},
  Author = { Enrike Hurtado and Thor Magnusson },
  Title = {Notating the Non-Notateable: Digital Notation of Txalaparta Practice},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {44--49},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/07_Sonnenfeld_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>S-notation: A complete musical notation system for scratching and sample music derived from "Theory of Motions"</div>
	<div class='proc-auth'>Alexander Sonnenfeld and Kjetil Falkenberg Hansen</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-7'>Bibtex</span>
	<div id='abstract2016-7' class='collapse proc-abstract'>
In this paper, we present and discuss S-notation for sample-based music, and particularly for DJ scratching and turntablism. Sonnenfeld developed S-notation based on his Theory of Motion where scratch music is seen as constructions of concurrent musical gestures (motion parameters), and not only turntable actions. The detailed symbolic notation was inspired by traditional musical notation, and among its advantages it covers current musical needs, it can be read and played live in performance, it provides a tool for composers to convey musical ideas, it can be expanded towards new styles and techniques, and it is generalizable to other types of sample-based music. In addition to motion parameters, the new notation system involves an analysis of the sampled sound. Finally, S-notation is also applicable for documenting and for teaching situations.
	</div>
	<pre id='bibtex2016-7' class='collapse proc-bibtex'>
@inproceedings{Sonnenfeld_tenor2016,
  Address = {Cambridge, UK},
  Author = { Alexander Sonnenfeld and Kjetil Falkenberg Hansen },
  Title = {S-notation: A complete musical notation system for scratching and sample music derived from "Theory of Motions"},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {50--57},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/08_Hall_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Pitchcircle3D: A Case Study in Live Notation for Interactive Music Performance</div>
	<div class='proc-auth'>Tom Hall</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-8'>Bibtex</span>
	<div id='abstract2016-8' class='collapse proc-abstract'>
Recent decades have seen the establishment of computer software live notations intended as music scores, affording new modes of interaction between composers, improvisers, performers and audience. This paper presents a live notations project situated within the research domains of algorithmic music composition, improvisation, performance and software interaction design. The software enables the presentation of live animated scores which display 2D and 3D pitch-space representations of note collections including a spiral helix and pitch-class clock. The software has been specifically engineered within an existing sound synthesis environment, SuperCollider, to produce tight integration between sound synthesis and live notation. In a performance context, the live notation is usually presented as both music score and visualisation to the performers and audience respectively. The case study considers the performances of two of the author's contrasting compositions utilising the software. The results thus far from the project demonstrate the ways in which the software can afford different models of algorithmic and improvised interaction between the composer, performers and the music itself. Also included is a summary of feedback from musicians who have used the software in public music performances over a number of years.
	</div>
	<pre id='bibtex2016-8' class='collapse proc-bibtex'>
@inproceedings{Hall_tenor2016,
  Address = {Cambridge, UK},
  Author = { Tom Hall },
  Title = {Pitchcircle3D: A Case Study in Live Notation for Interactive Music Performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {58--64},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/09_Shafer_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Performance Practice of Real-Time Notation</div>
	<div class='proc-auth'>Seth Shafer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-9'>Bibtex</span>
	<div id='abstract2016-9' class='collapse proc-abstract'>
The primary distinction between real-time and non-real-time notation is the ability for the performer to know ahead of time the exact details of what they will be asked to perform. This paper address the myriad of performance practice issues encountered when the notation of a work loosens its bounds in the world of the fixed and knowable, and instead explores the realms of chance, spontaneity, and interactivity. Some of these issues include: the problem of rehearsal, the problem of ensemble synchronization, the extreme limits of sight reading, failure as a compositional device, new freedoms for the performer and composer, and the new opportunities offered by the ephemerality and multiplicity of real-time notation.
	</div>
	<pre id='bibtex2016-9' class='collapse proc-bibtex'>
@inproceedings{Shafer_tenor2016,
  Address = {Cambridge, UK},
  Author = { Seth Shafer },
  Title = {Performance Practice of Real-Time Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {65--70},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/10_Zitellini_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Representing atypical music notation practices: An example with late 17th century music</div>
	<div class='proc-auth'>Rodolfo Zitellini and Laurent Pugin</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-10'>Bibtex</span>
	<div id='abstract2016-10' class='collapse proc-abstract'>
From the 17th century towards the first decades of the 18th century music notation slowly looses all influences from mensural music, becoming virtually identical to what we would consider common modern notation. But in these five decades of transformation composers did not just suddenly abandon older notation styles, but they were used alongside the ones that would become standard. Void notation, black notation and uncommon tempi were all mixed together. The scholar preparing modern editions of this music is normally forced to normalize all these atypical notations as many software applications do not support them natively. This paper exemplifies the flexibility of the encoding scheme proposed by the Music Encoding Initiative (MEI) and of Verovio, a visualisation library designed for it. The modular approach of these tools means that particular notation systems can be easily added whilst maintaining compatibility to other encoded notations.
	</div>
	<pre id='bibtex2016-10' class='collapse proc-bibtex'>
@inproceedings{Zitellini_tenor2016,
  Address = {Cambridge, UK},
  Author = { Rodolfo Zitellini and Laurent Pugin },
  Title = {Representing atypical music notation practices: An example with late 17th century music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {71--77},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/11_Palma_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Expressive Function in Wor Songs</div>
	<div class='proc-auth'>Helena Palma</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-11'>Bibtex</span>
	<div id='abstract2016-11' class='collapse proc-abstract'>
We study some musical and expressive features of traditional Wor vocal music, an ancestral gender of the Biaks (West Papua). A core aspect in Wor songs is the expression of wonder, which Biaks have developed into an Aesthetics of Surprise. We describe some key structural features in the pitch and time domain used as means to express such an aesthetics. We represent the acoustic and prosodic features encoding expressive content by means of an Expressive Function which contains expressive indices with internal structure. We propose an augmented expressive score for the transcription of unaccompanied Wor songs.
	</div>
	<pre id='bibtex2016-11' class='collapse proc-bibtex'>
@inproceedings{Palma_tenor2016,
  Address = {Cambridge, UK},
  Author = { Helena Palma },
  Title = {The Expressive Function in Wor Songs},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {78--84},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/12_Fournier_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Is There a Data Model in Music Notation?</div>
	<div class='proc-auth'>Raphaël Fournier-Sn'Iehotta, Philippe Rigaux and Nicolas Travers</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-12'>Bibtex</span>
	<div id='abstract2016-12' class='collapse proc-abstract'>
Scores are structured objects, and we can therefore envisage operations that change the structure of a score, combine several scores, and produce new score instances from some pre-existing material. Current score encodings, however, are designed for rendering and exchange purposes, and cannot directly be exploited as instances of a clear data model supporting algebraic manipulations. We propose an approach that leverages a music content model hidden in score notation, and define a set of composable operations to derive new "scores" from a corpus of existing ones. We show that this approach supplies a high-level tool to express common, useful applications, can easily be implemented on top of standard components, and finally gives rise to interesting conceptual issues related to the modeling of music notation.
	</div>
	<pre id='bibtex2016-12' class='collapse proc-bibtex'>
@inproceedings{Fournier_tenor2016,
  Address = {Cambridge, UK},
  Author = { Raphaël Fournier-Sn'Iehotta and Philippe Rigaux and Nicolas Travers },
  Title = {Is There a Data Model in Music Notation?},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {85--91},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/13_Kim-Boyle_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Ontology of Live Notations Through Assemblage Theory</div>
	<div class='proc-auth'>David Kim-Boyle</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-13'>Bibtex</span>
	<div id='abstract2016-13' class='collapse proc-abstract'>
This paper uses assemblage theory to help develop an ontological framework for better understanding live notation practice. Originally developed by Deleuze and Guattari across a range of theoretical writings, assemblage theory is more fully explicated in the work of Manuel de Landa in the more focused context of social ontology. This paper examines the basic concepts of assemblage theory such as material components, expressive capacities, and relations of exteriority and how they may pro-vide useful insights in the analysis of music which explores the creative potential of live notation. The temporal dynamics of non-linear musical forms are discussed and assemblage theory is shown to be a powerful tool for promoting a better understanding of how the various interactions between material and expressive components help catalyze the emergent properties of the assemblage and through it, the ontological identity of a live notation aesthetic practice.
	</div>
	<pre id='bibtex2016-13' class='collapse proc-bibtex'>
@inproceedings{Kim-Boyle_tenor2016,
  Address = {Cambridge, UK},
  Author = { David Kim-Boyle },
  Title = {The Ontology of Live Notations Through Assemblage Theory},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {92--97},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/14_Ross-Smith_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>[Study no. 50][Notational Becoming][Speculations]</div>
	<div class='proc-auth'>Ryan Ross Smith</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-14'>Bibtex</span>
	<div id='abstract2016-14' class='collapse proc-abstract'>
The use of animation in contemporary notational practices has become increasingly prevalent over the last ten years, due in large part to the increased compositional activities throughout Europe, the United Kingdom, and North America, and in particular Iceland and Western Australia.1 The publication of several foundational texts,2 and the materialization of focused scholarly meetings3 and online consolidation projects4 have also contributed to the expansion of this growing field of animated notational practice. The range of compositional ideas repre- sented by these scores is vast, encompassing a wide va- riety of stylistic approaches and technological experimentation. While these ideas often demonstrate intriguing compositional directions, and the unique dynamic functionalities and visual characteristics of animated scores are clearly distinct from traditionally-fixed scores, it is the real-time generative processes of these scores that represent a shift in the very ontology of the musical score. In this paper I speculate on one possible framing for this ontological distinction by focusing on several attributes that, in combination, most explicitly demonstrate this distinction. These include the real-time, process-based qualities of generative animated notations, the openness that enables these procedural functionalities, the displacement of interpretive influence, and the timeliness of these processes in respect to the temporal relationship between generation, representation as notation, and sonic realization. A new work, Study no. 50, will be examined as a practical demonstration of these attributes, and will function as a jumping off point for a speculative discussion of the concept of Notational Becoming.
	</div>
	<pre id='bibtex2016-14' class='collapse proc-bibtex'>
@inproceedings{Ross-Smith_tenor2016,
  Address = {Cambridge, UK},
  Author = { Ryan Ross Smith },
  Title = {[Study no. 50][Notational Becoming][Speculations]},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {98--104},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/15_Fox_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Autonomy, Control, and Notation in Interactive Music</div>
	<div class='proc-auth'>K. Michael Fox</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-15'>Bibtex</span>
	<div id='abstract2016-15' class='collapse proc-abstract'>
This paper proposes a conceptualization of notation for interactive musical environments. The notational approach describes the relationship between both human and non-human agents, instead of actions to be taken or sounds to be made. Of critical importance in contemporary networked culture is the degree to which technological devices and networks constrain (or control) the actions of their users. The author has developed a conception of interactivity and notational considerations which instead foreground the autonomous potential of participants and the computational systems. The author analyzes three case studies that demonstrate either a direct connection or a broader conceptual link to the described notational approach. The larger implication is a need for notational systems which do not constrain the identity of the users of interactive systems while also acknowledging and representing the agency of the systems themselves.
	</div>
	<pre id='bibtex2016-15' class='collapse proc-bibtex'>
@inproceedings{Fox_tenor2016,
  Address = {Cambridge, UK},
  Author = { K. Michael Fox },
  Title = {Autonomy, Control, and Notation in Interactive Music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {105--109},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/16_Tomas_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Musical Instruments as Scores: A Hybrid Approach</div>
	<div class='proc-auth'>Enrique Tomás</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-16'>Bibtex</span>
	<div id='abstract2016-16' class='collapse proc-abstract'>
The development of new approaches to instrumentality during the decade of 1960 contributed to the dual perception of instruments as scores. For many performers, the instrument became the score of what they played. This artistic hybridization carries substantial questions about the nature of our scores and about the relationships among instruments, performers and musical works. This paper contextualizes the historical origins of this instrumental development within Drucker's theory of performative materiality. Then we examine the nature and notational scheme of this type of scores making use of the concept of "inherent score". Finally, through the analysis of two examples ("tangible scores" and "choreographic objects") and the notions of "affordance" and "constraint", a compositional framework for shaping the inherent instrument score is presented.
	</div>
	<pre id='bibtex2016-16' class='collapse proc-bibtex'>
@inproceedings{Tomas_tenor2016,
  Address = {Cambridge, UK},
  Author = { Enrique Tomás },
  Title = {Musical Instruments as Scores: A Hybrid Approach},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {110--120},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/17_Bhagwati_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Musicking the Body Electric. The "body:suit:score" as a polyvalent score interface for situational scores.</div>
	<div class='proc-auth'>Sandeep Bhagwati, Marcello Giordano, Joanna Berzowska, Alex Bachmayr, Julian Stein, Joseph Browne, Felix Del Tredici, Deborah Egloff, John Sullivan, Marcelo Wanderley and Isabelle Cossette</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-17'>Bibtex</span>
	<div id='abstract2016-17' class='collapse proc-abstract'>
Situational scores, in this paper, are defined as scores that deliver time- and context-sensitive score information to musicians at the moment when it becomes relevant. Mnemonic (rule/style-based) scores are the oldest score models of this type. Lately, animated, interactive, locative scores have added new options to situative scoring. The body:suit:score is an interface currently developed in collaboration of four labs at Concordia and McGill Universities in Montréal - an interface that will allow the musical use of all four types of situational score. Musicians are clad in a body-hugging suit with embedded technology - this suit becomes their score interface. Ultimately intended to enable ensembles to move through performance spaces unencumbered by visual scores and their specific locations, the project currently enters its second year of research-creation. The paper discusses the closely intertwined technological, ergonomic, music-psychology based and artistic decisions that have led to a first bodysuit prototype - a vibrotactile suit for a solo musician. It will also discuss the so-far three etude compositions by Sandeep Bhagwati and Julian Klein for this prototype, and their widely divergent conceptual approaches to an artistic use of the body:suit:score interface. Finally, the paper discusses next steps and emergent problems and opportunities, both technological and artistic.
	</div>
	<pre id='bibtex2016-17' class='collapse proc-bibtex'>
@inproceedings{Bhagwati_tenor2016,
  Address = {Cambridge, UK},
  Author = { Sandeep Bhagwati and Marcello Giordano and Joanna Berzowska and Alex Bachmayr and Julian Stein and Joseph Browne and Felix Del Tredici and Deborah Egloff and John Sullivan and Marcelo Wanderley and Isabelle Cossette },
  Title = {Musicking the Body Electric. The "body:suit:score" as a polyvalent score interface for situational scores.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {121--126},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/18_Antoniadis_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Processing of symbolic music notation via multimodal performance data: Brian Ferneyhough’s Lemma-Icon-Epigram for solo piano, phase 1</div>
	<div class='proc-auth'>Pavlos Antoniadis and Frédéric Bevilacqua</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-18'>Bibtex</span>
	<div id='abstract2016-18' class='collapse proc-abstract'>
In the “Performance Notes” to his formidable solo piano work Lemma-Icon-Epigram, British composer Brian Ferneyhough proposes a top-down learning strategy: Its first phase would consist in an “overview of gestural patterning”, before delving into the notorious rhythmic intricacies of this most complex notation. In the current paper, we propose a methodology for inferring such patterning from multimodal performance data. In particular, we have a) conducted qualitative analysis of the correlations between the performance data -an audio recording, 12-axis acceleration and gyroscope signals captured by inertial sensors, kinect video and MIDI- and the implicit annotation of pitch during a ‘sight-reading’ performance; b) observed and documented the correspondence between patterns in the gestural signals and patterns in the score annotations and c) produced joint tablature-like representations, which inscribe the gestural patterning back into the notation, while reducing the pitch material by 70-80% of the original. In addition, we have incorporated this representation in videos and interactive multimodal tablatures using the INScore. Our work is drawing from recent studies in the fields of gesture modeling and interaction. It is extending the authors’ previous work on an embodied model of navigation of complex notation and on an application for offline and real-time gestural control of complex notation by the name GesTCom. Future prospects include the probabilistic modeling of gesture-to-notation mappings, towards the design of interactive systems which learn along with the performer while cutting through textual complexity.
	</div>
	<pre id='bibtex2016-18' class='collapse proc-bibtex'>
@inproceedings{Antoniadis_tenor2016,
  Address = {Cambridge, UK},
  Author = { Pavlos Antoniadis and Frédéric Bevilacqua },
  Title = {Processing of symbolic music notation via multimodal performance data: Brian Ferneyhough’s Lemma-Icon-Epigram for solo piano, phase 1},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {127--136},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/19_Lepetit-Aimon_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>INScore expressions to compose symbolic scores</div>
	<div class='proc-auth'>Gabriel Lepetit-Aimon, Dominique Fober, Yann Orlarey and Stéphane Letz</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-19'>Bibtex</span>
	<div id='abstract2016-19' class='collapse proc-abstract'>
INScore is an environment for the design of augmented interactive music scores turned to non-conventional use of music notation. The environment allows arbitrary graphic resources to be used and composed for the music representation. It supports symbolic music notation, described using Guido Music Notation or MusicXML formats. The environment has been extended to provided score level composition using a set of operators that consistently take scores as arguments to compute new scores as output. INScore API supports now score expressions both at OSC and at scripting levels. The work is based on a previous research that solved the issues of the notation consistency across scores composition. This paper focuses on the language level and explains the different strategies to evaluate score expressions.
	</div>
	<pre id='bibtex2016-19' class='collapse proc-bibtex'>
@inproceedings{Lepetit-Aimon_tenor2016,
  Address = {Cambridge, UK},
  Author = { Gabriel Lepetit-Aimon and Dominique Fober and Yann Orlarey and Stéphane Letz },
  Title = {INScore expressions to compose symbolic scores},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {137--143},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/20_Haddad_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>OMLILY: Filling the notational gap between composition and performance</div>
	<div class='proc-auth'>Karim Haddad and Carlos Agon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-20'>Bibtex</span>
	<div id='abstract2016-20' class='collapse proc-abstract'>
This paper describes the design, the development, the usage, limitations and prospect of future development of Omlily, an OpenMusic library, for editing scores with Lilypond, using OM musical editors.
	</div>
	<pre id='bibtex2016-20' class='collapse proc-bibtex'>
@inproceedings{Haddad_tenor2016,
  Address = {Cambridge, UK},
  Author = { Karim Haddad and Carlos Agon },
  Title = {OMLILY: Filling the notational gap between composition and performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {144--150},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/21_Carey_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Netscore: an Image Server/Client Package for Transmitting Notated Music to Browser and Virtual Reality Interfaces</div>
	<div class='proc-auth'>Benedict Carey and Georg Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-21'>Bibtex</span>
	<div id='abstract2016-21' class='collapse proc-abstract'>
NetScore is an extension of the existing MaxScore pack-age (Hajdu, Didkovsky) which adds new functionality for the rapid transmission and display of music notation on remote devices through standard modern browsers with WebSocket support. This was seen as a necessary development for MaxScore due to the ubiquity of tablets and other mobile devices, among other advantages for the user, and future applications of the software. We chose a server based solution executed in Java using the Jetty library for both portability between different platforms, and scalability. Novel applications facilitated by NetScore include transmitting scores generated in Max/MSP into virtual reality interfaces and more convenient performance/ rehearsal of real-time generated music, whereby devices commonly on hand such as smartphones, tablets and laptops are used as e-scores without requiring the installation of additional software.
	</div>
	<pre id='bibtex2016-21' class='collapse proc-bibtex'>
@inproceedings{Carey_tenor2016,
  Address = {Cambridge, UK},
  Author = { Benedict Carey and Georg Hajdu },
  Title = {Netscore: an Image Server/Client Package for Transmitting Notated Music to Browser and Virtual Reality Interfaces},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {151--156},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/22_Olowe_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>FEATUR.UX: exploiting multitrack information for artistic visualization</div>
	<div class='proc-auth'>Ireti Olowe, Mathieu Barthet, Mick Grierson and Nick Bryan-Kinns</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-22'>Bibtex</span>
	<div id='abstract2016-22' class='collapse proc-abstract'>
FEATUR.UX (Feature - ous) is an audio visualization tool, currently in the process of development, which proposes to introduce a new approach to sound visualization using pre-mixed, independent multitracks and audio feature extraction. Sound visualization is usually performed using a final mix, mono or stereo track of audio. Audio feature extraction is commonly used in the field of music information retrieval to create search and recommendation systems for large music databases rather than generating live visualizations. Visualizing multitrack audio circumvents problems related to the source separation of mixed audio signals and presents an opportunity to examine interdependent relationships within and between separate streams of music. This novel approach to sound visualization aims to provide an enhanced accession to the listening experience corresponding to this use case that employs non-tonal, non-notated forms of electronic music. Findings from prior research studies focused on live performance and preliminary quantitative results from a user survey have provided the basis from which to develop a prototype that will be used throughout an iterative design study to examine the impact of using multitrack audio and audio feature extraction on sound visualization practice.
	</div>
	<pre id='bibtex2016-22' class='collapse proc-bibtex'>
@inproceedings{Olowe_tenor2016,
  Address = {Cambridge, UK},
  Author = { Ireti Olowe and Mathieu Barthet and Mick Grierson and Nick Bryan-Kinns },
  Title = {FEATUR.UX: exploiting multitrack information for artistic visualization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {157--166},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/23_Janin_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A robust algebraic framework for high-level music programming</div>
	<div class='proc-auth'>David Janin</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-23'>Bibtex</span>
	<div id='abstract2016-23' class='collapse proc-abstract'>
In this paper, we present a new algebraic model for music programming : tiled musical graphs. It is based on the idea that the definition of musical objects~: what they are, and the synchronization of these objects~: when they should be played, are two orthogonal aspects of music programming that should be kept separate although handled in a combined way. This leads to the definition of an algebra of music objects~: tiled music graphs, which can be combined by a single operator : the tiled product, that is neither sequential nor parallel but both. From a mathematical point of view, this algebra is known to be especially robust since it is an inverse monoid. Various operators such as the reset and the coreset projections derive from these algebra and turned out to be fairly useful for music modeling. From a programming point of view, it provide a high level domain specific language (DSL) that is both hierarchical and modular. This language is currently under implementation in the functional programming language Haskell. From an applicative point of view, various music modeling examples are provided to show how notes, chords, melodies, musical meters and various kind of interpretation aspects can easily and robustly be encoded in this formalism.
	</div>
	<pre id='bibtex2016-23' class='collapse proc-bibtex'>
@inproceedings{Janin_tenor2016,
  Address = {Cambridge, UK},
  Author = { David Janin },
  Title = {A robust algebraic framework for high-level music programming},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {167--175},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/24_Hope_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Possibilities of a Line: Marking the Glissando in Music</div>
	<div class='proc-auth'>Cat Hope and Michael Terren</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-24'>Bibtex</span>
	<div id='abstract2016-24' class='collapse proc-abstract'>
Despite the prevalence of the term "line" in musicology to suggest a trajectory or contour of a melody, these do not embody the line in the Euclidean sense of the word, due to the striated, stepwise nature of pitches in the chromatic scale in traditional harmonic music. The glissando, however, embodies this literal and smooth line without fragmentation and has become a way to align music with other disciplines such as architecture, mathematics and physics. In a more figurative sense, the glissando has been used in a mimetic capacity to signify an irrational, metaphysical otherness. From modernist stochasticism to science fiction film scores, the glissando has a dynamic and complex relationship with representation.<br/>Glissandi explore ideas of sonic trace, surface-ness and stasis. The notation of glissandi, in traditional Western and graphical notation as well as spectrographic visualisation, is presented as a line, its horizontal axis being a measure of time, and its vertical axis being a measure of pitch. This “pitch-time space” enables the consideration of the line as a sonic trace—of motion, gesture or time itself. This also permits the conceptualisation of the line as a surface.<br/>Some glissandi also tend to operate in structural stasis, working against the glissando's function as a sonic trace, thus the glissando-as-stasis, especially as related to drone music, is explored. Deriving inspiration from works by composers, Iannis Xeankis, James Tenney and Giacinto Scelsi, compositional attempts to combine the nature of glissando with drone in the author’s own work are de-scribed, providing an examination of examples of the way glissandi and related concepts can be notated formal-ly, rather than decoratively, in musical works.
	</div>
	<pre id='bibtex2016-24' class='collapse proc-bibtex'>
@inproceedings{Hope_tenor2016,
  Address = {Cambridge, UK},
  Author = { Cat Hope and Michael Terren },
  Title = {The Possibilities of a Line: Marking the Glissando in Music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {176--180},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/25_Hajdu_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Resurrecting a Dinosaur - The Adaptation of Clarence Barlow's Legacy Software Autobusk</div>
	<div class='proc-auth'>Georg Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-25'>Bibtex</span>
	<div id='abstract2016-25' class='collapse proc-abstract'>
This paper aims at describing efforts to conserve and further develop the legacy real-time generative music program AUTOBUSK by Clarence Barlow. We present a case study demonstrating that a simple port of 30+ year old code may not suffice to infuse new life into a project that suffered from the abandonment of the hardware it was developed on. In the process of resurrecting this dinosaur, AUTOBUSK was entirely redesigned for the popular music software environments Max and Ableton Live (via Max for Live) and renamed DJster. It comes in several incarnations, the most recent ones being DJster Autobus for Ableton Live, a device for real-time event generation and DJster Autobus Scorepion, a plugin for the MaxScore Editor. These incarnations take advantage of being embedded in current environments running on modern operating systems and have since acquired some new and useful features. As AUTOBUSK/DJster is based on universal musical principles, which Barlow formalized during the 1970’s while working on his generative piano piece Çoǧluotobüsişletmesi, its algorithms are of general applicability for composers and performers working in diverse fields such as microtonality, interactive installations and/or film music. It has therefore inspired me to lay the foundations of a shorthand notation, which we will discuss in the last section.
	</div>
	<pre id='bibtex2016-25' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2016,
  Address = {Cambridge, UK},
  Author = { Georg Hajdu },
  Title = {Resurrecting a Dinosaur - The Adaptation of Clarence Barlow's Legacy Software Autobusk},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {181--186},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/26_Angulo_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Hexaphonic Guitar Transcription and Visualization</div>
	<div class='proc-auth'>Iñigo Angulo, Sergio Giraldo and Rafael Ramirez</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-26'>Bibtex</span>
	<div id='abstract2016-26' class='collapse proc-abstract'>
Music representation has been a widely researched topic through centuries. Transcription of music through the conventional notation system has dominated the field, for the best part of the last centuries. However, this notational system often falls short of communicating the essence of music to the masses, especially to the people with no music training. Advances in signal processing and computer science over the last few decades have bridged this gap to an extent, but conveying the meaning of music remains a challenging research field. Music visualization is one such bridge, which we explore in this paper. This paper presents an approach to visually represent music produced by a guitar. To achieve this, hexaphonic guitar processing is carried out (i.e. processing each of the six strings as an independent monophonic sound source). Once this information is obtained, different approaches for representing it visually are explored. As a final result, a system is proposed to enrich the musical listening experience, by extending the perceived auditory sensations to include visual stimuli.
	</div>
	<pre id='bibtex2016-26' class='collapse proc-bibtex'>
@inproceedings{Angulo_tenor2016,
  Address = {Cambridge, UK},
  Author = { Iñigo Angulo and Sergio Giraldo and Rafael Ramirez },
  Title = {Hexaphonic Guitar Transcription and Visualization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {187--192},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/27_Eldridge_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Designing Dynamic Networked Scores to Enhance the Experience of Ensemble Music Making</div>
	<div class='proc-auth'>Alice Eldridge, Ed Hughes and Chris Kiefer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-27'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-27'>Bibtex</span>
	<div id='abstract2016-27' class='collapse proc-abstract'>
This paper describes the impetus for, and design and evaluation of, a pilot project examining the potential for digital, dynamic networked scores to enhance the experience of ensemble music making. We present a new networked score presentation system, and describe how it has evolved through a participatory design approach. Feedback has highlighted key issues concerning synchronisation between conductor, performers and notation, and autonomy and adaptation for performers; we discuss these key points and present our future plans for the project.
	</div>
	<pre id='bibtex2016-27' class='collapse proc-bibtex'>
@inproceedings{Eldridge_tenor2016,
  Address = {Cambridge, UK},
  Author = { Alice Eldridge and Ed Hughes and Chris Kiefer },
  Title = {Designing Dynamic Networked Scores to Enhance the Experience of Ensemble Music Making},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {193--199},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/28_Saito_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Conversion from Standard MIDI Files to Vertical Line Notation Scores and Automatic Decision of Piano Fingering for Beginners</div>
	<div class='proc-auth'>Yasuyuki Saito, Eita Nakamura, Riku Sato, Suguru Agata, Yuu Igarashi and Shigeki Sagayama</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-28'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-28'>Bibtex</span>
	<div id='abstract2016-28' class='collapse proc-abstract'>
This paper introduces "vertical line notation'' (VLN) of music for piano beginners, a conversion method from standard MIDI files to VLN scores, and an algorithm of automatic decision of piano fingering for it. Currently, staff notation is widely used for various instruments including piano. However, this notation often appears hard to beginners. On the other hand, VLN is intuitive and easy to understand for piano beginners since it graphically indicates the time order of notes as well as fingering. With the VLN score, piano beginners can make smooth progress with correct fingering. VLN scores are expected to help piano beginners make smooth progress with correct fingering. An issue with VLN is that it is currently created by hand with a spreadsheet software. It would be desirable to automatically produce VLN scores from existing digital scores. In this paper, we propose a method of converting standard MIDI files into VLN scores and an algorithm of automatic fingering decision for piano beginners. Some examples of practical and successful use of VLN scores are shown.
	</div>
	<pre id='bibtex2016-28' class='collapse proc-bibtex'>
@inproceedings{Saito_tenor2016,
  Address = {Cambridge, UK},
  Author = { Yasuyuki Saito and Eita Nakamura and Riku Sato and Suguru Agata and Yuu Igarashi and Shigeki Sagayama },
  Title = {Conversion from Standard MIDI Files to Vertical Line Notation Scores and Automatic Decision of Piano Fingering for Beginners},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {200--211},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/29_Ellberger_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Taxonomy and Notation of Spatialization</div>
	<div class='proc-auth'>Emile Ellberger, Germán Toro Pérez, Linda Cavaliero, Johannes Schuett, Basile Zimmermann and Giorgio Zoia</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-29'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-29'>Bibtex</span>
	<div id='abstract2016-29' class='collapse proc-abstract'>
The SSMN Spatial Taxonomy and its symbols libraries, which are the corner stone of the Spatialization Symbolic Music Notation (SSMN) project, emanates from research into composers’ attitudes in this domain. It was conceived as the basis for the development of dedicated notation and rendering tools within the SSMN project. The taxonomy is a systematic representation of all relevant features necessary to specify sound spatiality: shape and acoustic quality of the space, structure, position and movement of sound sources. It is based on single descriptors that can be combined in order to define complex spatial configurations. Descriptors can be transformed locally and globally and can be the object of structural and behavioral operations. The SSMN Spatial Taxonomy proposes a corresponding graphic symbolic representation of descriptors, operations and other functional elements facilitating the communication of creative ideas to performers and technical assistants. This paper focuses on the presentation of the taxonomy and the symbols. Additionally it describes the workflow  proposed for using symbols inside a notation software prototype developed within the project. Finally, further aspects concerning the actual and future developments of SSMN are mentioned.
	</div>
	<pre id='bibtex2016-29' class='collapse proc-bibtex'>
@inproceedings{Ellberger_tenor2016,
  Address = {Cambridge, UK},
  Author = { Emile Ellberger and Germán Toro Pérez and Linda Cavaliero and Johannes Schuett and Basile Zimmermann and Giorgio Zoia },
  Title = {Taxonomy and Notation of Spatialization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {212--219},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/30_Li_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Music Analysis Through Visualization</div>
	<div class='proc-auth'>Jia Li</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-30'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-30'>Bibtex</span>
	<div id='abstract2016-30' class='collapse proc-abstract'>
In this paper analytic visualizations are used to selectively highlight salient musical features in four modern compositions, focusing on micro or macro structures: from motivic pitch contour to large-scale form. At a glance these visualizations allow a quick grasp of the structure and assist listeners to make connections between local features and global trends. Textures obscured by musical notation become more apparent when displayed in a graphical format, such as broad registral shifts, polyphonic streaming, as well as interplay between instruments.  Pitch, timbre and voicing are plotted against time to show large-scale patterns that would otherwise be difficult to recognize in a musical score or compare between different works. Music analysis through compositional data visualization not only makes sense to musicians but also to non-musicians, facilitating collaboration and exchange with artists and technicians in other media.
	</div>
	<pre id='bibtex2016-30' class='collapse proc-bibtex'>
@inproceedings{Li_tenor2016,
  Address = {Cambridge, UK},
  Author = { Jia Li },
  Title = {Music Analysis Through Visualization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {220--225},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/31_Maestri_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notation as Temporal Instrument</div>
	<div class='proc-auth'>Eric Maestri</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-31'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-31'>Bibtex</span>
	<div id='abstract2016-31' class='collapse proc-abstract'>
In this paper the author proposes a descriptive musicological framework built on the notion of notation as temporal instrument in today's context of electronic music. The principal goal is to discuss a research categorization of musical notation that consider the performative character of musical writing in electronic music performance. In the intentions of the author, this framework could resume the multiple enhancement of the temporal dimension of notation implied by the new means of performance in electronic music.
	</div>
	<pre id='bibtex2016-31' class='collapse proc-bibtex'>
@inproceedings{Maestri_tenor2016,
  Address = {Cambridge, UK},
  Author = { Eric Maestri },
  Title = {Notation as Temporal Instrument},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {226--229},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/32_Wood_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Visual Confusion in Piano Notation</div>
	<div class='proc-auth'>Marion Wood</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-32'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-32'>Bibtex</span>
	<div id='abstract2016-32' class='collapse proc-abstract'>
This series of Reaction Time experiments investigates how quickly notes can be read from a screen and immediately executed on a MIDI keyboard. This makes it possible to study pitch reading and motor coordination in considerable detail away from the customary confounds of rhythm reading or pulse entrainment. The first experiment found that reaction times were slower in extreme keys (3#, 4#, 3b, 4b), even for very experienced sightreaders, a large effect of clef in most individuals, and other results suggesting that, in this simple paradigm at least, reading notation presents more of a difficulty to execution than motor coordination. A second experiment found, in addition, an effect of order in which the notes were presented. A clarified form of notation was devised that disambiguates visual confusion across key signatures, and to some extent across clefs. Initial results from an experiment to contrast traditional noteheads with the clearer ones found substantial improvements in both Reaction Time and accuracy for the clarified notation. The possible applications of improved notation to the wider field of piano playing are discussed.
	</div>
	<pre id='bibtex2016-32' class='collapse proc-bibtex'>
@inproceedings{Wood_tenor2016,
  Address = {Cambridge, UK},
  Author = { Marion Wood },
  Title = {Visual Confusion in Piano Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {230--239},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/33_Tahon_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>From Transcription to Signal Representation: Pitch, Rhythm and Performance</div>
	<div class='proc-auth'>Marie Tahon and Pierre-Eugène Sitchet</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-33'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-33'>Bibtex</span>
	<div id='abstract2016-33' class='collapse proc-abstract'>
Musical transcription is a real challenge, moreover in a folk music context. Signal visualization tools could be of interest for such music. The present paper is a comparison of a musical transcription and two signal representations (pitch and rhythm) applied to a song from the Gwoka repertoire. The study aims at finding similar elements and differences on pitch, rhythm and performance features in both the transcription and the signal visualization. Signal visualization is founded on vowel segmentation, and extraction of pitch and duration information. On the one hand transcription gives general characteristics on the music (harmony, tonality and rhythmic structure) and on the other hand, signal visualization gives performance-related characteristics. The main conclusion is that both approaches are of great interest for understanding such a music.
	</div>
	<pre id='bibtex2016-33' class='collapse proc-bibtex'>
@inproceedings{Tahon_tenor2016,
  Address = {Cambridge, UK},
  Author = { Marie Tahon and Pierre-Eugène Sitchet },
  Title = {From Transcription to Signal Representation: Pitch, Rhythm and Performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation - TENOR2016},
  Pages = {240--245},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
</div>
    </section>

    <section class="proc-altern" id="2015">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2015</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2015/01-Martin-LeadsheetJS.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>LEADSHEETJS: A Javascript Library for Online Lead Sheet Edition</div>
	<div class='proc-auth'>Daniel Martín, Timotée Neullas and François Pachet</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-1'>Bibtex</span>
	<div id='abstract2015-1' class='collapse proc-abstract'>
Lead sheets are routinely used in many genres of popular music. Lead sheets are music scores consisting of a melody and a chord grid. With the increase of online and portable music applications, the need for easily embeddable, adaptable and extensible lead sheet editing tools is pressing. We introduce LeadsheetJS, a javascript library for visualizing, editing and rendering lead sheets on multiple devices. LeadsheetJS provides lead sheet edition as well as support for extensions such as score augmentation and peer feedback. LeadsheetJS is a client-based component that can be embedded from arbitrary third-party websites. We describe the main design aspects of LeadsheetJS and some applications in online computer-aided composition tools.
	</div>
	<pre id='bibtex2015-1' class='collapse proc-bibtex'>
@inproceedings{Martin_tenor2015,
  Address = {Paris, France},
  Author = { Daniel Martín and Timotée Neullas and François Pachet },
  Title = {LEADSHEETJS: A Javascript Library for Online Lead Sheet Edition},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {1--10},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/02-PerezLopez-Bigram.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Bigram Editor: a score editor for the Bigram Notation</div>
	<div class='proc-auth'>Andres Perez-Lopez, Pep Alcantara-Noalles and Bertrand Kientz</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-2'>Bibtex</span>
	<div id='abstract2015-2' class='collapse proc-abstract'>
The Bigram Notation is an alternative approach to musical notation, based on the chromatic nature of Western music. As observed historically with alternative notation systems, their spread and consolidation is based on the existence of complementary and supportive tools, as ideosyncratic instruments and specific written material. Accordingly, we present the binary keyboards and the Bigram Editor, a graphical bigram score editor with automatic transcription and reproduction capabilities
	</div>
	<pre id='bibtex2015-2' class='collapse proc-bibtex'>
@inproceedings{Perez-Lopez_tenor2015,
  Address = {Paris, France},
  Author = { Andres Perez-Lopez and Pep Alcantara-Noalles and Bertrand Kientz },
  Title = {Bigram Editor: a score editor for the Bigram Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {11--17},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/03-Rodriguez-ExpressiveQuantization.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Expressive Quantization of Complex Rhythmic Structures for Automatic Music Transcription</div>
	<div class='proc-auth'>Mauricio Rodriguez</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-3'>Bibtex</span>
	<div id='abstract2015-3' class='collapse proc-abstract'>
Two quantization models for ‘expressive’ rendering of complex rhythmic patterns are discussed. A multi-nesting quantizer captures expressivity by allowing fine-grained/high-quality resolution, thus covering the automatic transcription of a wide range of rhythmic configurations, yielding from simple to rather complex music notations. A look-up table quantizer is discussed as another model to attain expressivity and musical consistency; input is quantized by comparison of 'rhythmic similarity' from a user-defined data-set or look-up 'dictionary'. Both quantizers are presented as computing assisting tools to facilitate the transcription of rhythmic structures into the symbolic domain (i.e. music notation).
	</div>
	<pre id='bibtex2015-3' class='collapse proc-bibtex'>
@inproceedings{Rodriguez_tenor2015,
  Address = {Paris, France},
  Author = { Mauricio Rodriguez },
  Title = {Expressive Quantization of Complex Rhythmic Structures for Automatic Music Transcription},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {18--22},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/04-Mauch-Tony.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Computer-aided Melody Note Transcription Using the Tony Software: Accuracy and Efficiency</div>
	<div class='proc-auth'>Matthias Mauch, Chris Cannam, Rachel Bittner, George Fazekas, Justin Salamon, Jiajie Dai, Juan Bello and Simon Dixon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-4'>Bibtex</span>
	<div id='abstract2015-4' class='collapse proc-abstract'>
We present Tony, a software tool for the interactive evaluation of melodies from monophonic audio recordings, and evaluate its usability and the accuracy of its note extraction method. The scientific study of acoustic performances of melodies, whether sung or played, requires the accurate transcription of notes and pitches. To achieve the desired transcription accuracy for a particular application, researchers manually correct results obtained by automatic methods. Tony is an interactive tool directly aimed at making this correction task efficient. It provides (a) state-of-the art algorithms for pitch and note estimation, (b) visual and auditory feedback for easy error-spotting, (c) an intelligent graphical user interface through which the user can rapidly correct estimation errors, d) extensive export functions enabling further processing in other applications. We show that Tony's built in automatic note transcription method compares favorably against existing tools. We report how long it takes to annotate recordings on a set of 96 recordings and study the effect of piece, the number of edits made and the annotator's increasing mastery of the software. Tony is Open Source software, with source code and compiled binaries for Windows and Mac OS X available from https://code.soundsoftware.ac.uk/projects/tony/.
	</div>
	<pre id='bibtex2015-4' class='collapse proc-bibtex'>
@inproceedings{Mauch_tenor2015,
  Address = {Paris, France},
  Author = { Matthias Mauch and Chris Cannam and Rachel Bittner and George Fazekas and Justin Salamon and Jiajie Dai and Juan Bello and Simon Dixon },
  Title = {Computer-aided Melody Note Transcription Using the Tony Software: Accuracy and Efficiency},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {23--30},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/05-Fischer-AnimatedNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Understanding Animated Notation</div>
	<div class='proc-auth'>Christian Fischer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-5'>Bibtex</span>
	<div id='abstract2015-5' class='collapse proc-abstract'>
Alternative notation approaches become more and more popular. Animated notation is one of them. Mainly because it seems easy to apply. On the other hand, practice shows that classically trained musicians, composers and musicologists tend to reject this kind of notation. Furthermore some musical performances based on animated notation should face the question whether a regular notation would not have been more efficient. Overall there is still a lack of knowledge and some misconceptions when it comes to animated notation and its practical application. A brief look into the development of animated notation, examples of actual fields of application and especially an examination of the visual communication process and the design of animated scores will shed a little light into the darkness.
	</div>
	<pre id='bibtex2015-5' class='collapse proc-bibtex'>
@inproceedings{Fischer_tenor2015,
  Address = {Paris, France},
  Author = { Christian Fischer },
  Title = {Understanding Animated Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {31--38},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/06-RossSmith-AtomicAMN.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>An Atomic Approach to Animated Music Notation</div>
	<div class='proc-auth'>Ryan Ross Smith</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-6'>Bibtex</span>
	<div id='abstract2015-6' class='collapse proc-abstract'>
Since the turn of the century, and in particular the last 5 years, the discourse surrounding dynamic scoring techniques and practices has increased dramatically, while leading to an increasingly disparate terminological melee. With an awareness of what implications exist in the premature analysis and theorization of an emerging field of practice, the author argues that in order to further develop a taxonomy of dynamic scoring techniques and practices, it may be useful to take a reductionist approach toward defining the various low-level elements of dynamic scoring, in the case of this paper those elements that features prominently in Animated Music Notation [AMN]. By suggesting a set of low-level elements, and isolating the actualized indicators of contact and intersection as the primary functional components of AMN, the author will propose a working definition of AMN supported by examples drawn from the author’s work and others. This definition is not intended to satisfy the broad range of dynamic scoring techniques that implement AMN, but to highlight prevalent methodologies, and to point toward the extension of existing taxonomies, specifically regard-ing their respective global functionalities.
	</div>
	<pre id='bibtex2015-6' class='collapse proc-bibtex'>
@inproceedings{RSmith_tenor2015,
  Address = {Paris, France},
  Author = { Ryan Ross Smith },
  Title = {An Atomic Approach to Animated Music Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {39--47},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/07-Hoadley-Semaphore.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>SEMAPHORE: Cross-Domain Expressive Mapping with Live Notation</div>
	<div class='proc-auth'>Richard Hoadley</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-7'>Bibtex</span>
	<div id='abstract2015-7' class='collapse proc-abstract'>
This paper describes research, investigations, creative experiments and performances undertaken by the author in collaboration with practitioners in different creative and performance domains. The research focuses on the translation of expression between these domains and its implementation using technology. This paper focuses primarily on the role of notation in this process. The domains involved include music (audio and notation), movement (dance) and text (poetry). The data arising from performers’ movements are collected and investigated; consideration is given to the use of image and graphics enabling elementary algorithmically generated dance notation.
	</div>
	<pre id='bibtex2015-7' class='collapse proc-bibtex'>
@inproceedings{Hoadley_tenor2015,
  Address = {Paris, France},
  Author = { Richard Hoadley },
  Title = {SEMAPHORE: Cross-Domain Expressive Mapping with Live Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {48--57},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/08-Hope-Decibel.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The DECIBEL Scoreplayer - A Digital Tool for Reading Graphic Notation</div>
	<div class='proc-auth'>Cat Hope, Lindsay Vickery, Aaron Wyatt and Stuart James</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-8'>Bibtex</span>
	<div id='abstract2015-8' class='collapse proc-abstract'>
These implementations are taken to be a part of the creative process. This research is about creating and investigating stimulating experiences where connections between one domain and the other are perceivable and where this connection itself provides an aesthetic experience. They are not intended to be fixed and permanent (although may remain so for the duration of a composition). The research is about creating dynamic environments, not musical instruments or general purpose tools.
	</div>
	<pre id='bibtex2015-8' class='collapse proc-bibtex'>
@inproceedings{Hope_tenor2015,
  Address = {Paris, France},
  Author = { Cat Hope and Lindsay Vickery and Aaron Wyatt and Stuart James },
  Title = {The DECIBEL Scoreplayer - A Digital Tool for Reading Graphic Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {58--69},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/11-Abdullah-SpectromorphologicalNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Spectromorphological Notation: Exploring the Uses of Timbral Visualisations in Ethnomusicological Works</div>
	<div class='proc-auth'>Hassan Abdullah Mohd and Andrew Blackburn</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-9'>Bibtex</span>
	<div id='abstract2015-9' class='collapse proc-abstract'>
Ethnomusicologists often face problem in precisely de-scribing characteristic of a sound recorded in the field-work. Written explanation normally will use the meta-phoric words to represent the timbral characteristic of a sound produced by ethnic musical instruments. But to what extend the reader will understand and perceive the sound based on the writer explanation? This study will explore all the possibilities of using timbral visualization in recognizing the Malaysian traditional musical instru-ments. We introduce an instrument recognition process in solo recordings of a set of Malay traditional instruments (gedombak), which yields a high recognition rate. A large sound profile is used in order to encompass the different sound characteristic of each instrument and evaluate the generalization abilities of the recognition process.
	</div>
	<pre id='bibtex2015-9' class='collapse proc-bibtex'>
@inproceedings{Mohd_tenor2015,
  Address = {Paris, France},
  Author = { Hassan Abdullah Mohd and Andrew Blackburn },
  Title = {Spectromorphological Notation: Exploring the Uses of Timbral Visualisations in Ethnomusicological Works},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {70--73},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/12-Bean-DENM.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>denm (dynamic environmental notation for music): Introducing a Performance-Centric Musical Interface</div>
	<div class='proc-auth'>James Bean</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-10'>Bibtex</span>
	<div id='abstract2015-10' class='collapse proc-abstract'>
denm (dynamic environmental notation for music) is an automatic notation renderer written for tablet computers in the Swift language and the Cocoa Touch Frameworks. denm is a performance-centric notation environment with many tools built into an interactive graphical representation of music. These tools, for both individual- and group-rehearsal contexts, invite multi-dimensional learning strategies to performing the complex musics written today. There are many excellent tools currently available that automatically generate musical scores, but the focus of these tools is often towards the compositional and/or theoretical end of the musical process. denm focuses its efforts on the performance end of the process, allowing performers to interact directly with the musical notation. This paper describes the impetus for the denm project, the current state of its development, and areas of continued implementation and exploration.
	</div>
	<pre id='bibtex2015-10' class='collapse proc-bibtex'>
@inproceedings{Bean_tenor2015,
  Address = {Paris, France},
  Author = { James Bean },
  Title = {denm (dynamic environmental notation for music): Introducing a Performance-Centric Musical Interface},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {74--80},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/13-Celerier-OSSIA.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>OSSIA: towards a unified interface for scoring time and interaction</div>
	<div class='proc-auth'>Jean-Michaël Celerier, Pascal Baltazar, Clément Bossut, Nicolas Vuaille, Jean-Michel Couturier and Myriam Desainte-Catherine</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-11'>Bibtex</span>
	<div id='abstract2015-11' class='collapse proc-abstract'>
The theory of interactive scores addresses the writing and execution of temporal constraints between musical objects, with the ability to describe the use of interactivity in the scores. In this paper, a notation for the use of conditional branching in interactive scores will be introduced. It is based on a high level formalism for the authoring of interactive scores developed during the course of the OSSIA research project. This formalism is meant to be at the same time easily manipulated by composers, and translatable to multiple formal methods used in interactive scores like Petri nets and timed automaton. An application programming interface that allows the interactive scores to be embedded in other software and the authoring software, i-score, will be presented.
	</div>
	<pre id='bibtex2015-11' class='collapse proc-bibtex'>
@inproceedings{Celerier_tenor2015,
  Address = {Paris, France},
  Author = { Jean-Michaël Celerier and Pascal Baltazar and Clément Bossut and Nicolas Vuaille and Jean-Michel Couturier and Myriam Desainte-Catherine },
  Title = {OSSIA: towards a unified interface for scoring time and interaction},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {81--90},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/14-DiSanto-AcousmaticScores.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Sign to write Acousmatic Scores</div>
	<div class='proc-auth'>Jean-Louis Di Santo</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-12'>Bibtex</span>
	<div id='abstract2015-12' class='collapse proc-abstract'>
This paper aims at describing an approach meant to build a sign adapted to acousmatic music and based on reduced listening. The sign, to be efficient, must obey to a certain number of requisits: precision, ergonomy, relevance... It must be both easy to use and able to create relations between sounds. A simple description of their qualities is not enough: it must be able to create or analyse sound compositions and structures, such as instrumental scores. To fulfill this purpose, it must be able to give each sound a value, in a saussurian meaning of the word. I will try to show the genealogy of my sign, how I took elements of reflexion from musical knowledge, linguistics, semiotics and aesthetics. From there I deduced the concept of minimal unit of sound applied to electroacoustic music and I created a sign combining symbols to decribe its features. I'll show how I have reorganised sound paramaters described by Schaeffer and how this sign works. At last, I will show the possibilities of writing scores sound by sound and I'll show two kinds of analysis: the analysis of a pure acousmatic work from a formal point of view and the analysis of a work for tape and instruments both from a formal and a symbolic point of view.
	</div>
	<pre id='bibtex2015-12' class='collapse proc-bibtex'>
@inproceedings{DiSanto_tenor2015,
  Address = {Paris, France},
  Author = { Jean-Louis Di Santo },
  Title = {A Sign to write Acousmatic Scores},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {91--97},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/15-Ellberger-SpacializationNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Paradigm for Scoring Spatialization Notation</div>
	<div class='proc-auth'>Emile Ellberger, Germán Toro-Perez, Johannes Schuett, Linda Cavaliero and Giorgio Zoia</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-13'>Bibtex</span>
	<div id='abstract2015-13' class='collapse proc-abstract'>
SSMN intends to develop a conceptual framework and a tool set that allows composers to integrate spatialization in musical notation from the onset of the creation process. As the composition takes form and graphic symbols ex-pressing spatialization is introduced into the score, instant audio rendering provides feedback within a surround sound configuration. In parallel, SSMN helps interpreters and audio engineers to learn and master scores that con-tain complex instructions of motion in space easily re-cognizable both in printed and animated electronic for-mat. At first a SSMN Spatial Taxonomy was established to identify key motion in space possibilities within musi-cal context; consequently, a collection of SSMN Symbols has been designed and implemented in a software library of graphical objects within MuseScoreSSMN, a dedicated editor that has been developed to allow interactive use of this library along with CWMN. In order to bridge the gap between visual elements and audio perception, an SSMN-Rendering-Engine application is at the heart of OSC inter-application communication strategies allowing the use of DAW and user-defined programming envi-ronments along with MuseScoreSSMN. A prototype has been prepared and tested by a user group consisting of composers and performers. Further research shall address other user cases integrating electroacoustic paradigms.
	</div>
	<pre id='bibtex2015-13' class='collapse proc-bibtex'>
@inproceedings{Ellberger_tenor2015,
  Address = {Paris, France},
  Author = { Emile Ellberger and Germán Toro-Perez and Johannes Schuett and Linda Cavaliero and Giorgio Zoia },
  Title = {A Paradigm for Scoring Spatialization Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {98--102},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/16-Fox-Accretion.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Accretion: Flexible, Networked Animated Music Notation For Orchestra With the Raspberry Pi</div>
	<div class='proc-auth'>Kelly Fox</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-14'>Bibtex</span>
	<div id='abstract2015-14' class='collapse proc-abstract'>
In 2014, the author set out to expand the notational potential of their generative music systems to be performed by the Rensselaer Orchestra in Troy, NY. The experiments resulted in the use of several networked Raspberry Pi devices delivering a realtime, generative Animated Music Notation to subsections of the live orchestra during performance. This paper outlines the structure of the piece, Accretion; the technical details of its implementation; and the possibilities presented by using the Raspberry Pi to deliver scored materials to performers. Ultimately, the paper seeks to make a case for adopting the Raspberry Pi as a powerful device and method of distribution/performance of Animated Music Notation.
	</div>
	<pre id='bibtex2015-14' class='collapse proc-bibtex'>
@inproceedings{Fox_tenor2015,
  Address = {Paris, France},
  Author = { Kelly Fox },
  Title = {Accretion: Flexible, Networked Animated Music Notation For Orchestra With the Raspberry Pi},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {103--108},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/17-Fujinaga-Simssa8.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Single Interface for Music Score Searching and Analysis (SIMSSA)</div>
	<div class='proc-auth'>Ichiro Fujinaga and Andrew Hankinson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-15'>Bibtex</span>
	<div id='abstract2015-15' class='collapse proc-abstract'>
Single Interface for Music Score Searching and Analysis (SIMSSA) project targets digitized music scores to de-sign a global infrastructure for searching and analyzing music scores. Specifically, we seek to provide research-ers, musicians, and others to access the contents and metadata of a large number of scores in a searchable, digital format. In this project, we are developing proto-types for processing and accessing the scores by consult-ing closely music researchers, musicians, and librarians.
	</div>
	<pre id='bibtex2015-15' class='collapse proc-bibtex'>
@inproceedings{Fujinaga_tenor2015,
  Address = {Paris, France},
  Author = { Ichiro Fujinaga and Andrew Hankinson },
  Title = {Single Interface for Music Score Searching and Analysis (SIMSSA)},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {109--115},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/18-Guyot-BrowsingSoundscapes.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Browsing soundscapes</div>
	<div class='proc-auth'>Patrice Guyot and Julien Pinquier</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-16'>Bibtex</span>
	<div id='abstract2015-16' class='collapse proc-abstract'>
Browsing soundscapes is generally based on the waveform of the audio signal or textual metadata, which may be not informative. The TM-charts provide an efficient tool to represent and compare soundscapes. However, they remain little used probably due to the human annotation they need. In this paper, we describe a new approach to compute charts of soundscapes, that we call Samocharts. The Samocharts are inspired by TM-charts and can be computed without a human annotation. We present two methods for Samochart computation. The first one is based on a segmentation of the signal from a set of predefined sound events. The second one is based on the confidence score of the detection algorithms. We describe two application cases on corpora of field recording from the CIESS and the UrbanSound projects. Finally, Samocharts provide a compact and efficient representation of soundscapes, which can be used in different kind of applications.
	</div>
	<pre id='bibtex2015-16' class='collapse proc-bibtex'>
@inproceedings{Guyot_tenor2015,
  Address = {Paris, France},
  Author = { Patrice Guyot and Julien Pinquier },
  Title = {Browsing soundscapes},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {116-123},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/20-Sapp-GraphicToSymbolic.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Graphic to Symbolic Representations of Musical Notation</div>
	<div class='proc-auth'>Craig Sapp</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-17'>Bibtex</span>
	<div id='abstract2015-17' class='collapse proc-abstract'>
This paper discusses a graphically oriented representation for music and how such representation systems can be converted into more symbolic/semantic representations of music. Specifically the representation system of the SCORE notation editor is presented along with case studies converting into other symbolic formats such as MIDI, Humdrum, Dox, MuseData, MusicXML and MEI using scorelib, an open-source library. Knowledge of the SCORE data format is useful for projects working on OMR (Optical Music Recognition) as it can be used as an intermediate layer between the raw scans and other digital music notation representation systems, as well as going in the other direction again from generalized music representations to specific graphical layouts.
	</div>
	<pre id='bibtex2015-17' class='collapse proc-bibtex'>
@inproceedings{Sapp_tenor2015,
  Address = {Paris, France},
  Author = { Craig Sapp },
  Title = {Graphic to Symbolic Representations of Musical Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {124--132},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/21-Magnusson-CodeScores.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Code scores in Live Coding</div>
	<div class='proc-auth'>Thor Magnusson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-18'>Bibtex</span>
	<div id='abstract2015-18' class='collapse proc-abstract'>
This paper explores the idea of live coding programming environments as notational systems. The improvisational practice of live coding as combining both composition and performance is introduced and selected systems are discussed. The author's Threnoscope system is then intro- duced, but this is a system that contains both descriptive and prescriptive scores that can be changed in real-time.
	</div>
	<pre id='bibtex2015-18' class='collapse proc-bibtex'>
@inproceedings{Magnusson_tenor2015,
  Address = {Paris, France},
  Author = { Thor Magnusson },
  Title = {Code scores in Live Coding},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {133--138},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/23-McCulloch-Thema.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>THEMA: A Music Notation Software Package with Integrated and Automatic Data Collection</div>
	<div class='proc-auth'>Peter McCulloch</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-19'>Bibtex</span>
	<div id='abstract2015-19' class='collapse proc-abstract'>
This paper introduces Thema, a custom music notation software environment designed to automatically and transparently capture quantitative data into a relational database. The majority of research into musical creativity is qualitative in nature, and this software addresses several areas, such as search and improvisational data, which are not well-addressed in the qualitative toolkit. Thema's database provides advantages over ad hoc file collection mechanisms by providing integrated search; the software also is able to consistently identify musical material via automatically assigned identification codes, and this provides a useful supplement to content-based search. In 2013, a study was conducted of ten graduate-level composers using Thema, and the dataset from this study was used to develop new analytical tools for examining compositional data.
	</div>
	<pre id='bibtex2015-19' class='collapse proc-bibtex'>
@inproceedings{McCulloch_tenor2015,
  Address = {Paris, France},
  Author = { Peter McCulloch },
  Title = {THEMA: A Music Notation Software Package with Integrated and Automatic Data Collection},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {139--145},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/24-Spreadbury-SMuFL.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Standard Music Font Layout (SMuFL)</div>
	<div class='proc-auth'>Daniel Spreadbury and Robert Piéchaud</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-20'>Bibtex</span>
	<div id='abstract2015-20' class='collapse proc-abstract'>
Digital typefaces containing the symbols used in Western common music notation have been in use for 30 years, but the development of the repertoire of symbols that are included, their assignment to code points, and design considerations such as glyph metrics and registration, have been rather ad hoc. The Standard Music Font Layout (SMuFL) establishes guidelines for all of these areas, and a reference implementation is available in the Bravura font family. Software developers and font designers alike are beginning to develop implementations of SMuFL in their products, and benefits including easier data interchange, interoperability of fonts with a variety of software packages, are already being felt.
	</div>
	<pre id='bibtex2015-20' class='collapse proc-bibtex'>
@inproceedings{Spreadbury_tenor2015,
  Address = {Paris, France},
  Author = { Daniel Spreadbury and Robert Piéchaud },
  Title = {Standard Music Font Layout (SMuFL)},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {146--153},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/25-Gottfried-SVG-OSC-Notation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>SVG to OSC Transcoding as a Platform for Notational Praxis and Electronic Performance</div>
	<div class='proc-auth'>Rama Gottfried</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-21'>Bibtex</span>
	<div id='abstract2015-21' class='collapse proc-abstract'>
In this paper presents a case study in the creation of an open notational framework for experimentation with new types of notation that may be applied in a wide variety of contexts. By separating the visual representation from the act of rendering, a space for an interpretive grammar layer is created in which symbolic notation may be translated into a format that is understood by another form of rendering. Technical details of preliminary work on this topic is presented, using Scalable Vector Graphics (SVG) as a container for hierarchical score information which is then transcoded to OpenSoundControl (OSC) as an intermediate data processing before being passed to a given rendering context.
	</div>
	<pre id='bibtex2015-21' class='collapse proc-bibtex'>
@inproceedings{Gottfried_tenor2015,
  Address = {Paris, France},
  Author = { Rama Gottfried },
  Title = {SVG to OSC Transcoding as a Platform for Notational Praxis and Electronic Performance},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {154--161},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/26-Baca-ABJAD.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Abjad: An Open-source Software System for Formalized Score Control</div>
	<div class='proc-auth'>Trevor Bača, Josiah Oberholtzer, Jeffrey Treviño and Víctor Adán</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-22'>Bibtex</span>
	<div id='abstract2015-22' class='collapse proc-abstract'>
The Abjad API for Formalized Score Control extends the Python programming language with an open-source, object-oriented model of common-practice music notation that enables composers to build scores through the aggregation of elemental notation objects. A summary of widely used notation systems’ intended uses motivates a discussion of system design priorities via examples of system use.
	</div>
	<pre id='bibtex2015-22' class='collapse proc-bibtex'>
@inproceedings{Baca_tenor2015,
  Address = {Paris, France},
  Author = { Trevor Bača and Josiah Oberholtzer and Jeffrey Treviño and Víctor Adán },
  Title = {Abjad: An Open-source Software System for Formalized Score Control},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {162--169},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/27-Laurenzi-DynamicLevels.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Notation of Dynamic Levels in the Performance of Electronic Music</div>
	<div class='proc-auth'>Carlo Laurenzi and Marco Stroppa</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-23'>Bibtex</span>
	<div id='abstract2015-23' class='collapse proc-abstract'>
The “sound diffusion” (or “sound projection”), that is, “the projection and the spreading of sound in an acoustic space for a group of listeners”[1], of works for solo electronics or for acoustic instruments and electronics (so called, “mixed pieces”), has always raised the issue of notating the levels to be reproduced during a concert or the correct balance between the electronics and the instruments. If, in the last decades, some attempts were made by few composers or computer-music designers, mostly in the form of scores, none of these managed to establish a common practice. In addition, little theoretical work has been done so far to address the performative aspects of a piece, that is, to provide just the useful information to the person in charge of the sound diffusion. Through the discussion of three historical examples and the analysis of two experiences we developed, we will try to identify some possibly general solutions that could be adopted independently on the aesthetic or tech-nological choices of a given piece.
	</div>
	<pre id='bibtex2015-23' class='collapse proc-bibtex'>
@inproceedings{Laurenzi_tenor2015,
  Address = {Paris, France},
  Author = { Carlo Laurenzi and Marco Stroppa },
  Title = {The Notation of Dynamic Levels in the Performance of Electronic Music},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {170--179},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/28-Hirst-PerceptualModels.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Automated Representations of Temporal Aspects of Electroacoustic Music: Recent Experiments Using Perceptual Models</div>
	<div class='proc-auth'>David Hirst</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-24'>Bibtex</span>
	<div id='abstract2015-24' class='collapse proc-abstract'>
Within this paper we firstly examine the determination of a number of temporal aspects of Electroacoustic Music, and their representations. Then various automated segmentation methods, for Harrison’s Unsound Objects, are investigated. We find the multi-granular approach outlined by Lartillot et al, combined with the use of MFCCs, is a very efficient and salient segmentation strategy for music structured predominantly according to timbre. Further, the ‘Contrast’ parameter is both versatile and effective in determining the granularity of segmentation.
	</div>
	<pre id='bibtex2015-24' class='collapse proc-bibtex'>
@inproceedings{Hirst_tenor2015,
  Address = {Paris, France},
  Author = { David Hirst },
  Title = {Automated Representations of Temporal Aspects of Electroacoustic Music: Recent Experiments Using Perceptual Models},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {180--189},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/29-Nash-CognitiveDimension.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Cognitive Dimensions of Music Notations</div>
	<div class='proc-auth'>Chris Nash</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-25'>Bibtex</span>
	<div id='abstract2015-25' class='collapse proc-abstract'>
This paper presents and adapts the Cognitive Dimensions of Notations framework (Green and Petre, 1996) for use in designing and analysing notations (and user interfaces) in both digital and traditional music practice and study. Originally developed to research the psychology of programming languages, the framework has since found wider use in both general HCI and music. The paper provides an overview of the framework, its application, and a detailed account of the core cognitive dimensions, each discussed in the context of three music scenarios: the score, Max/MSP, and sequencer/DAW software. Qualitative and quantitative methodologies for applying the framework are presented in closing, highlighting directions for further development of the framework.
	</div>
	<pre id='bibtex2015-25' class='collapse proc-bibtex'>
@inproceedings{Nash_tenor2015,
  Address = {Paris, France},
  Author = { Chris Nash },
  Title = {The Cognitive Dimensions of Music Notations},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {190--202},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/30-Bacon-TufteDesign.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Tufte Design Concepts in Musical Score Creation</div>
	<div class='proc-auth'>Benjamin Bacon and Marcelo Wanderley</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-26'>Bibtex</span>
	<div id='abstract2015-26' class='collapse proc-abstract'>
This paper introduces several examples of utilizing the information design concepts of Edward Tufte in musical no- tation and score design. Tufte is generally considered a modern pioneer in the field of information design. With several authoritative texts, Tufte’s work displays countless examples of successful and unsuccessful attempts of displaying information while also offering a few personal redesigns of especially troubled instances. Overall, Tufte reveals interesting concepts which could be useful when applied to designing musical notation systems. The author presents three personal notational examples which have been aided by Tufte’s work. Information design is a vast multidisciplinary field which could provide composers and musicians with an abundance of technical approaches to complex notational challenges.
	</div>
	<pre id='bibtex2015-26' class='collapse proc-bibtex'>
@inproceedings{Bacon_tenor2015,
  Address = {Paris, France},
  Author = { Benjamin Bacon and Marcelo Wanderley },
  Title = {Tufte Design Concepts in Musical Score Creation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {203--209},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/31-Maestri-NotationAsInstrument.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notation as Instrument: From Representation to Enaction</div>
	<div class='proc-auth'>Eric Maestri and Pavlos Antoniadis</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-27'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-27'>Bibtex</span>
	<div id='abstract2015-27' class='collapse proc-abstract'>
The paper explores the hybridization of notation and instrument as a cognitive movement from representation to enaction. Features of such hybridization are latent in every notation, as a mix of descriptive and prescriptive functions. Current advances in the fields of computer music representation (interactive scores) and New Interfaces for Musical Expression, with precedents in graphic and action-oriented scores, are turning notation into a shared multimodal platform between composer and performer, liquidizing the limit between notation and instrument. We will present this dynamic rapport between scores and interfaces (haptic interactions, INScore, GesTCom, post-Klaus K. Hübler tablature notations of decoupled action-structures) in the light of theoretical models (enaction defined as navigation of affordances from the field of embodied and extended cognition, Leman’s action-reaction cycle extended from instrument-making into notation, Veitl’s conception of software as tablature, Atau Tanaka’s definition of instruments as open-ended systems etc.). We are following an explicit line from new interfaces involving notation back to graphic and action-oriented scores, considering them in the theoretical framework of enaction.
	</div>
	<pre id='bibtex2015-27' class='collapse proc-bibtex'>
@inproceedings{Maestri_tenor2015,
  Address = {Paris, France},
  Author = { Eric Maestri and Pavlos Antoniadis },
  Title = {Notation as Instrument: From Representation to Enaction},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {210--217},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/32-Blackburn-TimbralNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Timbral Notation from Spectrograms: Notating the Un-Notatable?</div>
	<div class='proc-auth'>Andrew Blackburn and Jean Penny</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-28'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-28'>Bibtex</span>
	<div id='abstract2015-28' class='collapse proc-abstract'>
This paper outlines the background to a research project currently underway in Malaysia that, through spectography seeks to find models that might assist in the future development of a timbral notation. Located within the music creation and performance practices of the researchers, the project has elements of interculturality which both enrich and inform the research. The authors consider the nature of a music score, the explicit and implicit information it carries, and how this impacts on the models being developed. The understandings elicited to date are not only located in music practice, but are underpinned and supported by the theoretical works of a number of recent philosophers and theorists. The overall research project is broken down into smaller discrete sub-projects which are discussed, and the findings of each sub-project are then contextualized in the wider project. These findings include a discussion of the score as artifact and the potential contained within it. The finding in two sub-projects of a possible model of gestural notation, albeit with different purposes, suggests this as a further avenue of research. The paper concludes with some suggestions of future research areas that will follow on from the models of timbral notation being explored in this project.
	</div>
	<pre id='bibtex2015-28' class='collapse proc-bibtex'>
@inproceedings{Blackburn_tenor2015,
  Address = {Paris, France},
  Author = { Andrew Blackburn and Jean Penny },
  Title = {Timbral Notation from Spectrograms: Notating the Un-Notatable?},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {218--225},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/33-Rebelo-CompositionWithGraphics.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Composing with Graphics: Revealing the Compositional Process through Performance</div>
	<div class='proc-auth'>Pedro Rebelo</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-29'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-29'>Bibtex</span>
	<div id='abstract2015-29' class='collapse proc-abstract'>
The research presented here is product of a practice-based process that primarily generates knowledge through col-laboration and exchange in performance situations. It is this collaboration and exchange with various musicians over a period of five years that constitutes a body of practice that is here reflected upon. The paper focuses on non-instructional graphic scores and presents some insights based on performances of works by the author. We address how composition processes are revealed in graphic scores by looking at the conditions of decision making at the point of preparing a performance. We argue that three key elements are at play in the interpretation of these types of graphic scores: performance practice, mapping and musical form. By reflecting particularly on the work Cipher Series (Rebelo, 2010) we offer insights into the strategies for approaching the performance of graphic scores that go beyond symbolic codification.
	</div>
	<pre id='bibtex2015-29' class='collapse proc-bibtex'>
@inproceedings{Rebelo_tenor2015,
  Address = {Paris, France},
  Author = { Pedro Rebelo },
  Title = {Composing with Graphics: Revealing the Compositional Process through Performance},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {226--230},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/34-BaptisteJessel-NotationForBlindPeople.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Access to musical information for blind people</div>
	<div class='proc-auth'>Nadine Baptiste</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-30'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-30'>Bibtex</span>
	<div id='abstract2015-30' class='collapse proc-abstract'>
In this paper we describe our approach to help blind people to access musical information. Guidelines of our approach are centered on information accessibility according to user disability. We present the process which permits to code and transform musical information to be read, treat and analyze by a Blind musician. We focus our proposition on the various level of description of the score done by several code and we exploit and describe existing results like BMML (Braille Music Markup Lan-guage) defined during Contrapunctus European project. We describe and comment different scenarios using existing free transformation modules and software to obtain a score in BMML in order to be read and manipulate by a Blind people with BMR (Braille Music Reader) and the recommendation and tutorials propositions done during the Musi4vip European project.
	</div>
	<pre id='bibtex2015-30' class='collapse proc-bibtex'>
@inproceedings{Baptiste_tenor2015,
  Address = {Paris, France},
  Author = { Nadine Baptiste },
  Title = {Access to musical information for blind people},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {231--235},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/35-Burloiu-Ascograph.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Non-overlapping, Time-coherent Visualisation of Action Commands in the AscoGraph Interactive Music User Interface</div>
	<div class='proc-auth'>Grigore Burloiu and Arshia Cont</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-31'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-31'>Bibtex</span>
	<div id='abstract2015-31' class='collapse proc-abstract'>
Integrated authoring and performing of Mixed Music scores, where musicians interact dynamically with computer-controlled electronics, is enabled by the Antescofo state-of-the-art software package. Composers are able to plan computerised actions through a dedicated programming language, and performances are then synchronised in real time. AscoGraph is the dedicated graphical interface that allows users to configure Antescofo behaviours and visualise their layout over a Mixed Music score. This paper presents developments in the direction of increased clarity and coherence of AscoGraph’s visualisation of computerised action scores. Algorithms for efficient automatic stacking of time-overlapping action blocks are presented, as well as a simplified model for displaying atomic actions. The paper presents the improvements in score readability achieved, as well as the challenges faced towards a complete representation of dynamic mixed scores in the AscoGraph visual environment.
	</div>
	<pre id='bibtex2015-31' class='collapse proc-bibtex'>
@inproceedings{Burloiu_tenor2015,
  Address = {Paris, France},
  Author = { Grigore Burloiu and Arshia Cont },
  Title = {Non-overlapping, Time-coherent Visualisation of Action Commands in the AscoGraph Interactive Music User Interface},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {236--240},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/36-Hajdu-DynamicNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Dynamic Notation – A Solution to the Conundrum of Non-Standard Music Practice</div>
	<div class='proc-auth'>Georg Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-32'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-32'>Bibtex</span>
	<div id='abstract2015-32' class='collapse proc-abstract'>
This paper discusses dynamic notation—a method allowing, in a notation environment, instant switching between different views or notation styles, thus creating a common ground for practitioners of non-standard music, such as composers, performers, conductors and scholars. A plugin structure for different notation styles based on a set of maps and queries executed during note entry and rendering, affecting music glyph choice and placement was implemented in the MaxScore Editor—a notation editor designed to run in Max or Ableton Live. We will give an in-depth analysis of the methods used for equidistant scales, non-octave tunings, music in just intonation as well as for instrument-specific layouts and will con-clude with a description of a scenario in which dynamic notation was used for the transcription and performance of Alexander Scriabin’s piano poem Vers la Flamme op. 72 by an ensemble of acoustic Bohlen-Pierce instruments.
	</div>
	<pre id='bibtex2015-32' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2015,
  Address = {Paris, France},
  Author = { Georg Hajdu },
  Title = {Dynamic Notation – A Solution to the Conundrum of Non-Standard Music Practice},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation - TENOR2015},
  Pages = {241--248},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
</div>
    </section>


    <aside class="bg-dark">
        <div class="container text-center">
            <div class="call-to-action">
                <a class ="page-scroll" href="#page-top"><img src="img/TENORgb.png"  width=150></a>
            </div>
        </div>
    </aside>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="vendor/scrollreveal/scrollreveal.min.js"></script>
    <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/creative.min.js"></script>

</body>

</html>
