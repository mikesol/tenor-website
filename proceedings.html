<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>TENOR - International Conference on Technologies for Music Notation and Representation</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>

    <!-- Plugin CSS -->
    <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/creative.min.css" rel="stylesheet">
    <link href="css/tenor.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <!--i class="fa fa-bars"></i-->
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="index.html">TENOR</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="#2021">2021</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2020">2020</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2019">2019</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2018">2018</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2017">2017</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2016">2016</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#2015">2015</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header>
        <div class="header-content">
            <div class="header-content-inner">
                <a href="index.html"><img src="img/TENORg.png" width=250></a>
                <hr>
                <h1 id="homeHeading">Proceedings</h1>
            </div>
        </div>
    </header>

 <!-- ========================================================================= -->
 <!-- ========================================================================= -->

    <section class="proc-altern" id="2021">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2021</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>

<div class='container'>
<div class='row tenor-paper'>
  <a href='proceedings/TENOR2020-21_Proceedings.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
  <div class='proc-title'>FULL TENOR'20/21 PROCEEDINGS</div>
  <span class='proc-button' data-toggle='collapse' data-target='#bibtex2021'>Bibtex</span>
  | <a href="proceedings/bibtex2021.bib" class="tenor-bibtex">.bib</a>

  <pre id='bibtex2021' class='collapse proc-bibtex'>
@book{tenor2021,
  Address = {Hamburg, Germany},
  Title = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}}
  </pre>
</div>
<hr>
</div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2021/01_Zhu_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Ratioscore: A Text-Based System for Just Intonation</div>
	<div class='proc-auth'>Julie Zhu and Craig Stuart Sapp</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-1'>Bibtex</span>
	<div id='abstract2021-1' class='collapse proc-abstract'>
Ratioscore is a text-based musical score representation system that expresses pitches as integer ratios, making it particularly useful for working with just intonation. We also provide open-source software to compile Ratioscores into Standard MIDI files as well as a website front-end that renders these MIDI files into MP3 files for online listen- ing and downloading. Up to 15 voices/instruments can sound simultaneously with independent tuning control as well as independent glissandi in each voice within one octave of their starting pitch. Ratioscores are encoded using the Humdrum data format, which allows for basic data manipulation and transformation of the score, such as repeating segments of music, selecting between multiple timelines or sharing dynamics between different voices. We illustrate the use of Ratioscore as a prototyping system for composing a string quartet as a proof of concept. Ratioscore is particularly suited for algorithmic composition, both within and outside the traditional Western notation framework. 
	</div>
	<pre id='bibtex2021-1' class='collapse proc-bibtex'>
@inproceedings{Julie Zhu_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Julie Zhu and Craig Stuart Sapp },
  Title = {Ratioscore: A Text-Based System for Just Intonation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {205-211},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/02_Grunbacher_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Using Music Features for Managing Revisions and Variants in Music Notation Software</div>
	<div class='proc-auth'>Paul Grünbacher, Rudolf Hanl, and Lukas Linsbauer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-2'>Bibtex</span>
	<div id='abstract2021-2' class='collapse proc-abstract'>
"Music engravers need to manage both revisions and variants of digital music artifacts created with music notation software. However, existing version control systems such as Git fail to manage fine-grained revisions and variants in a uniform manner. This paper presents an approach that uses music features and applies a variation control system in the domain of music notation. In particular, we extended the variation control system ECCO to support the evolution of digital music artifacts encoded in LilyPond. We illustrate music features using a running example. We present basic feature-oriented workflows and discuss the architecture and implementation of our LilyECCO tool. We further present a preliminary evaluation based on an existing LilyPond music artifact.
	</div>
	<pre id='bibtex2021-2' class='collapse proc-bibtex'>
@inproceedings{Paul Grünbacher_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Paul Grünbacher and Rudolf Hanl and and Lukas Linsbauer },
  Title = {Using Music Features for Managing Revisions and Variants in Music Notation Software},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {212-220},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/03_Fober_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Web-Based Environment Embedding Signal Processing in Musical Scores</div>
	<div class='proc-auth'>Dominique Fober, Yann Orlarey, Stéphane Letz, and Romain Michon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-3'>Bibtex</span>
	<div id='abstract2021-3' class='collapse proc-abstract'>
"We present an online environment for the design of musical scores, also allowing for the embedding of signal processors and hence the publication of electronic works. This environment is part of the INScore project. Its latest version has been transcribed to WebAssembly/Javascript to provide in a web browser the same features as in its native counterpart: the diversity of music representations supported by INScore, the interaction capabilities and all the dynamic aspects of the score. After some historical elements about distributed musical scores, we will provide some reminders about the INScore project and its associated description language. We will then describe the architecture of the system and the choices made for its portability to the Web. Then, we will present the extensions specific to the Javascript version and in particular the support of signal processing objects. Finally, we will show how INScore’s communication system has been extended to allow online musical score control from a native version of INScore, paving the way for real-time performance on the web. 
	</div>
	<pre id='bibtex2021-3' class='collapse proc-bibtex'>
@inproceedings{Dominique Fober_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Dominique Fober and Yann Orlarey and Stéphane Letz and and Romain Michon },
  Title = {A Web-Based Environment Embedding Signal Processing in Musical Scores},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {221-226},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/04_Andersen_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Indra: A Virtual Score Platform for Networked Musical Performance</div>
	<div class='proc-auth'>Drake Andersen</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-4'>Bibtex</span>
	<div id='abstract2021-4' class='collapse proc-abstract'>
"This paper introduces Indra, a Max-based virtual score platform for networked musical performance. Indra allows a conductor to improvise with an ensemble over a local area network by determining the notation that appears on performers’ screens in real time. Musical compositions for the Indra platform consist of short encoded or image-based notation clips that are tagged with customizable metadata corresponding to musical qualities. The conductor uses the metadata to filter clips, determining the general qualities of the musical texture while the software cycles through clips that meet the filter criteria. Indra is designed to be accessible and adaptable for musicians working in diverse styles and numerous performance contexts. 
	</div>
	<pre id='bibtex2021-4' class='collapse proc-bibtex'>
@inproceedings{Drake Andersen_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Drake Andersen },
  Title = {Indra: A Virtual Score Platform for Networked Musical Performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {227-234},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/05_Bresson_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Score Objects in OM#</div>
	<div class='proc-auth'>Jean Bresson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-5'>Bibtex</span>
	<div id='abstract2021-5' class='collapse proc-abstract'>
This paper is an overview of the new score objects and editors available in the OM# visual programming and computer-assisted composition environment. 
	</div>
	<pre id='bibtex2021-5' class='collapse proc-bibtex'>
@inproceedings{Jean Bresson_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Jean Bresson },
  Title = {Score Objects in OM#},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {235-239},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/06_Calandra_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Multi-Scale Oracle and Automated Representation of Formal Diagrams Based on the Cognitive Algorithm</div>
	<div class='proc-auth'>Joséphine Calandra, Jean-Marc Chouvel, and Myriam Desainte-Catherine</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-6'>Bibtex</span>
	<div id='abstract2021-6' class='collapse proc-abstract'>
"This article deals with the automatic representation of formal diagrams, which corresponds to a paradigmatic analysis of the musical work which is being listened to. These diagrams represent musical materials as a function of time and are initially obtained from the audio signal, applying a Cognitive Algorithm. In this article, we focus on the second step of the algorithm, as such we assume that the first step, analyzing and labeling the audio signal, has been done. Thus, we propose to analyze predefined materials given as a string. Then we develop the automatic creation of all the formal diagrams of higher levels that result from it. The structuration of the sequences of materials of the lower level constructs the formal diagrams of higher levels. The structured characters which are gathered then represent a higher-level material. Therefore, we present the Multi-scale Oracle: a data structure that stores and connects the different levels and materials. Thus, a character string given as input of the system produces a superposition of formal diagrams as a function of various structuring parameters. As the hierarchical formal diagrams offer a new representation of music, we suggest the musicologists could use these diagrams for analysis. 
	</div>
	<pre id='bibtex2021-6' class='collapse proc-bibtex'>
@inproceedings{Joséphine Calandra_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Joséphine Calandra and Jean-Marc Chouvel and and Myriam Desainte-Catherine },
  Title = {Multi-Scale Oracle and Automated Representation of Formal Diagrams Based on the Cognitive Algorithm},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {240-250},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/07_Bell_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Distributed Notation in the Browser, an Overview</div>
	<div class='proc-auth'>Jonathan Bell</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-7'>Bibtex</span>
	<div id='abstract2021-7' class='collapse proc-abstract'>
"This paper endeavours to discuss a few available technologies for musical notation, from a user’s point of view, focusing on “distributed notation”: musical notation rendered in real time to multiple devices simultaneously. The rapid evolution of browsers and the cheaper cost of heterogeneous (cross-platform) systems inclines us to narrow down the scope to browser-based solutions. The overview recalls a few key concepts of the JavaScript ecosystem, typically addressed to composers with little background in web development. The survey then compares three frameworks: INScore (INScoreWeb), DRAWSOCKET, and SmartVox, focusing on their respective approach to software architecture/implementation, as well as their “higher” user level. After highlighting the convergence points between INScore and DRAWSOCKET - but also their own specificity, such as INScore’s time model, or DRAWSOCKET’s API, the paper concludes with a case study: the Tenor 21 choral concert. 
	</div>
	<pre id='bibtex2021-7' class='collapse proc-bibtex'>
@inproceedings{Jonathan Bell_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Jonathan Bell },
  Title = {Distributed Notation in the Browser, an Overview},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {251-259},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/08_Nash_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Automatic for the People: Crowd-driven Generative Scores Using Machine Vision and Manhattan</div>
	<div class='proc-auth'>Chris Nash</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-8'>Bibtex</span>
	<div id='abstract2021-8' class='collapse proc-abstract'>
"This paper details a workshop and optional public installation based on the development of situational scores that combine music notation, AI, and code to create dynamic interactive art driven by the realtime movements of objects and people in a live scene, such as crowds on a public concourse. The approach presented here uses machine vision to process a video feed from a scene, from which detected objects and people are input to the Manhattan digital music notation, which integrates music editing and programming practices to support the creation of sophisticated musical scores that combine static, algorithmic, or reactive musical parts. 
	</div>
	<pre id='bibtex2021-8' class='collapse proc-bibtex'>
@inproceedings{Chris Nash_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Chris Nash },
  Title = {Automatic for the People: Crowd-driven Generative Scores Using Machine Vision and Manhattan},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {260-264},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2021/09_Felten_tenor21.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Autoconductor: Synchronizing Graphic Scores, Multi-Channel sound and Video Files</div>
	<div class='proc-auth'>Lothar Felten and Christian Klinkenberg</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2021-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2021-9'>Bibtex</span>
	<div id='abstract2021-9' class='collapse proc-abstract'>
In this paper, a networked score display system which synchronizes graphical notation, precise pitch notation and video with multi-channel audio is presented. The software was purpose built for the project The Glacier - Opera 2.0 composed by Christian Klinkenberg.
	</div>
	<pre id='bibtex2021-9' class='collapse proc-bibtex'>
@inproceedings{Lothar Felten_tenor2021,
  Address = {Hamburg, Germany},
  Author = { Lothar Felten and Christian Klinkenberg },
  Title = {Autoconductor: Synchronizing Graphic Scores, Multi-Channel sound and Video Files},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {265-269},
  Year = {2021},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
</div>
</section>

 <!-- ========================================================================= -->

    <section id="2020">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2020</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>

<div class='container'>
<div class='row tenor-paper'>
  <a href='proceedings/2021/TENOR2020-21_Proceedings.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
  <div class='proc-title'>FULL TENOR'20/21 PROCEEDINGS</div>
  <span class='proc-button' data-toggle='collapse' data-target='#bibtex2020'>Bibtex</span>
  | <a href="proceedings/bibtex2020.bib" class="tenor-bibtex">.bib</a>

  <pre id='bibtex2020' class='collapse proc-bibtex'>
@book{tenor2020,
  Address = {Hamburg, Germany},
  Title = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}}
  </pre>
</div>
<hr>
</div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2020/01_Lepper_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Crowded Staves — Rules for Semantic and Style of Conventional Multiple-Voices-Per-Staff Musical Notation</div>
	<div class='proc-auth'>Markus Lepper, Michael Oehler, Hartmuth Kinzler, Baltasar Trancón</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-1'>Bibtex</span>
	<div id='abstract2020-1' class='collapse proc-abstract'>
In many variants of Common Western Notation (CWN) more than two voices can be notated together in one staff. Reading this kind of multi-voice notation implies complicated parsing decisions, taken by the trained musician’s brain in most cases non-knowingly. This article makes them explicit, supposing a theoretical maximum of information retrieval and formal consistency. 
	</div>
	<pre id='bibtex2020-1' class='collapse proc-bibtex'>
@inproceedings{Lepper_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Markus Lepper and Michael Oehler and Hartmuth Kinzler and Baltasar Trancón },
  Title = {Crowded Staves — Rules for Semantic and Style of Conventional Multiple-Voices-Per-Staff Musical Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {1-12},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/02_Hayden_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>NEXUS: Live Notation as a Hybrid Composition and Performance Tool</div>
	<div class='proc-auth'>Sam Hayden, Mieko Kanno</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-2'>Bibtex</span>
	<div id='abstract2020-2' class='collapse proc-abstract'>
The NEXUS live notation system, the latest product of the Hayden-Kanno collaboration, contrasts with their previous projects which utilised live DSP and synthesis. NEXUS is first discussed in the contexts of a comparison of Kanno’s experience of performing solo violin works involving the live generation of music in both the audio and symbolic domains, and the affordances of Common Practice Notation for generative music. As with previous Hayden-Kanno projects, the main goal is the creation of a musical work which is fluid and spontaneous, both in its global form and specifics of detail, yet maintains a sonic consistency and coherence, but now in the symbolic domain. The implications of performer reading and interpretation for system design are explored. The second half of the paper outlines the main functions of the Max patch, how GMN code is generated for rendering as CPN in INScore during the performance, and, of the performer GUI which constrains the stochastic processes underlying the generation of specific musical parameters, general textual characteristics, and global formal shaping. The challenge was to formalize Hayden’s compositional procedures so the generated notations retain a musical identity and interest, whilst leaving space for Kanno’s interpretative decisions and being technically simple enough to be sightreadable. The uses of the system for hybrid performance and compositional applications are discussed, and some directions for future development. 
	</div>
	<pre id='bibtex2020-2' class='collapse proc-bibtex'>
@inproceedings{Hayden_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Sam Hayden and Mieko Kanno },
  Title = {NEXUS: Live Notation as a Hybrid Composition and Performance Tool},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {13-23},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/03_Nuno_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Representation of Harmonies on the Harmonic Wheel</div>
	<div class='proc-auth'>Luis Nuño</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-3'>Bibtex</span>
	<div id='abstract2020-3' class='collapse proc-abstract'>
The Tonnetz is a useful tool for representing musical excerpts or full pieces containing mainly major and minor triads. However, when a musical composition contains dissonant triads or higher-order chords, it can only give a limited representation of it. The Harmonic Wheel is a physical tool that combines a Tonnetz transformed into a polar grid with a plastic disc containing the lines that define the major, harmonic and melodic minor scales, together with the scale degrees and the symbols of the corresponding seventh chords. This way, it allows to represent a large variety of musical works, including both triads and seventh chords, as well as to find the chords that are common to different keys. To show its main characteristics and advantages, several examples are given from different musical styles. In all cases, the representations obtained are simple and compact, and therefore easy to memorize, which makes the Harmonic Wheel a powerful and versatile tool for analyzing and composing music, as well as providing an efficient mnemonic notation. 
	</div>
	<pre id='bibtex2020-3' class='collapse proc-bibtex'>
@inproceedings{Nuno_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Luis Nuño },
  Title = {Representation of Harmonies on the Harmonic Wheel},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {24-32},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/04_Rodriguez_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Resurfacing Mechanics and Action in Music Notation: The Musicwriter</div>
	<div class='proc-auth'>Mauricio Rodriguez</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-4'>Bibtex</span>
	<div id='abstract2020-4' class='collapse proc-abstract'>
This text discusses the compositional use of the Musicwriter, a music notation device used after old engraving practices such as lithographic notation and metal printing blocks for music printing, but discontinued before modern digital notation. After a short description of this singular device, the author presents his ongoing composition/engraving project: ‘Meaning The Score’, a series of tyscores (or typed scores) performed using the Musicwriter; the notation of this series is conceived as an emergent property of the performative interaction with the Musicwriter, notation that is later reinterpreted by musicians that react to both, the live-typeset notation and the composer’s performance that created the score in the first place. 
	</div>
	<pre id='bibtex2020-4' class='collapse proc-bibtex'>
@inproceedings{Rodriguez_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Mauricio Rodriguez },
  Title = {Resurfacing Mechanics and Action in Music Notation: The Musicwriter},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {33-36},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/05_Trubert_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notation of Gesture and Modelling : The process of composition of Mots de jeu</div>
	<div class='proc-auth'>Jean-François Trubert, Alireza Farhang.</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-5'>Bibtex</span>
	<div id='abstract2020-5' class='collapse proc-abstract'>
This paper aims to present the process of composition of a piece in which the musical material integrates syntactic and semantic dimensions of a poetic language. Modeling the semantics of speech gestures through graphical notation and using formant synthesis to generate the electronic sounds are also the subjects that will be explained in order to give an outline about the way poetry and prosody contribute to the microstructure and macrostructure of a vocal piece. 
	</div>
	<pre id='bibtex2020-5' class='collapse proc-bibtex'>
@inproceedings{Trubert_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Jean-François Trubert and Alireza Farhang. },
  Title = {Notation of Gesture and Modelling : The process of composition of Mots de jeu},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {37-48},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/06_Kalonaris_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Scheme for Music Interaction Design and Notation Based on Dynamic Sociometry</div>
	<div class='proc-auth'>Stefano Kalonaris</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-6'>Bibtex</span>
	<div id='abstract2020-6' class='collapse proc-abstract'>
A framework for musical interaction design and notation based on social network analysis is proposed. To this end, the affiliation network model, which comprises actors and events, is employed. Maintaining a sufficiently flexible definition of event can cater for both music improvisers and composers alike. If the (number of) events, their time occurrence and their action space (what happens in a given event) can be subjectively defined, then the concept of authorship and the continuum between improvisation and composition can be arbitrarily explored. The theoretical axioms of the affiliation network, along with methods for analysing its dynamics are presented. Furthermore, it is suggested that such analysis can provide a suitable strategy for notating emergent and/or composed musical interactions and, retrospectively, for designing some anew. Finally, a general scheme is illustrated, along with some speculative blends for its practical implementation. 
	</div>
	<pre id='bibtex2020-6' class='collapse proc-bibtex'>
@inproceedings{Kalonaris_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Stefano Kalonaris },
  Title = {A Scheme for Music Interaction Design and Notation Based on Dynamic Sociometry},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {49-55},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/07_Hopkins_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Jam Tabs: A Color Based Notation System for Novice Improvisation</div>
	<div class='proc-auth'>Torin Hopkins and Ellen Do</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-7'>Bibtex</span>
	<div id='abstract2020-7' class='collapse proc-abstract'>
Music improvisation, which is defined as creatively and playfully exchanging musical concepts, is often associated with expert musicianship and musical skill. While there are numerous methods for live scoring improvisation, there are not many resources aimed at assisting novice performance during improvisational activities. Jam Tabs is a notation system that helps coordinate idiomatic musical expression for novice musicians using color-coded instruments and a colored visual display. Jam Tabs utilizes a seven-color notation system, LED cubes and a colored piano keyboard to assist novices in coordinating chord progressions—a common musical element used among improvising musicians in popular western music contexts. We have observed that novice piano players could follow chord progressions in tonal music note for note using color coordination while improvising. We found that seven colors in any key provide enough information for players to experience a satisfactorily expressive and creative jam session. 
	</div>
	<pre id='bibtex2020-7' class='collapse proc-bibtex'>
@inproceedings{Hopkins_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Torin Hopkins and Ellen Do },
  Title = {Jam Tabs: A Color Based Notation System for Novice Improvisation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {56-62},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/08_Slavik_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Strategies and Suggestions for Singing in Foreign Languages Based on Phonetic Musical Notation</div>
	<div class='proc-auth'>Korbinian Slavik, Markus Jochim, Verena Klasen</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-8'>Bibtex</span>
	<div id='abstract2020-8' class='collapse proc-abstract'>
There are different approaches to a good pronunciation when singing in foreign languages. One promising example is the use of the International Phonetic Alphabet (IPA). Transcribing lyrics with this alphabet has a tradition of several decades, but it can be very time-consuming when done manually, especially if you want to store IPA information directly within a score. We investigated, for what musicians the use of IPA is useful and what they normally do when singing in foreign languages. In a questionnaire with more than 450 participants from 19 different countries we asked singers and conductors about their strategies when singing in a foreign language and whether they thought it was useful to have IPA inside a score. We identified a variety of strategies which are used for singing in foreign languages like listening to recordings or to experts of the target language. Additionally, 60-70 % of all participants and 90 % of opera singers think that a phonetic alphabet could be helpful in a score. Test subjects were also asked to name the languages they wanted as transcriptions in the notes, where Russian was second to none. As a consequence of these results, we are working on an automated approach for writing IPA information directly in MusicXML data, thus combining IPA transcription with the original score. 
	</div>
	<pre id='bibtex2020-8' class='collapse proc-bibtex'>
@inproceedings{Slavik_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Korbinian Slavik and Markus Jochim and Verena Klasen },
  Title = {Strategies and Suggestions for Singing in Foreign Languages Based on Phonetic Musical Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {63-67},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/09_Dori_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Using Gesture Data to Generate Real-Time Graphic Notation: a Case Study</div>
	<div class='proc-auth'>Gil Dori</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-9'>Bibtex</span>
	<div id='abstract2020-9' class='collapse proc-abstract'>
The paper describes the concepts and compositional process of my recent real-time graphic score work Arcos, for cello and augmented violin bow. The work's graphic notation is generated directly from gesture data of various bowing techniques. A Myo armband was used to record cello bowing data, and the augmented bow's own position tracking module was used to record its motion data. After processing the data, gestures were visualized on the screen, as a form of real-time graphic notation based on imitation. This notational approach—a low-level symbolic representation of gestures—allows for an immediate, intuitive interpretation on the spot, and provides an instantaneous connection between notation and action. My work also offers a distinct perspective on notation for electronic instruments in the context of real-time action-based scores. 
	</div>
	<pre id='bibtex2020-9' class='collapse proc-bibtex'>
@inproceedings{Dori_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Gil Dori },
  Title = {Using Gesture Data to Generate Real-Time Graphic Notation: a Case Study},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {68-74},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/10_Befera_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Filtering and Synthesis: IT-Based Approach in the Compositive Process of Giovanni Verrando and Fausto Romitelli</div>
	<div class='proc-auth'>Luca Befera, Luca Guidrini</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-10'>Bibtex</span>
	<div id='abstract2020-10' class='collapse proc-abstract'>
To investigate the influences that information technology has brought to musical writing and compositional process, the cases of Giovanni Verrando and Fausto Romitelli – Italian post-spectral composers of the 1960s generation – will be examined. After their studies at IRCAM in Paris, they integrated tools of digital sound treatment and musical form management into their notation, opportunely mediated by software and informatics tools. Two fundamental aspects of their language will be investigated: the cyclical organization of the form, and timbral generation techniques as filtering for Verrando and synthesis for Romitelli. It will be demonstrated how the principles indicated, deriving from specific methods of digital treatment of sound, are applied to the creation of complex timbres reproduced by the orchestra or by the ensemble. In both cases, the results are a writing process, compositional way of thinking and sound outcome hybrid between acoustic and electronic, determining a formal management mediated by sound data and according to a prominently IT-based approach. 
	</div>
	<pre id='bibtex2020-10' class='collapse proc-bibtex'>
@inproceedings{Befera_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Luca Befera and Luca Guidrini },
  Title = {Filtering and Synthesis: IT-Based Approach in the Compositive Process of Giovanni Verrando and Fausto Romitelli},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {75-83},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/11_Santini_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Action scores and gesture-based notation in Augmented Reality</div>
	<div class='proc-auth'>Giovanni Santini</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-11'>Bibtex</span>
	<div id='abstract2020-11' class='collapse proc-abstract'>
Augmented Reality (AR) is becoming, year by year, an established and well-known technological resource. Experimentations and innovative applications are produced in different areas. In music, there already is some use of such a technology in the fields of education and performance. However, the use of AR features as compositional resources has yet to be deeply explored and leaves room for innovative research. In particular, the possibility of notating the gesture in space, instead of on paper or screen, has been only superficially studied. This research focuses on the development of a new prescriptive notation system for gestures that represents extended techniques requiring direct contact between the performer and the vibrating body. Such a system has been implemented in the composition Portale, for small tam-tam, AR environment and live-electronics. 
	</div>
	<pre id='bibtex2020-11' class='collapse proc-bibtex'>
@inproceedings{Santini_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Giovanni Santini },
  Title = {Action scores and gesture-based notation in Augmented Reality},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {84-90},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/12_ElRaheb_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Symbolising Space: From Notation to Movement Interaction</div>
	<div class='proc-auth'>Katerina El Raheb, Marina Stergiou, Akrivi Katifori, Yannis Ioannidis</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-12'>Bibtex</span>
	<div id='abstract2020-12' class='collapse proc-abstract'>
The last decades the development of whole-body interaction technologies, as well as XR (Extended Reality) technologies, including Augmented, Mixed and Virtual Reality, created a strong potential for embodied and immersive experiences to support learning and the use of notation while moving. In our ongoing work, we explore this potential on the user case of familiarizing dance experts and amateurs with movement notation in general and Labanotation in particular. By applying methodologies of usercentered design, including co-design workshops with notation and dance experts, interviews, focus-groups, questionnaires supporting the iterative design of our prototype, we focus on how we can meaningfully transfer the concepts related to space from notation to full body interaction instructions. So far we have developed two prototypes following two paradigms: a. the augmented mirror paradigm using Kinect and b. the immersive paradigm using HTCVive, that we have used as technology probes to interact with dance experts in the context of our co-design work. We reflect on this experimentation and we document the emerging challenges of transferring a symbolic language that is meant to be transmitted through paper, into spatial semantic queues. We discuss the challenges that arise between the gaps of symbolically referring to space, within a rich conceptual framework, such as Laban Movement Analysis (LMA), experiencing space kinaesthetically, and transferring these into a digital experience, always within the limitations of the current technologies. 
	</div>
	<pre id='bibtex2020-12' class='collapse proc-bibtex'>
@inproceedings{El_Raheb_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Katerina El Raheb and Marina Stergiou and Akrivi Katifori and Yannis Ioannidis },
  Title = {Symbolising Space: From Notation to Movement Interaction},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {91-99},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/13_Opstad_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Aiding the Performance of Tempo Canon: New Technology in Studies 1, 2 and 3 for String Quartet</div>
	<div class='proc-auth'>James Opstad</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-13'>Bibtex</span>
	<div id='abstract2020-13' class='collapse proc-abstract'>
This paper discusses the application of new score-reading technologies in a set of string quartet studies written for Apartment House. I highlight how the use of technology facilitates complex polytemporal relationships within the ensemble and allows these to be conveyed in a simpler and more direct manner. I demonstrate the current state of the score application and draw attention to design features that differ from existing approaches as well as changes that have been made in response to performer feedback. This follows a brief discussion of tempo canon in both my own work and its broader historical context. 
	</div>
	<pre id='bibtex2020-13' class='collapse proc-bibtex'>
@inproceedings{Opstad_tenor2020,
  Address = {Hamburg, Germany},
  Author = { James Opstad },
  Title = {Aiding the Performance of Tempo Canon: New Technology in Studies 1, 2 and 3 for String Quartet},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {100-105},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/14_Skold_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The notation of sound for composition and transcription: An adaptation of Lasse Thoresen's spectromorphological analysis</div>
	<div class='proc-auth'>Mattias Sköld</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-14'>Bibtex</span>
	<div id='abstract2020-14' class='collapse proc-abstract'>
This paper details my adaptation of Lasse Thoresen’s spectromorphological analysis notation for the sake of composition and transcription, re-imagining the analysis symbols for use over a spectrum staff system over which pitch and spectra can be indicated with great detail, and possibly interpreted by musicians and computers for performance. A sound object is notated with regard to its spectral width, density, centroid frequency, significant sound components, modulation and amplitude envelope. It can also have a spectrum reference. The symbols are placed over a spectrum grand-staff with a frequency scale to show each parameter both from a frequency and pitch perspective. Also included are suggestions for the visual representation of spatialisation where positions and movements are displayed in two or three dimensions above the sound notation while constant rotations are notated as modulations. 
	</div>
	<pre id='bibtex2020-14' class='collapse proc-bibtex'>
@inproceedings{Skold_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Mattias Sköld },
  Title = {The notation of sound for composition and transcription: An adaptation of Lasse Thoresen's spectromorphological analysis},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {106-113},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/15_Malt_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Geometric Notation for Time-Bracket works, application and performance The case of John Cage’s Music for___</div>
	<div class='proc-auth'>Mikhail Malt, Benny Sluchin</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-15'>Bibtex</span>
	<div id='abstract2020-15' class='collapse proc-abstract'>
The interpreter who approaches the music of John Cage composed after the middle of the 20th century is often disconcerted by a great freedom of execution, associated with a set of precise instructions. In previous work [8] we modeled these time brackets (TB) by parallelograms to build computer interfaces for interpretation assistance in the context of Cage’s Two5. Over time ([9], [10], [11], [13]), we realized that the shape used to represent TB, brought important information for the interpretation and musical analysis. In this paper we apply previous research to a computer display conception of John Cage’s Music for___ (1984-87). 
	</div>
	<pre id='bibtex2020-15' class='collapse proc-bibtex'>
@inproceedings{Malt_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Mikhail Malt and Benny Sluchin },
  Title = {Geometric Notation for Time-Bracket works, application and performance The case of John Cage’s Music for___},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {114-119},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/16_Isadora_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Performing the Practice of Composition</div>
	<div class='proc-auth'>Alison Isadora</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-16'>Bibtex</span>
	<div id='abstract2020-16' class='collapse proc-abstract'>
In this paper I discuss challenges towards our understanding of the role and ontology of the score, in relationship to the roles of composer, performer, audience and performance space. I consider the role of these actants within three situated aspects of the Western art music tradition as proposed by Coessens and colleagues: the ecological, epistemic and social. What emerges from this deliberation, is the reification of the score as the ‘work’, the expectation of a ‘genius’ (male) composer, hierarchic and stultifying conditions for both musicians and audience members, and performance spaces that encourage these stratifications. Modes of engagement are explored that might foster alternative roles for all actants and the notions of sympoiesis, and the anarchive are presented as potentially useful conceptual tools when imagining an alternative ontology of the score. Moreover, developing on Isabelle Stengers’ ideas on an ecology and interdependence of practices I speculate on the ramifications of considering the score as having a ‘challenging and fostering’ role in relationship to the other parties. The paper finishes with a discussion of Together#5.1 in which methods for encouraging a social technology of belonging and shared compositional response-ability between all actants are explored. These methods include collective listening practices, audience scores, adaptive notations and context specific elements. 
	</div>
	<pre id='bibtex2020-16' class='collapse proc-bibtex'>
@inproceedings{Isadora_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Alison Isadora },
  Title = {Performing the Practice of Composition},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {120-124},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/17_Vickery_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notational Strategies for Integrating Live Performers with Complex Sounds and Environments</div>
	<div class='proc-auth'>Lindsay Vickery</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-17'>Bibtex</span>
	<div id='abstract2020-17' class='collapse proc-abstract'>
This paper describes strategies for integrating live performers with complex “extra-musical” sounds and environments through extended traditional and proportional notations. The subjects of the works discussed include Animals (wardang [2019], kurui [2018]) and environments (rising water [2018], willsons downfall [2018], njookenbooro [2018]) . The techniques include spectrographic transcription, audio processing, extended forms of notation and spatial audio. 
	</div>
	<pre id='bibtex2020-17' class='collapse proc-bibtex'>
@inproceedings{Vickery_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Lindsay Vickery },
  Title = {Notational Strategies for Integrating Live Performers with Complex Sounds and Environments},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {125-132},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/18_Zagorac_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Networked Comprovisation Stratagies with ZScore</div>
	<div class='proc-auth'>Slavko Zagorac, Michael Zbyszynski</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-18'>Bibtex</span>
	<div id='abstract2020-18' class='collapse proc-abstract'>
ZScore is a networked notation system for mixed ensemble composition and performance. This paper describes recent system developments towards a platform for comprovised music making. The long-term project objective is to provide an inclusive, democratised music-making environment by utilising technology that enables distributed decision making, dynamic notation processing and visualisation. It is proposed that all music is the outcome of a decision-making process that can be represented on the spectrum between immutable static and real-time dynamic decision making. Networking technology can act as an enabler for moving the dial on this decision-making spectrum in a required direction. Furthermore, a definition of a networked notational perspective is outlined, covering the dynamic aspects of distributed notation for heterogeneous clients. Several strategies for dealing with dynamic notation visualisation and control are presented, such as the dynamic performance parameter processing and embedded scripting. Finally, this paper presents the results from recent user trials and plans for future developments. 
	</div>
	<pre id='bibtex2020-18' class='collapse proc-bibtex'>
@inproceedings{Zagorac_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Slavko Zagorac and Michael Zbyszynski },
  Title = {Networked Comprovisation Stratagies with ZScore},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {133-140},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/19_Ghisi_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Interactive timeshaping of musical scores</div>
	<div class='proc-auth'>Daniele Ghisi, Andrea Agostini, Eric Maestri</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-19'>Bibtex</span>
	<div id='abstract2020-19' class='collapse proc-abstract'>
In this article we aim to organize the collection of practices that amount to modifying the temporality of a musical score in order to create a new one, by representing them as a combination of three basic families of operations: dilations, distortions and repetitions. The initial score can be borrowed or designed on purpose, and can be of any complexity (an entire score, a single note, or anything in between). We call the complex of these practices ‘timeshaping’. We describe the analytical space derived from the proposed organization and show how many of its processes can be implemented in an interactive computer-aided composition environment using the bach and cage libraries for Max. 
	</div>
	<pre id='bibtex2020-19' class='collapse proc-bibtex'>
@inproceedings{Ghisi_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Daniele Ghisi and Andrea Agostini and Eric Maestri },
  Title = {Interactive timeshaping of musical scores},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {141-148},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/20_Wetherfield_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Minimum Cut Pitch Spelling Algorithm</div>
	<div class='proc-auth'>Benjamin Wetherfield</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-20'>Bibtex</span>
	<div id='abstract2020-20' class='collapse proc-abstract'>
This paper describes and refines the Minimum Cut Pitch Spelling Algorithm, designed for flexible use in modern software and contemporary music settings. In the process of composing notated music, a decision must be made by the composer as to which enharmonic spelling should be assigned to each represented pitch. Spelling assignments in close proximity on the page are interrelated, with each choice exerting a pull on the surrounding choices. Hence, the complexity of the problem can proliferate, especially where tonal centers are contextually ambiguous or even non-existent. The minimum cut approach herein presents a model for spelling pitches efficiently based on their intervallic relationships. Building on the previous presentation of the model (in the author’s bachelor’s thesis), simplifications and extensions of both the workings of the algorithm and its exposition are given. Among the simplified components of the presentation are the system of encoding applied to pitch spellings, the approach taken to avoid double-accidentals, and a decoupling of the full complexity of the model from its simplest pitch relationships. A new practical inverting (or ‘learning’) process for generating algorithm parameters from collections of spelled pitches (based on the Edmonds-Karp Maximum Flow algorithm) is also introduced. 
	</div>
	<pre id='bibtex2020-20' class='collapse proc-bibtex'>
@inproceedings{Wetherfield_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Benjamin Wetherfield },
  Title = {The Minimum Cut Pitch Spelling Algorithm},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {149-157},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/21_Fukuda_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Super Colliders: A Gamified Screen-Score</div>
	<div class='proc-auth'>Takuto Fukuda</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-21'>Bibtex</span>
	<div id='abstract2020-21' class='collapse proc-abstract'>
This paper introduces Super Colliders (2018), a piece written for three pitched instruments and a computer. This piece applies gamification to the screen-score as a compositional approach to achieve playful human-computer interactions. The piece features a game design that encompasses various game mechanics and elements. The paper describes the technical details of the game’s design, the role and effects of the featured game elements from the perspective of motivational affordances. Finally, through the analysis of a performance of the piece, the paper reveals how motivational affordances in the screen-score supported to generate the musical structure through the playful performer-computer interactions. 
	</div>
	<pre id='bibtex2020-21' class='collapse proc-bibtex'>
@inproceedings{Fukuda_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Takuto Fukuda },
  Title = {Super Colliders: A Gamified Screen-Score},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {158-168},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/22_Wyatt_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Conducting Animated Notation: Is It Necessary?</div>
	<div class='proc-auth'>Aaron Wyatt, Cat Hope</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-22'>Bibtex</span>
	<div id='abstract2020-22' class='collapse proc-abstract'>
At the 2019 Perth Festival, Western Australia’s largest and most nationally significant arts event, a new animated notation opera by Cat Hope was premiered. This sixty minute staged work for thirty piece orchestra, thirty voice community choir and four vocal soloists ran over six nights and was led by musical director Aaron Wyatt. The score was delivered over 26 networked iPads in the orchestra within the Decibel ScorePlayer application [1], controlled by the musical director, and both the choir and vocal soloists memorised the graphic score. In addition to directing the preparations for the performance, Wyatt conducted the orchestra and singers from the podium each night. This paper discusses the role of the conductor in this performance, and examines the role of the conductor in works performed from animated notations more broadly. A questionnaire was sent to the orchestral members who participated in the performances of ‘Speechless’ asking a series of questions about the impact and role of the conductor in the work, and their responses inform the body of this paper. Overall, the responses indicate that although the score presentation for the work on the networked iPads was very exacting, the role of the conductor was essential for extracting musicianship and nuance in each performance. 
	</div>
	<pre id='bibtex2020-22' class='collapse proc-bibtex'>
@inproceedings{Wyatt_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Aaron Wyatt and Cat Hope },
  Title = {Conducting Animated Notation: Is It Necessary?},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {169-174},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/23_Shatri_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Optical Music Recognition: State of the Art and Major Challenges</div>
	<div class='proc-auth'>Elona Shatri, György Fazekas</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-23'>Bibtex</span>
	<div id='abstract2020-23' class='collapse proc-abstract'>
Optical Music Recognition (OMR) is concerned with transcribing sheet music into a machine-readable format. The transcribed copy should allow musicians to compose, play and edit music by taking a picture of a music sheet. Complete transcription of sheet music would also enable more efficient archival. OMR facilitates examining sheet music statistically or searching for patterns of notations, thus helping use cases in digital musicology too. Recently, there has been a shift in OMR from using conventional computer vision techniques towards a deep learning approach. In this paper, we review relevant works in OMR, including fundamental methods and significant outcomes, and highlight different stages of the OMR pipeline. These stages often lack standard input and output representation and standardised evaluation. Therefore, comparing different approaches and evaluating the impact of different processing methods can become rather complex. This paper provides recommendations for future work, addressing some of the highlighted issues and represents a position in furthering this important field of research. 
	</div>
	<pre id='bibtex2020-23' class='collapse proc-bibtex'>
@inproceedings{Shatri_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Elona Shatri and György Fazekas },
  Title = {Optical Music Recognition: State of the Art and Major Challenges},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {175-184},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/24_Moroz_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Extending Notation Through Embodied Research</div>
	<div class='proc-auth'>Solomiya Moroz</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-24'>Bibtex</span>
	<div id='abstract2020-24' class='collapse proc-abstract'>
Through engagement with embodied research, I challenge the use of notation as part of the ‘paradigm of reproduction’ [1] in which notation plays a central role in the musical work concept. In my work, I propose new collaborative methods which place an accent on performers’ response and embodied memory, thus I anchor the idea of a work with collaborators of my projects in addition to any other methods of mediation such as a notated score. In this paper, I would like to discuss two of my latest works, On Fragments and Motion Studies, which rely on performers’ embodied memory in order to execute the works. 
	</div>
	<pre id='bibtex2020-24' class='collapse proc-bibtex'>
@inproceedings{Moroz_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Solomiya Moroz },
  Title = {Extending Notation Through Embodied Research},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {185-188},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/25_Pirchner_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Ergodic and Emergent Qualities of Real-Time Scores. Anna & Marie and Gamified Audiovisual Compositions</div>
	<div class='proc-auth'>Andreas Pirchner</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-25'>Bibtex</span>
	<div id='abstract2020-25' class='collapse proc-abstract'>
This paper describes the functionality and aesthetic implications of the real-time score-system developed for the composition Anna & Marie by Marko Ciciliani. It originates from the artistic research project GAPPP and was first performed at Donaueschinger Musiktage 2019. By referring to examples of historic tendencies towards non-linear scores, the terms ergodicity and emergence are introduced to the understanding of the score properties of the real-time virtual performance space. This first part is then exemplified by describing the ergodic score of Anna & Marie. A particularity of this work is that two violinists navigate avatars in two virtual 3D environments by their manner of playing. The environment offers distinct audiovisual situations distributed in the virtual space and is identified as a spatial score. The musicians’ musical effort of spatially traversing the virtual performance space consequently allows the audiovisual gestalt of the performance to emerge. The entanglement of spatial score and symbolic score, generated and presented on tablets, and mediated by the performers, is shown to be a characteristic of the composition. It is investigated, how the emerging performances question a notion of ergodicity where a prior text is followed by a technology reproducing it. In conclusion, the group of categories of real-time scores is extended by ergodic emergent scores. 
	</div>
	<pre id='bibtex2020-25' class='collapse proc-bibtex'>
@inproceedings{Pirchner_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Andreas Pirchner },
  Title = {Ergodic and Emergent Qualities of Real-Time Scores. Anna & Marie and Gamified Audiovisual Compositions},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = {189-197},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2020/26_Bell_tenor20.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Common Ground, Music and Movement Directed by a Raspberry Pi</div>
	<div class='proc-auth'>Jonathan Bell, Aaron Wyatt</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2020-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2020-26'>Bibtex</span>
	<div id='abstract2020-26' class='collapse proc-abstract'>
This paper describes Common Ground, a piece for six dancing singers and electronics, in which the coordination between performers is ensured by a RaspberryPi-embedded node.js web application. The singers received synchronised scores in the browser of their phone, which they wore in head-mounted display in order to free their hands and enhance their scenic presence. After a description of the artistic project, the elaboration of the score is examined under the categories of movement notation (how trajectories are embedded in musical notation), spectral composition (microtonal tuning between synthesised sounds and human voices), algorithmic processes (how the recent bell coding language facilitates processes for which Max patching is ill-suited). The article finally describes the Raspberry implementation, outlining potential ameliorations of the current system, including dns support and unnecessary dependance on a dedicated router. 
	</div>
	<pre id='bibtex2020-26' class='collapse proc-bibtex'>
@inproceedings{Bell_tenor2020,
  Address = {Hamburg, Germany},
  Author = { Jonathan Bell and Aaron Wyatt },
  Title = {Common Ground, Music and Movement Directed by a Raspberry Pi},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'20/21},
  Pages = { 198-204},
  Year = {2020},
  Editor = {Rama Gottfried and Georg Hajdu and Jacob Sello and Alessandro Anatrini and John MacCallum},
  Publisher = {Hamburg University for Music and Theater},
  ISBN = {978-3-00-066930-9}
}
	</pre>
</div>
</div>
</section>

 <!-- ========================================================================= -->

    <section class="proc-altern" id="2019">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2019</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>

<div class='container'>
<div class='row tenor-paper'>
  <a href='proceedings/TENOR2019-Proceedings.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
  <div class='proc-title'>FULL TENOR'19 PROCEEDINGS</div>
  <span class='proc-button' data-toggle='collapse' data-target='#bibtex2019'>Bibtex</span>
  | <a href="proceedings/bibtex2019.bib" class="tenor-bibtex">.bib</a>

  <pre id='bibtex2019' class='collapse proc-bibtex'>
@book{tenor2019,
  Address = {Melbourne, Australia},
  Title = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}}
  </pre>
</div>
<hr>
</div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2019/01Bell.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Animated Notation, Score Distribution and AR-VR Environments for Spectral Mimetic Transfer in Music Composition</div>
	<div class='proc-auth'>Jonathan Bell and Benedict Carey</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-1'>Bibtex</span>
	<div id='abstract2019-1' class='collapse proc-abstract'>
This paper seeks to make a case for a compositional ideal (the mimetic transfer of a recorded or synthesized sound to the instrumental/vocal domain) which today’s technologies for animated/distributed musical notation have made more realistic than when it first appeared as a general aesthetic (with composers such as Tristan Murail and Gérard Grisey, or, in the realm of computer music, as with the practice of Jean-Claude Risset), simultaneously with the birth of the digital era in the 1970s. The concept of mimesis is here examined both as a (post) spectral compositional technique and as a common feature of many forms of musical score/representation. These theoretical considerations are then exemplified by musical examples and software demonstrations extract from the “In memoriam Jean-Claude Risset” cycle of compositions, scored for ensembles of various sizes (small chamber music group with players wearing head-mounted displays, choir and electronics, large instrumental groups with choir, and for the performance of an opera), all performed with the help of the SmartVox Score distribution system.
	</div>
	<pre id='bibtex2019-1' class='collapse proc-bibtex'>
@inproceedings{Bell_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Jonathan Bell and Benedict Carey },
  Title = {Animated Notation, Score Distribution and AR-VR Environments for Spectral Mimetic Transfer in Music Composition},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {7--14},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/02Bouchard.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Live Structures</div>
	<div class='proc-auth'>Linda Bouchard and Joseph Browne</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-2'>Bibtex</span>
	<div id='abstract2019-2' class='collapse proc-abstract'>
Live Structures is a research and composition project that explores different ways to interpret data into graphic notation and compositions. The Live Structures project started in October 2017, supported by an Explore and Create Grant from the Canada Council for the Arts received by Bouchard. One of the goals of the Live Structures project is to interpret data from the analysis of complex sounds into a visual musical notation. The tool, developed in collaboration with Joseph Browne of matralab at Concordia University, is called Ocular ScoresTM. So far, three iterations of the Ocular Scores Tool have been created, each performing multiple functions: a) the ability to draw an image from the analysis of complex sounds that can be used as gestural elements to compose new works or to compare a complex sound against another complex sound, b) the ability to draw full transcriptions of a performance for future interpretation, and c) the ability to draw images in real time and to manipulate those images to create interactive projected scores to be performed live by multiple performers.
	</div>
	<pre id='bibtex2019-2' class='collapse proc-bibtex'>
@inproceedings{Bouchard_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Linda Bouchard and Joseph Browne },
  Title = {Live Structures},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {26--32},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/04Davis.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Monthly Acid Pattern – An Accessible Notation System for Acid House collaboration</div>
	<div class='proc-auth'>Dylan Davis</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-3'>Bibtex</span>
	<div id='abstract2019-3' class='collapse proc-abstract'>
Scholars continue to investigate how communities are built by sharing histories, norms and values within the ‘third spaces’ enabled by social media technologies. How can these third spaces be harnessed to explore collaborative and experimental compositional practices, and, in turn, what can practising music as a ‘shareable’ culture reveal about community building as it shifts to digital platforms. The Monthly Acid Pattern Group used the compositional schematic of the Acid Pattern and a particular analogue synthesizer, the Roland TB-303, as the basis for the sustained production of interpretative works using online collaborative and publishing platforms over a four-year period. This project contributed to further understanding of how the practices and cultures of music composition are shared and can build community. With the use of an emerging online platform (SoundCloud), the research project made an innovative contribution to methodologies of documenting, and enabling, the interpretative practices of an online community as it emerged. The works that were created demonstrated new possibilities for accessible modes of notation, instrumentality and compositions within digital music cultures.
	</div>
	<pre id='bibtex2019-3' class='collapse proc-bibtex'>
@inproceedings{Davis_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Dylan Davis },
  Title = {The Monthly Acid Pattern – An Accessible Notation System for Acid House collaboration},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {69--73},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/05Gottfried.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Drawsocket: A Browser Based System for Networked Score Display”</div>
	<div class='proc-auth'>Rama Gottfried and Georg Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-4'>Bibtex</span>
	<div id='abstract2019-4' class='collapse proc-abstract'>
We present DRAWSOCKET, a new platform for generating synchronized, browser-based displays across an array of networked devices developed at the Hochschule für Musik und Theater, Hamburg. Conceived as a system for distributed notation display with applications in music and spatial performance contexts, DRAWSOCKET provides a unified interface for controlling diverse media features of web browsers which can be utilized in many ways. By providing access to browser mouse and multitouch gesture data, and the ability to dynamically create user-defined callback methods, the DRAWSOCKET system aims to provide a flexible tool for creating graphical user interfaces. Included is a discussion of the architecture design and development process, followed by an overview of the features, and syntax considerations for the DRAWSOCKET API.
	</div>
	<pre id='bibtex2019-4' class='collapse proc-bibtex'>
@inproceedings{Gottfried_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Rama Gottfried and Georg Hajdu },
  Title = {Drawsocket: A Browser Based System for Networked Score Display”},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {15--25},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/06Hajdu.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Networked Music Performance in the Old Elbe Tunnel</div>
	<div class='proc-auth'>Georg Hajdu and Rama Gottfried</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-5'>Bibtex</span>
	<div id='abstract2019-5' class='collapse proc-abstract'>
In this paper we present a new distributed score display system currently under development at the Hochschule für Musik und Theater, Hamburg (HfMT). The project was initiated as part of a large scale live performance in the St. Pauli Elbe Tunnel (sometimes also referred to as Old Elbe Tunnel), for 144 musicians spread out over the 864 meters of its two tubes. We describe here the background of this project and the current status of the technological and musical considerations required to achieve this event.
	</div>
	<pre id='bibtex2019-5' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Georg Hajdu and Rama Gottfried },
  Title = {Networked Music Performance in the Old Elbe Tunnel},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {55--60},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/07Ingamells.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Performing the Compositional Act with Bouncy Castles, Soap and Shh</div>
	<div class='proc-auth'>Andy Ingamells</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-6'>Bibtex</span>
	<div id='abstract2019-6' class='collapse proc-abstract'>
My practice-based research has led to a rethinking of the relationships between composer, performer and listener in my own creative work through an interpretation of a diagram by experimental composer George Brecht. Through the reconfiguration of this diagram I have developed a framework in which the act of composition can be performed via the activities of ‘reading’, ‘performance’ and ‘playing’, with the focus on an expanded notion of traditional score-reading that makes the act of reading manifest onstage as part of the physical theatricality of musical performance. This approach can be used as a site for further experimentation by other interdisciplinary creative practitioners.
	</div>
	<pre id='bibtex2019-6' class='collapse proc-bibtex'>
@inproceedings{Ingamells_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Andy Ingamells },
  Title = {Performing the Compositional Act with Bouncy Castles, Soap and Shh},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {74--79},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/08Kim-Boyle.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Immersive Scores on the HoloLens</div>
	<div class='proc-auth'>David Kim-Boyle and Benedict Carey</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-7'>Bibtex</span>
	<div id='abstract2019-7' class='collapse proc-abstract'>
The authors describe work undertaken in porting the 3D, Max generated score for David Kim-Boyle’s 5x3x3 (2018) to the Microsoft HoloLens. The constraints of various network protocols for communicating between Max and the Unity 3D platform, with which HoloLens applications are built, are discussed and the deployment process from Unity to the HoloLens is described. Various optimization considerations are outlined, and the paper concludes with a discussion of feedback from performers and a brief appraisal of some of the unique aesthetic affordances of the HoloLens platform. 
	</div>
	<pre id='bibtex2019-7' class='collapse proc-bibtex'>
@inproceedings{Kim-Boyle_tenor2019,
  Address = {Melbourne, Australia},
  Author = { David Kim-Boyle and Benedict Carey },
  Title = {Immersive Scores on the HoloLens},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {1--6},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/09Nickel.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Palace 64: Impossible Virtual Roller Coasters as Musical Scores</div>
	<div class='proc-auth'>Luke Nickel</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-8'>Bibtex</span>
	<div id='abstract2019-8' class='collapse proc-abstract'>
In Palace64, a major new multidisciplinary project combining video and chamber ensemble, I examine the ways in which the domains of music composition and virtual roller coaster design might influence one another. First, I briefly discuss existing artistic projects relating to roller coaster design. Second, I present my own early artistic explorations combining music and virtual roller coasters. Finally, I discuss Palace64. In this project, I create a new medium of score that combines oral transmissions describing imaginary impossible roller coasters with videos created using innovative 3D roller coaster design software (NoLimits 2). Using strategies pioneered by Éliane Radigue and Jennifer Walshe for interpreting imagined images and paths as musical material, I develop ways in which performers can “read” these impossible roller coasters—remembered and virtual—as scores. Ultimately through this project my goal is to create and demonstrate a hybrid artwork that exists not only as a score to facilitate the performance of experimental music, but also as a conceptual theme park ride that traverses the boundaries of possibility and impossibility in a region that marries the digital with an embodied human experience of risk and pleasure. This paper is intended as an accompaniment to the performance of Palace64 by Decibel New Music Ensemble.
	</div>
	<pre id='bibtex2019-8' class='collapse proc-bibtex'>
@inproceedings{Nickel_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Luke Nickel },
  Title = {Palace 64: Impossible Virtual Roller Coasters as Musical Scores},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {80--84},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/10Schimana.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Sound as Score</div>
	<div class='proc-auth'>Elisabeth Schimana</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-9'>Bibtex</span>
	<div id='abstract2019-9' class='collapse proc-abstract'>
As a composer and musician of electronic music since the 1980s my medium is sound. When I was asked in 2009 to compose a piece for RSO (Radio-Symphonieorchester) Vienna I had to think about how to communicate with this sound body. I opted for what I do best - sound and listening. Since that year I have developed two different methods of communication with musicians - the live generated audio score, where the performers have to imitate the live generated electronic sounds they hear through a loudspeaker, and the audio score based on acoustic memory, where the musicians are given a set of sound samples for interpretation on their instruments and then in the performance this interpretation has to be played from memory. This paper examines the method, scoring, practice and rehearsal, as well as the artistic results using examples from The Virus series and the music theater piece Pricked and Away.
	</div>
	<pre id='bibtex2019-9' class='collapse proc-bibtex'>
@inproceedings{Schimana_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Elisabeth Schimana },
  Title = {Sound as Score},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {33--37},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/11Sdraulig.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Recent Audio Scores: Affordances and Limitations</div>
	<div class='proc-auth'>Charlie Sdraulig and Chris Lortie</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-10'>Bibtex</span>
	<div id='abstract2019-10' class='collapse proc-abstract'>
A growing body of contemporary composers produces audio scores where sound is the integral mediator between the composer and performer. While many musical scores deploy some form of symbolic visual representation of sound or movement, audio scores represent information and instructions in the same domain as the performed product. This paper aims to survey the affordances and limitations of audio scores enacted thus far. Within the field, we identify two primary sub-categories associated with the temporal relations between performer and audio score: reactive and rehearsed. Louis d’Heudieres’ Laughter Studies 1-3 (2015-16) and Lara Stanic’s Open Air Bach (2005, rev. 2013) are examples of reactive audio scores. Representative examples of rehearsed audio scores include Carola Bauckholt’s Zugvögel (2011-12) and Cassandra Miller’s Guide (2013). These primary sub-categories may be combined and hybridized to varying degrees, as in Carolyn Chen’s Adagio (2009). Finally, in light of our survey of the possibilities offered by audio scores, we propose some further avenues of exploration for creative practice.
	</div>
	<pre id='bibtex2019-10' class='collapse proc-bibtex'>
@inproceedings{Sdraulig_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Charlie Sdraulig and Chris Lortie },
  Title = {Recent Audio Scores: Affordances and Limitations},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {38--45},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/12Wilson.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Towards Responsive Scoring Techniques for Networked Music Performances</div>
	<div class='proc-auth'>Rebekah Wilson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-11'>Bibtex</span>
	<div id='abstract2019-11' class='collapse proc-abstract'>
The latent and unstable nature of networked performances, where the delayed transmission and uncertain, unstable, and compressed reception of transferred information demands scoring conceptualizations that consider the loss of the presence information traditionally expected by musicians when performing together in a shared space and time. The focus of this study is to develop electronic network- aware responsive scoring techniques that consider the primary constraints of networked music performances: i.e., latency, uncertainty, multilocated, and digital. Using machine-learning techniques to investigate and enhance digitally mediated presence technology, scoring possibilities are discussed that promote the experience of performing together while being remote from each other—connected via a public network and subject to latency. This study also looks at compositional and technical approaches to creating responsive scores for networked music performances using analysis of transferred sound as a means to generate and control metadata and symbolic notation.
	</div>
	<pre id='bibtex2019-11' class='collapse proc-bibtex'>
@inproceedings{Wilson_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Rebekah Wilson },
  Title = {Towards Responsive Scoring Techniques for Networked Music Performances},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {46--54},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2019/13Wyatt.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Unlocking the Decibel ScorePlayer</div>
	<div class='proc-auth'>Aaron Wyatt, Lindsay Vickery and Stuart James</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2019-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2019-12'>Bibtex</span>
	<div id='abstract2019-12' class='collapse proc-abstract'>
This paper discusses recent developments in the Decibel ScorePlayer project, including the introduction of a canvas scoring mode, python ScorePlayer externals, and enhancements to the ScoreCreator application. Firstly, the canvas scoring mode of the Decibel ScorePlayer app allows for other applications, such as Max, to send drawing commands to the ScorePlayer via OSC. Several examples of implementations of generative and animated notation scores are discussed and evaluated. An object model has been developed allowing for the creation of hierarchies of drawn elements. The object model defines a framework of commands that can be used to create and control these objects, and supporting examples describe the way in which scores can be developed to take advantage of this new scoring mode. Secondly, a python scoreplayer - external library has been developed, defining two python classes: scorePlayerExternal that makes a connection to the iPad, opening a UDP listening socket and letting the iPad know which port to send its replies to, and scoreObject which is responsible for creating and drawing objects populated on the canvas display window of the Decibel ScorePlayer. It acts as a wrapper to the raw OSC commands so that programming can be done using object-oriented paradigms. Thirdly, the ScoreCreator, an application developed for Mac OSX for automating the process of making scores for the Decibel ScorePlayer, has been expanded allowing for the defining of a range of score types and functionalities.
	</div>
	<pre id='bibtex2019-12' class='collapse proc-bibtex'>
@inproceedings{Wyatt_tenor2019,
  Address = {Melbourne, Australia},
  Author = { Aaron Wyatt and Lindsay Vickery and Stuart James },
  Title = {Unlocking the Decibel ScorePlayer},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'19},
  Pages = {61--68},
  Year = {2019},
  Editor = {Cat Hope and Lindsay Vickery and Nat Grant},
  Publisher = {Monash University},
  ISBN = {978-0-6481592-5-4}
}
	</pre>
</div>
</div>
</section>

 <!-- ========================================================================= -->

    <section id="2018">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2018</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>
        
<div class='container'>
<div class='row tenor-paper'>
  <a href='proceedings/TENOR2018-Proceedings.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
  <div class='proc-title'>FULL TENOR'18 PROCEEDINGS</div>
  <span class='proc-button' data-toggle='collapse' data-target='#bibtex2018'>Bibtex</span>
  | <a href="proceedings/bibtex2018.bib" class="tenor-bibtex">.bib</a>

  <pre id='bibtex2018' class='collapse proc-bibtex'>
@book{tenor2018,
  Address = {Paris, France},
  Title = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Year = {2018},
  Editor = "Sandeep Bhagwati and Jean Bresson",
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
  </pre>
</div>
<hr>
</div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2018/01_Skold_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Combining Sound- and Pitch-Based Notation for Teaching and Composition</div>
	<div class='proc-auth'>Mattias Sköld</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-1'>Bibtex</span>
	<div id='abstract2018-1' class='collapse proc-abstract'>
My research is concerned with finding a common notation for pitch-based, sound-based and spatialized music in an attempt to bridge the gap between acoustic and electronic music, also working towards the possibility of a holistic system for algorithmic composition based on music representation. This paper describes the first step towards this goal, focusing on the combination of pitch-based and sound-based musical structures, introducing a graphical notation system that combines traditional music notation with electroacoustic music analysis notation. I present how this was tested in practice in a case study within the framework of composition education at the Royal College of Music in Stockholm, where composition students were working with, and reacting to, the system.
	</div>
	<pre id='bibtex2018-1' class='collapse proc-bibtex'>
@inproceedings{Skold_tenor2018,
  Address = {Montreal, Canada},
  Author = { Mattias Sköld },
  Title = {Combining Sound- and Pitch-Based Notation for Teaching and Composition},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {1--6},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/02_Couprie_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Methods and Tools for Transcribing Electroacoustic Music</div>
	<div class='proc-auth'>Pierre Couprie</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-2'>Bibtex</span>
	<div id='abstract2018-2' class='collapse proc-abstract'>
This article presents some tools and methods to carry out transcriptions of electroacoustic music. It introduces the relationship between sound analysis and image or drawing at the birth of electroacoustic music and explains the interest of creating transcriptions. The article contains a proposed framework, based on several years of practice, which links musical analysis to transcription, sound analysis and representation. The different parts of a transcription are then detailed and methods are proposed to create annotations with reference to various examples I have created since the late 1990s. The last section presents the EAnalysis package, developed with Simon Emmerson and Leigh Landy at Leicester's De Montfort University, in order to create a tool for analyzing, transcribing and representing electroacoustic music. It introduces the interface, the architecture and the transcription features of this piece of software in relation to other technologies.
	</div>
	<pre id='bibtex2018-2' class='collapse proc-bibtex'>
@inproceedings{Couprie_tenor2018,
  Address = {Montreal, Canada},
  Author = { Pierre Couprie },
  Title = {Methods and Tools for Transcribing Electroacoustic Music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {7--16},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/03_Bell_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Audiovisual Scores and Parts Synchronized Over the Web</div>
	<div class='proc-auth'>Jonathan Bell</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-3'>Bibtex</span>
	<div id='abstract2018-3' class='collapse proc-abstract'>
Typing smartvox.eu into the address bar of the browser of several phones, tablets and/or computers simultaneously is a simple way to understand what this web application is about: the different parts of the same musical score are being synchronized over the internet, through a remote server. This form of music making falls under the category of 'networked music performance', and addresses questions regarding what becomes a live performance of chamber music when musicians are distanced from each other, when sheet music is replaced by screens and headphones, or when the form of the piece is generated live by algorithms. The scores, composed in the Bach environment, display a scrolling playhead in proportional notation, bypassing conventional bars and beat rhythmic notation. Providing the performer with audio-scores and animated musical representation undoubtedly simplifies and speeds up the rehearsal process, but large forces (such as 80 simultaneous connections) and the constraints of a concert situation still leave numerous technical problems unsolved (mainly concerned with synchronization between devices, and server saturation), to which the present paper will attempt to partially formulate a response.
	</div>
	<pre id='bibtex2018-3' class='collapse proc-bibtex'>
@inproceedings{Bell_tenor2018,
  Address = {Montreal, Canada},
  Author = { Jonathan Bell },
  Title = {Audiovisual Scores and Parts Synchronized Over the Web},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {17--23},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/04_Bhagwati_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Elaborate Audio Scores: Concepts, Affordances and Tools</div>
	<div class='proc-auth'>Sandeep Bhagwati</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-4'>Bibtex</span>
	<div id='abstract2018-4' class='collapse proc-abstract'>
Over the past 18 years, I have repeatedly worked with auditive tools and audio scores that completely replaced any written score. The paper examines characteristics of the type of elaborate, autonomous audio score that I de-veloped during this time, as well as attempts a preliminary classification of the compositional affordances that differentiate audio scores from visual scores. It describes the conveyance modes unique to audio scores; it touches on questions of control and context in elaborate audio scores, including on the question of whether such audio scores must necessarily be comprovisation scores; it details how, in the context of elaborate audio scores, the terms “practicing” and “rehearsal” describe other kinds of activities than they do in the context of visual scores; and it discusses unique problems of timing in the perfor-mance and composition of elaborate audio scores.
	</div>
	<pre id='bibtex2018-4' class='collapse proc-bibtex'>
@inproceedings{Bhagwati_tenor2018,
  Address = {Montreal, Canada},
  Author = { Sandeep Bhagwati },
  Title = {Elaborate Audio Scores: Concepts, Affordances and Tools},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {24--32},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/05_Santini_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>LINEAR (Live-generated Interface and Notation Environment in Augmented Reality)</div>
	<div class='proc-auth'>Giovanni Santini</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-5'>Bibtex</span>
	<div id='abstract2018-5' class='collapse proc-abstract'>
Recent developments in Augmented Reality (AR) technology are opening up new modes of representation and interaction with virtual objects; at the same time, increase in processing power of portable devices is enabling a wide diffusion of applications until recently usable only in very specific situations (like motion-capture labs). This study aims to describe an AR environment created for musical performance: LINEAR (Live-generated Interface and Notation Environment in Augmented Reality), where the author explored some perspectives made possible by the current state of AR technology applied to music. In LINEAR, one dedicated performer using an AR iPhone app, can create virtual objects (rendered in real-time and superimposed to the real environment) according to the movement of the device; they are used both as virtual interfaces for electronics (sending OSC message to Max/MSP on a computer) and as forms of live-generated graphic notation. LINEAR allows, with some limitations, the representation of gestural movements with an exact 3-D placement in space: we can now have an analogic notation of gestures, rather than a symbolic one. For the iPhone performer, the act of notation corresponds to the notated act. The resulting representations can be also approached as graphic animated notation by other performers (the iPhone screen is mirrored to a projector). The multiple perspectives on the notation and the possibilities of interaction with virtual bodies allow a high level of flexibility, while introducing some almost unprecedented resources and foreseeing a very rich scenario.
	</div>
	<pre id='bibtex2018-5' class='collapse proc-bibtex'>
@inproceedings{Santini_tenor2018,
  Address = {Montreal, Canada},
  Author = { Giovanni Santini },
  Title = {LINEAR (Live-generated Interface and Notation Environment in Augmented Reality)},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {33--42},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/06_Goudard_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>John, the Semi-Conductor: A Tool for Comprovisation</div>
	<div class='proc-auth'>Vincent Goudard</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-6'>Bibtex</span>
	<div id='abstract2018-6' class='collapse proc-abstract'>
This article presents “John”, an open-source software designed to help collective free improvisation. It provides generated screen-scores running on distributed, reactive web-browsers. The musicians can then concurrently edit the scores in their own browser. John is used by ONE, a septet playing improvised electro-acoustic music with digital musical instruments (DMI). One of the original features of John is that its design takes care of leaving the musician's attention as free as possible. Firstly, a quick review of the context of screen-based scores will help situate this research in the history of contemporary music notation. Then I will trace back how improvisation sessions led to John's particular “notational perspective”. A brief description of the software will precede a discussion about the various aspects guiding its design.
	</div>
	<pre id='bibtex2018-6' class='collapse proc-bibtex'>
@inproceedings{Goudard_tenor2018,
  Address = {Montreal, Canada},
  Author = { Vincent Goudard },
  Title = {John, the Semi-Conductor: A Tool for Comprovisation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {43--49},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/07_Gironnay_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Exploring with ILÉA Ensemble: Shaping Freedom in Improvised Music</div>
	<div class='proc-auth'>Kevin Gironnay</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-7'>Bibtex</span>
	<div id='abstract2018-7' class='collapse proc-abstract'>
This paper approaches the topic of experimental impro-vised music within an ensemble, and will first present several techniques used in the field of non-idiomatic improvised music, especially in the case of collaborative improvisation such as within Cobra (J. Zorn) and En-semble SuperMusique. After discussing the limitations of these techniques, the method of Ensemble ILÉA will be introduced along with its techniques and solutions to guide an ensemble without restraining the expressivity of the improvisers or limiting the experience of the audi-ence.
	</div>
	<pre id='bibtex2018-7' class='collapse proc-bibtex'>
@inproceedings{Gironnay_tenor2018,
  Address = {Montreal, Canada},
  Author = { Kevin Gironnay },
  Title = {Exploring with ILÉA Ensemble: Shaping Freedom in Improvised Music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {50--54},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/08_Louzeiro_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Improving Sight-Reading Skills through Dynamic Notation – the Case of Comprovisador</div>
	<div class='proc-auth'>Pedro Louzeiro</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-8'>Bibtex</span>
	<div id='abstract2018-8' class='collapse proc-abstract'>
This paper proposes an approach to sight-reading improvement using a dynamic notation system – Comprovisador. The system was created with the goal of coordinating musical performances in which a soloist improvises and an ensemble of musicians sight-read a staff-based dynamic score. This situative score is therefore generated by Comprovisador's algorithms which feed on the soloist's improvisation. Musicians read the score from computer screens, in a local network. This kind of musical practice requires performers to be good sight-readers. A good sight-reader (of traditional notation) often relies on pattern recognition, understanding of musical structure and other abilities which come from being familiarized with certain repertoires – but when dealing with situative scores these abilities are seldom relevant. With this consideration, a Practice Tool was developed as part of Comprovisador to allow musicians to get acquainted with the system's notation interface and to learn (not the notes, but) how to deal with not being able to predict patterns or structure. After further development, this tool was tested by music students and teachers in order to assess its applicability in an educational context regarding improvement of sight-reading skills. A study with those participants is presented to validate the utility of the system and identify areas for further development.
	</div>
	<pre id='bibtex2018-8' class='collapse proc-bibtex'>
@inproceedings{Louzeiro_tenor2018,
  Address = {Montreal, Canada},
  Author = { Pedro Louzeiro },
  Title = {Improving Sight-Reading Skills through Dynamic Notation – the Case of Comprovisador},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {55-61},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/09_Zagorac_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>ZScore: A Distributed System For Integrated Mixed Music Composition and Performance</div>
	<div class='proc-auth'>Slavko Zagorac, Patricia Alessandrini</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-9'>Bibtex</span>
	<div id='abstract2018-9' class='collapse proc-abstract'>
This paper proposes a distributed system design for mixed ensemble music composition and performance of stave-based dynamic scores. ZScore is a collection of third-party and newly-developed components which aims to implement described networked notation solutions. The solution scope includes complex notation authoring, reliable score data distribution over a network to heterogeneous clients, precise performance scheduling and dynamic rendering of interactive scores. Taking the specification of optimal system features as a starting point, this paper looks at suitable solutions from other industries where high-throughput, low-latency systems have been successfully implemented. It presents the case for SVG-based notation representation, its distribution over a reliable message-oriented middleware and the innovative alternating pane layout design for dynamic notation rendering. Finally, the paper describes the current state of ZScore development and outcomes from initial user trials. It concludes with future perspectives towards realizing the underlying ambition behind this project: to blur and thereby call into question the traditional boundaries between the roles of a composer, performer, conductor and audience through the effective utilization of cutting-edge technology.
	</div>
	<pre id='bibtex2018-9' class='collapse proc-bibtex'>
@inproceedings{Zagorac_tenor2018,
  Address = {Montreal, Canada},
  Author = { Slavko Zagorac and Patricia Alessandrini },
  Title = {ZScore: A Distributed System For Integrated Mixed Music Composition and Performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {62--70},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/10_OConnor_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Towards a Notation for Trumpet Valve Rotation</div>
	<div class='proc-auth'>Dan O'Connor, Lindsay Vickery</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-10'>Bibtex</span>
	<div id='abstract2018-10' class='collapse proc-abstract'>
Many contemporary performers and composers seek new sounds through extension of traditional instrument techniques. For the trumpet one such extended technique is valve rotation, the rotation of a trumpet piston valve within its casing affecting the timbral complexity of airstream effects. This paper describes the development of a system for notating valve rotation using a prescriptive graphical language and an animated interface for entering continuous rotation and airstream data.
	</div>
	<pre id='bibtex2018-10' class='collapse proc-bibtex'>
@inproceedings{Oconnor_tenor2018,
  Address = {Montreal, Canada},
  Author = { Dan O'Connor and Lindsay Vickery },
  Title = {Towards a Notation for Trumpet Valve Rotation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {71--76},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/11_Foscarin_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Gioqoso, an On-line Quality Assessment Tool for Music Notation</div>
	<div class='proc-auth'>Francesco Foscarin, David Fiala, Florent Jacquemart, Philippe Rigaux, Virginie Thion</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-11'>Bibtex</span>
	<div id='abstract2018-11' class='collapse proc-abstract'>
Quality is a daily concern to everyone involved in the production of digitized scores. We propose an on-line interface devoted to music notation, freely accessible to the community, intended to help users to assess the quality of a score thanks to a combination  of automatic and interactive tools. This interface analyzes a score supplied in MusicXML or MEI, and reports quality problems evaluated with respect to a taxonomy of quality rules. We expose  the motivation, describe the interface, and present the methodology. 
	</div>
	<pre id='bibtex2018-11' class='collapse proc-bibtex'>
@inproceedings{Foscarin_tenor2018,
  Address = {Montreal, Canada},
  Author = { Francesco Foscarin and David Fiala and Florent Jacquemart and Philippe Rigaux and Virginie Thion },
  Title = {Gioqoso, an On-line Quality Assessment Tool for Music Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {77--84},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/12_Kosta_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>MazurkaBL: Score-aligned Loudness, Beat, and Expressive Markings Data for 2000 Chopin Mazurka Recordings</div>
	<div class='proc-auth'>Katerina Kosta, Oscar F. Bandtlow, Elaine Chew</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-12'>Bibtex</span>
	<div id='abstract2018-12' class='collapse proc-abstract'>
Large-scale analysis of expressive performance—with focus on how a performer responds to score markings---has been limited by a lack of big datasets of recordings with accurate beat and loudness information with score markings. To bridge this gap, we created the MazurkaBL dataset, a collection of score-beat positions and loudness values, with corresponding score dynamic and tempo markings for 2000 recordings of forty-four Chopin Mazurkas. MazurkaBL forms the largest annotated expressive performance dataset to date. This paper describes how the dataset was created, and variations found in the dataset. For each Mazurka, the recordings were first aligned to the score and one to another to facilitate the transfer of meticulously created manual beat annotations from one reference to all other recordings. We propose a multi-recording alignment heuristic that optimises the reference audio choice for best average alignment results. Loudness values in sones are extracted and analysed; we also provide the score position of dynamic and tempo markings. The result is a rich repository of score-aligned loudness, beat, and expressive marking data for studying expressive variations. We further discuss recent and future applications of MazurkaBL and future directions for database development.
	</div>
	<pre id='bibtex2018-12' class='collapse proc-bibtex'>
@inproceedings{Kosta_tenor2018,
  Address = {Montreal, Canada},
  Author = { Katerina Kosta and Oscar F. Bandtlow and Elaine Chew },
  Title = {MazurkaBL: Score-aligned Loudness, Beat, and Expressive Markings Data for 2000 Chopin Mazurka Recordings},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {85--94},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/13_Asmar_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Traditional Modal Monodies Generative Grammar Encoding in the Music Encoding Initiative</div>
	<div class='proc-auth'>Mark Asmar, Talar Atéchian, Nidaa Abou Mrad, Sylvaine Leblond Martin</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-13'>Bibtex</span>
	<div id='abstract2018-13' class='collapse proc-abstract'>
Encoding written music with a textual format is a technology developed for exchanging and analyzing digital music scores. In the literature, many standards exist for this purpose, such as, MusicXML and the Music Encoding Initiative (MEI). The Music Encoding Initiative is a standard developed for encoding music scores in XML. It supports the encoding of different types of notations, such as, Common Music Notation, Neumes Notation, etc. It encodes many features and elements related to musical components such as the pitch name, the octave and the duration of notes. However, for the researchers in musicology, additional information are necessary to enrich the MEI and in order to provide more specific music analysis. In this paper, we target the modal monodies analysis. Thus, we propose to enrich the MEI by appending to its initial schema additional information extracted from the generative grammar of modal monodies. The proposed solution consists of adding a custom module to the MEI containing new elements and attributes. In addition, a new semi-automated analysis component is proposed for the analysis of traditional Modal Monodies of the Middle East and the Mediterranean cultures.
	</div>
	<pre id='bibtex2018-13' class='collapse proc-bibtex'>
@inproceedings{Asmar_tenor2018,
  Address = {Montreal, Canada},
  Author = { Mark Asmar and Talar Atéchian and Nidaa Abou Mrad and Sylvaine Leblond Martin },
  Title = {Traditional Modal Monodies Generative Grammar Encoding in the Music Encoding Initiative},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {95--103},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/14_Giraud_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Dezrann, a Web Framework to Share Music Analysis</div>
	<div class='proc-auth'>Mathieu Giraud, Richard Groult, Emmanuel Leguy</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-14'>Bibtex</span>
	<div id='abstract2018-14' class='collapse proc-abstract'>
Music analysis on traditional scores is often based on annotated elements, such as patterns, harmonies, or sections. Music students, teachers, players, or researchers are used to annotate music and to discuss these analyses. Music lovers, even when they do not read music, also frequently talk about music and share their reaction to specific sections. We present Dezrann, an open-source web platform for music annotation and analysis on scores in traditional notation, developed with the Web Components through the Polymer framework. Dezrann enables to view, edit, and share music analysis through sets of labels on a score or a waveform. Labels are linked to musical positions and possibly to voices of the score, and can have a duration or not. They can be created or edited with simple mouse or finger gestures. A public server is available to test the application on Bach fugues and chorales as well as on Mozart string quartets.
	</div>
	<pre id='bibtex2018-14' class='collapse proc-bibtex'>
@inproceedings{Giraud_tenor2018,
  Address = {Montreal, Canada},
  Author = { Mathieu Giraud and Richard Groult and Emmanuel Leguy },
  Title = {Dezrann, a Web Framework to Share Music Analysis},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {104--110},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/15_Gottfried_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Symbolist: An Open Authoring Environment for User-Defined Symbolic Notation</div>
	<div class='proc-auth'>Rama Gottfried, Jean Bresson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-15'>Bibtex</span>
	<div id='abstract2018-15' class='collapse proc-abstract'>
We present symbolist, a graphic notation environment for music and multimedia. symbolist is based on an Open Sound Control (OSC) encoding of symbols representing multi-rate and multidimensional control data, which can be streamed as control messages to audio processing or any kind of media environment. Symbols can be designed and composed graphically, and brought in relationship with other symbols. The environment provides tools for creating symbol groups and stave references, by which symbols maybe timed and used to constitute a structured and executable multimedia score.
	</div>
	<pre id='bibtex2018-15' class='collapse proc-bibtex'>
@inproceedings{Gottfried_tenor2018,
  Address = {Montreal, Canada},
  Author = { Rama Gottfried and Jean Bresson },
  Title = {Symbolist: An Open Authoring Environment for User-Defined Symbolic Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {111--118},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/16_Hunt_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Cognitive Dimensions Approach for the Design of an Interactive Generative Score Editor</div>
	<div class='proc-auth'>Samuel Hunt, Thomas Mitchell, Chris Nash</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-16'>Bibtex</span>
	<div id='abstract2018-16' class='collapse proc-abstract'>
This paper describes how the Cognitive Dimensions of Notation can guide the design of algorithmic composition tools. Prior research has also used the cognitive dimensions for analysing interaction design for algorithmic composition software. This work aims to address the shortcomings of existing algorithmic composition software, by utilising the more commonly used score notation interfaces, rather than patch based or code based environments. The paper sets out design requirements in each dimension and presents these in the context of a software prototype. These principles are also applicable for general music composition systems.
	</div>
	<pre id='bibtex2018-16' class='collapse proc-bibtex'>
@inproceedings{Hunt_tenor2018,
  Address = {Montreal, Canada},
  Author = { Samuel Hunt and Thomas Mitchell and Chris Nash },
  Title = {A Cognitive Dimensions Approach for the Design of an Interactive Generative Score Editor},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {119--127},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/17_Agostini_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Pitches in bach</div>
	<div class='proc-auth'>Andrea Agostini, Daniele Ghisi</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-17'>Bibtex</span>
	<div id='abstract2018-17' class='collapse proc-abstract'>
Traditionally, most computer-aided composition environments represent a pitch via a number (typically a MIDI note number or its  value in midicents), flattening the enharmonic information onto a single real-valued parameter. Although this choice is convenient in many applications, it can be very limiting in any context where diatonicism, to some degree, matters. The latest release of bach, a library for Max dedicated to musical representation and computer-aided composition, introduces a new `pitch' data type, designed to overcome this limitation by representing both diatonic pitches and intervals and supporting standard arithmetic operations. In this article we motivate and detail its implementation and its syntax. As an application, we introduce a new respelling algorithm, also implemented in \bach, designed to provide an easy-to-read spelling of notes. Differently from most existing pitch spelling algorithms, tailored on the tonal repertoire, our algorithm is targeted to produce a musician-friendly representation of non-tonal music.
	</div>
	<pre id='bibtex2018-17' class='collapse proc-bibtex'>
@inproceedings{Agostini_tenor2018,
  Address = {Montreal, Canada},
  Author = { Andrea Agostini and Daniele Ghisi },
  Title = {Pitches in bach},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {128--137},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/18_Hajdu_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>MaxScore: Recent Developments</div>
	<div class='proc-auth'>Georg Hajdu, Nick Didkovsky</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-18'>Bibtex</span>
	<div id='abstract2018-18' class='collapse proc-abstract'>
This paper presents recent development in MaxScore and its peripheral applications. These developments include: a) adding new functionality to the core mxj object including details on our implementation of an un-do/redo stack, new licensing models, custom beam groups, and other new features, b) strategies to achieve proportional notation, with a look to the future, c) expanding the feature set of the MaxScore and LiveScore Editors which include new style editors for the design of non-standard clefs, tablature nota-tion and Bohlen-Pierce microtonality, d) providing tools for greater compatibility with other third-party developments such as bach, Mira, the Scala Archive as well as the conTimbre sample li-brary and its ePlayer, e) new peripheral components for guided improvisation and situated scores, f) strategies to achieve proportional notation, with a look to the future.
	</div>
	<pre id='bibtex2018-18' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2018,
  Address = {Montreal, Canada},
  Author = { Georg Hajdu and Nick Didkovsky },
  Title = {MaxScore: Recent Developments},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {138--146},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/19_Ghisi_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>dada: Non-Standard User Interfaces for Computer-Aided Composition in Max</div>
	<div class='proc-auth'>Daniele Ghisi, Carlos Agon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-19'>Bibtex</span>
	<div id='abstract2018-19' class='collapse proc-abstract'>
This article introduces the dada library, providing Max with the ability to organize, select and generate musical content via a set of graphical interfaces manifesting an interactive, explorative approach. Its modules address a range of scenarios, including, but not limited to, database visualization, score segmentation and analysis, concatenative synthesis, music generation via physical or geometrical modelling, wave terrain synthesis, graph exploration, cellular automata, swarm intelligence, and videogames. The library is open-source and extendable; similarly to bach, it fosters a performative approach to computer-aided composition (as opposed to traditional off-line techniques): the outcome of all its interfaces can be recorded in scores, or used in real time to drive, among other things, digital signal processes, score transformations, video treatments, or physical actuators.
	</div>
	<pre id='bibtex2018-19' class='collapse proc-bibtex'>
@inproceedings{Ghisi_tenor2018,
  Address = {Montreal, Canada},
  Author = { Daniele Ghisi and Carlos Agon },
  Title = {dada: Non-Standard User Interfaces for Computer-Aided Composition in Max},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {147--156},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/20_Merlier_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Space Notation in Electroacoustic Music: From Gestures to Signs</div>
	<div class='proc-auth'>Bertrand Merlier</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-20'>Bibtex</span>
	<div id='abstract2018-20' class='collapse proc-abstract'>
This article is based on an analysis of the functionalities of many devices and software used for sound spatialization, an original research about space perception modes and finally an in-depth study about musical notation systems. Theses studies lead the author to propose a notation system for spatialization activities, simply based on the paradigm of our Western classical music notation. Various examples illustrate the merits and versatility of this proposal. The present notation is both descriptive and prescriptive. Thus, a practical implementation based on MIDI standard also makes possible instrumental space performances, implemen-tation of algorithmic processes, space writing and structuring, but also offers access to all the existing software such as MIDI sequencer, MIDI computing and score writing. The MIDISpat plug-in – developed by the author – has been used for many years inside of Reaper digital audio sequencer.
	</div>
	<pre id='bibtex2018-20' class='collapse proc-bibtex'>
@inproceedings{Merlier_tenor2018,
  Address = {Montreal, Canada},
  Author = { Bertrand Merlier },
  Title = {Space Notation in Electroacoustic Music: From Gestures to Signs},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {157--164},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/21_Vickery_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Some Approaches to Representing Sound with Colour and Shape</div>
	<div class='proc-auth'>Lindsay Vickery</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-21'>Bibtex</span>
	<div id='abstract2018-21' class='collapse proc-abstract'>
In recent times much of the practice of musical notation and representation has begun a gradual migration away from the monochrome standard that existed since the emergence of printed Non-Western music in the 16th century, towards the full colour pallet afforded by modern printers and computer screens. This move has expanded the possibilities available for the representation of infor-mation in the musical score. Such an expansion is argua-bly necessitated by the growth of new musical techniques favouring musical phenomena that were previously poor-ly captured by traditional Western musical notation. As time-critical form of visualisation there is a strong imper-ative for the musical score to employ symbols that signi-fy sonic events and the method of their execution with maximal efficiency. One important goal in such efficien-cy is “semantic soundness”: the degree to which graphical representations makes inherent sense to the reader. This paper explores the implications of recent research into cross-modal colour-to-sound and shape-to sound map-pings for the application of colour and shape in musical scores. The paper also revisits Simon Emmerson’s Super-Score concept as a means to accommodate multiple syn-chronised forms of sonic representation (the spectrogram and spectral descriptors for example) together with alter-native notational approaches (gestural, action-based and graphical for example) in a single digital document. 
	</div>
	<pre id='bibtex2018-21' class='collapse proc-bibtex'>
@inproceedings{Vickery_tenor2018,
  Address = {Montreal, Canada},
  Author = { Lindsay Vickery },
  Title = {Some Approaches to Representing Sound with Colour and Shape},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {165--173},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/22_Noble_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Removing the Imaginary Boundary between Score and Work: Interactive Geometrical Notation</div>
	<div class='proc-auth'>Jason Noble</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-22'>Bibtex</span>
	<div id='abstract2018-22' class='collapse proc-abstract'>
In many notational practices in late 20th- and early 21st- century music, the score has a visual artistry all its own. Nevertheless, even heavily graphical Augenmusik scores are often experienced only by the composer and perform-er, and are not part of the audience's visual experience of performance. Because elements from non-auditory modal-ities (especially visual) seem essential to many musical works, I argue for a multimodal understanding of such pieces, removing the imaginary boundary between score and work. I discuss a type of aleatoric, flowchart-like geometrical notation that I frequently use in my own compositions, using hybrid notation combining standard musical notation with geometrical forms. This kind of notation helps clarify the analogy between visual and auditory modalities. In my piece simple geometries, I integrate geometrical notation into performance with the projection of an interactive, animated score that uses movement and changes of zoom perspective to make the logic of the work’s open form accessible to the audience.
	</div>
	<pre id='bibtex2018-22' class='collapse proc-bibtex'>
@inproceedings{Noble_tenor2018,
  Address = {Montreal, Canada},
  Author = { Jason Noble },
  Title = {Removing the Imaginary Boundary between Score and Work: Interactive Geometrical Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {174--180},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/23_Kim-Boyle_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Reframing the Listening Experience Through the Projected Score</div>
	<div class='proc-auth'>David Kim-Boyle</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-23'>Bibtex</span>
	<div id='abstract2018-23' class='collapse proc-abstract'>
Over the past ten years, performance scores have been radically foregrounded in a variety of performance practic-es. Whether such notations assume a prescriptive func-tion, visually projected for musicians to interpret, or a descriptive one, unfolding as a documentation of a live coding performance, how might such a foregrounding reframe the listening process for an audience? Does a notational schema help promote a deeper, structural level understanding of a musical work?  This paper will con-sider these various questions, exploring how principles of graphic design and the transparency of notation contribute to the listening experience. It will suggest that works featuring projected scores find aesthetic value in the jux-taposition of notation's traditionally mnemonic function and the unique temporal modalities that projected scores establish. 
	</div>
	<pre id='bibtex2018-23' class='collapse proc-bibtex'>
@inproceedings{Kim-Boyle_tenor2018,
  Address = {Montreal, Canada},
  Author = { David Kim-Boyle },
  Title = {Reframing the Listening Experience Through the Projected Score},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {181--185},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/24_Klinkenberg_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Combination of Graphic Notation and Microtonal Pitch Notation in the Video Score of the Opera "The Cross of the Engaged"</div>
	<div class='proc-auth'>Christian Klinkenberg</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-24'>Bibtex</span>
	<div id='abstract2018-24' class='collapse proc-abstract'>
This paper describes a procedure for isolating pitch nota-tion in the environment of a flexible real-time graphic video notation. It aims to combine precise microtonal pitch and the flexible interpretation of other parameters such as rhythm, volume, attack and decay. The procedure was developed and tested in the opera The Cross of the Engaged. The pitch is notated exclusively by note heads and accidentals on the lower third of the screen, some-times supplemented by short written explanations or pictograms. These note heads are linked to a correspond-ing graphic element on the upper part of the screen by using the same color. Each musician, conductor, director, singer and technician was given a custom-made video file, playable on his or her private laptop or tablet, re-gardless of operating system or video player app used.
	</div>
	<pre id='bibtex2018-24' class='collapse proc-bibtex'>
@inproceedings{Klinkenberg_tenor2018,
  Address = {Montreal, Canada},
  Author = { Christian Klinkenberg },
  Title = {A Combination of Graphic Notation and Microtonal Pitch Notation in the Video Score of the Opera "The Cross of the Engaged"},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {186--192},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/25_Hope_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Scoring an Animated Notation Opera -- The Decibel Score Player and the Role of the Digital Copyist in 'Speechless'</div>
	<div class='proc-auth'>Cat Hope, Aaron Wyatt, Daniel Thorpe</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-25'>Bibtex</span>
	<div id='abstract2018-25' class='collapse proc-abstract'>
This paper outlines the developments made to the Decibel ScorePlayer, the software that enables the delivery of the digital, graphic animated score of an hour long new opera by composer Cat Hope, entitled Speechless. The Decibel ScorePlayer is an iPad application that delivers the coordinated reading of graphic notation that was first created in 2012 and has been updated regularly ever since it was made available on the iTunes store the following year. Engaging the software to deliver the score for an hour long opera featuring a thirty piece orchestra, a thirty voice choir and four soloists saw considerable improvements made, contributing to a smooth running workshop period for the work. The workshop saw the score for the opera being updated, revised, added to and shared with different sections of musicians, vocalists, technicians and stage managers daily. This paper summarises the major additions to the score player software that came about as a result of this workshopping period and discusses pro-cedures, developments and contributions engaged to facilitate the score updating process in a digital score for a large-scale work.
	</div>
	<pre id='bibtex2018-25' class='collapse proc-bibtex'>
@inproceedings{Hope_tenor2018,
  Address = {Montreal, Canada},
  Author = { Cat Hope and Aaron Wyatt and Daniel Thorpe },
  Title = {Scoring an Animated Notation Opera -- The Decibel Score Player and the Role of the Digital Copyist in 'Speechless'},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {193--200},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2018/26_Finbloom_tenor18.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Scoring for Conversation</div>
	<div class='proc-auth'>Aaron Finbloom</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2018-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2018-26'>Bibtex</span>
	<div id='abstract2018-26' class='collapse proc-abstract'>
This paper discusses the prospects of using verbal notation to score live conversation. It defines a practice of conversation scoring that lies in-between two poles of structured conversations 1) where the content is entirely scripted, and 2) in which a conversation is structured primarily based on an initial set of static conditions (ex. location, time, roles, etc). By working in this middle-ground, conversation scores push conversation to new pedagogical, formal, and methodological limits, while retaining critical elements of conversation such as: spontaneous interruptibility, investment in a subject matter, and a non-linear yet quasi-coherent thought pathway or topic. This paper will discuss notable examples of event-scores both as a means of distinguishing this practice from other verbal notational practices, and for the purposes of elucidating key notational methods which have influenced this practice. The bulk of the paper will then go on to discuss various types of conversational semantic (and para-semantic) directives and end by discussing mechanisms for sequencing these directives. It is my hope that by expanding scoring into a live conversational field, that the practice of conversation itself can be expanded by adopting notational methodologies and aesthetic components that allows us to conceive of conversation as not entirely bound by its content, but defined by its dynamic movements and performative parameters.
	</div>
	<pre id='bibtex2018-26' class='collapse proc-bibtex'>
@inproceedings{Finbloom_tenor2018,
  Address = {Montreal, Canada},
  Author = { Aaron Finbloom },
  Title = {Scoring for Conversation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'18},
  Pages = {201--208},
  Year = {2018},
  Editor = {Sandeep Bhagwati and Jean Bresson},
  Publisher = {Concordia University},
  ISBN = {978-1-5251-0551-7}
}
	</pre>
</div>
</div>
</section>

 <!-- ========================================================================= -->

    <section class="proc-altern" id="2017">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2017</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>

<div class='container'>
<div class='row tenor-paper'>
  <a href='proceedings/TENOR2017-Proceedings.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
  <div class='proc-title'>FULL TENOR'17 PROCEEDINGS</div>
  <span class='proc-button' data-toggle='collapse' data-target='#bibtex2017'>Bibtex</span>
  | <a href="proceedings/bibtex2017.bib" class="tenor-bibtex">.bib</a>

  <pre id='bibtex2017' class='collapse proc-bibtex'>
@book{tenor2017,
  Address = {A Coru\~{n}a, Spain},
  Title = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Corun\~{n}a},
  ISBN = {978-84-9749-666-7}}
  </pre>
</div>
<hr>
</div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2017/00_Haus_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Digitization of historial music archives: Preserving the past, embracing the future</div>
	<div class='proc-auth'>Goffredo Haus, Luca A. Ludovico</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-1'>Bibtex</span>
	<div id='abstract2017-1' class='collapse proc-abstract'>
Cultural institutions dealing with music (opera houses, conservatories, public and private collections, etc.) often hold huge archives made of music related heterogeneous materials. These subjects can greatly benefit from digitization campaigns and the consequent adoption of ICT techniques as it regards not only the preservation, but also the exploitation and revivification of their content. This paper, that summarizes the keynote speech held at the 3rd  International Conference on Technologies for Music Notation and Representation (TENOR 2017), starts from the experiences of the Teatro alla Scala and the Ricordi Historical Archive in order to show the new possibilities emerging from the adoption of computer-based technologies and approaches.
	</div>
	<pre id='bibtex2017-1' class='collapse proc-bibtex'>
@inproceedings{Haus_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Goffredo Haus and Luca A. Ludovico },
  Title = {Digitization of historial music archives: Preserving the past, embracing the future},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {1--8},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/01_Hajdu_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>MACAQUE — A tool for spectral processing and transcription</div>
	<div class='proc-auth'>George Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-2'>Bibtex</span>
	<div id='abstract2017-2' class='collapse proc-abstract'>
This paper describes Macaque, a tool for spectral processing and transcription, in development since 1996. Macaque was programmed in Max and, in 2013, embedded into the MaxScore ecosystem. Its GUI offers several choices for the processing and transcription of SDIF partial-track files into standard music notation. At the core of partial-track transcription is an algorithm capable of “attracting” partial tracks (and fragments thereof) into single staves, thereby performing an important aspect of “spectral orchestration.”
	</div>
	<pre id='bibtex2017-2' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { George Hajdu },
  Title = {MACAQUE — A tool for spectral processing and transcription},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {9--15},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/02_Calvo-Zaragoza_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> A machine learning framework for the categorization of elements in images of musical documents</div>
	<div class='proc-auth'>Jorge Calvo-Zaragoza, Gabriel Vigliesoni, Ichiro Fujinaga</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-3'>Bibtex</span>
	<div id='abstract2017-3' class='collapse proc-abstract'>
Musical documents may contain heterogeneous information such as music symbols, text, staff lines, ornaments, annotations, and editorial data. Before any attempt at automatically recognizing the information on scores, it is usually necessary to detect and classify each constituent layer of information into different categories. The greatest obstacle of this classification process is the high heterogeneity among music collections, which makes it difficult to propose methods that can be generalizable to a broad range of sources. In this paper we propose a novel machine learning framework that focuses on extracting the different layers within musical documents by categorizing the image at pixel level. The main advantage of our approach is that it can be used regardless of the type of document provided, as long as training data is available. We illustrate some of the capabilities of the framework by showing examples of common tasks that are frequently performed on images of musical documents, for which our approach has shown promising performance. We believe our framework will allow the development of generalizable and scalable automatic music recognition systems from document images, thus facilitating the creation of large-scale browsable and searchable repositories of music documents.
	</div>
	<pre id='bibtex2017-3' class='collapse proc-bibtex'>
@inproceedings{Calvo-Zaragoza_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Jorge Calvo-Zaragoza and Gabriel Vigliesoni and Ichiro Fujinaga },
  Title = { A machine learning framework for the categorization of elements in images of musical documents},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {17--23},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/03_Barate_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A web Interface for the analysis and performance of aleatory music notation</div>
	<div class='proc-auth'>Adriano Baratè, Luca A. Ludovico</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-4'>Bibtex</span>
	<div id='abstract2017-4' class='collapse proc-abstract'>
Black and White n.2 is a collection of 120 exercises for keyboard instrument(s) written by the Italian composer Franco Donatoni. Conceived as aleatory music, this composition adopts a non-conventional way to encode the score where some parameters are fixed and others are left to chance. In this work, we will describe a Web-based framework that, after inserting user-defined scores in Donatoni's notation, is able to automatically produce score versions compatible with the composer's constraints and executable by a human player. This application produces modern staff notation and can perform it via the Web Audio API. The goal is on one side to revive the interest towards aleatory music literature, and Donatoni's repertoire in particular, and on the other to investigate the compositional and computational process that originate a given score out of many aleatory variants.
	</div>
	<pre id='bibtex2017-4' class='collapse proc-bibtex'>
@inproceedings{ Barate_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Adriano Baratè and Luca A. Ludovico },
  Title = {A web Interface for the analysis and performance of aleatory music notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {25--31},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/04_Kim-Boyle_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The 3-D score</div>
	<div class='proc-auth'>David Kim-Boyle</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-5'>Bibtex</span>
	<div id='abstract2017-5' class='collapse proc-abstract'>
This paper examines attempts by composers to transcend the two-dimensional constraints of the printed page in musical notation. The author reviews how material depth in printed media has been explored to help create new structural forms and two of the author’s works which feature real-time, three-dimensional scores are examined. Incumbent technical limitations and constraints of multidimensional notational schemas are discussed and the author concludes by arguing that the reading through of a notational schema affords a new spatial ontology for the works represented.
	</div>
	<pre id='bibtex2017-5' class='collapse proc-bibtex'>
@inproceedings{Kim-Boyle_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { David Kim-Boyle },
  Title = {The 3-D score},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {33--38},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/05_Ham_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>An architectural approach to 3D spatial drum notation</div>
	<div class='proc-auth'>Jeremy J. Ham</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-6'>Bibtex</span>
	<div id='abstract2017-6' class='collapse proc-abstract'>
This research has evolved from creative practice focused on inter-disciplinary positioning between the domains of music and architecture. Through engagement in the theories and practice of architectural representation and the computational tools of spatial design, a new form of 3D spatial drum notation is presented. This notation seeks to compliment the capacities of traditional drum notation and overcome issues inherent in a theoretical ‘musico-perspectival hinge’ between the notation and the meaning of the notation. A representational schema of the spatial drum notation is discussed in the first instance in relation to the development of a lexicon of referent drum patterns and phrases and then in the testing of notation on a multi-layered improvised ‘drumscape’ composition. The paper culminates in the extension beyond notation into the realm of music spatialization through 3D printing, digital fabrication and Virtual Reality.
	</div>
	<pre id='bibtex2017-6' class='collapse proc-bibtex'>
@inproceedings{Ham_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Jeremy J. Ham },
  Title = {An architectural approach to 3D spatial drum notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {39--49},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/06_Sluchin_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A CAP for graphic scores. Graphic notation and performance</div>
	<div class='proc-auth'>Benny Sluchin,  Mikhail Malt</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-7'>Bibtex</span>
	<div id='abstract2017-7' class='collapse proc-abstract'>
Many graphic scores use the pitch versus time presentation, as a natural extension of the usual notation. In the general case, it displays discrete pitches, in a fixed timeline. Nevertheless, graphic scores use a lot of continuous lines, and the vertical dimension can be adapted to a particular performance. In such a way, the instrumentation is free, and the actual range of a particular instrument can be adapted according to the notation. The present article is initiated by a search to provide the performer with adequate tools to approach the execution of such works. A computer assisted performance approach helps the player in the preparation process for both: the time and the pitch approximations. The simulation can enhance the performance in approaching the graphical notation.
	</div>
	<pre id='bibtex2017-7' class='collapse proc-bibtex'>
@inproceedings{Sluchin_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Benny Sluchin and Mikhail Malt },
  Title = {A CAP for graphic scores. Graphic notation and performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {51--56},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/07_Miller_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Are scores maps? A cartographic response to Goodman</div>
	<div class='proc-auth'>Daniel Miller</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-8'>Bibtex</span>
	<div id='abstract2017-8' class='collapse proc-abstract'>
Nelson Goodman’s theory of notation attempts to provide an ambitious, unified account of how systems of symbolic representation preserve and transmit information and how they differ from pictorial depiction. However, Goodman’s account of music and dance notation has proven unpopular, with some critics objecting to the rigor with which scores and musical symbols are assumed to designate musical works and their constituent elements. This paper reconsiders a Goodmanian account of a music notation system in the light of recent philosophical work on maps and map-like cognition. Specifically, I propose that scores do not act as compound symbols that uniquely designate musical works. Instead notational components of scores are better understood as contingent surface-level features leveraged by an underlying map-like representational structure. On this account, scores are seen to be highly conventionalized maps, and the notational symbols of scores constitute just one of multiple modes of representation and depiction harnessed by this framework. Finally, I consider several contemporary examples of music notation and discuss how a cartographic theory of notation may provide novel insights into the graphic design considerations of these scores, particularly those that rely on new notation platforms such as graphic design software or animation, where depictive and symbolic strategies are frequently hybridized.
	</div>
	<pre id='bibtex2017-8' class='collapse proc-bibtex'>
@inproceedings{Miller_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Daniel Miller },
  Title = { Are scores maps? A cartographic response to Goodman},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {57--67},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/08_Hunt_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>How can music visualisation techniques reveal different perspectives on musical structure?</div>
	<div class='proc-auth'>Samuel J. Hunt, Tom Mitchell, Chris Nash</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-9'>Bibtex</span>
	<div id='abstract2017-9' class='collapse proc-abstract'>
Standard western notation supports the understanding and performance of music, but has limited provisions for revealing overall musical characteristics and structure. This paper presents several visualisers for highlighting and providing insights into musical structures, including rhythm, pitch, and interval transitions, also noting how these elements modulate over time. The visualisations are presented in the context of Shneiderman’s Visual Information-Seeking Mantra, and terminology from the Cognitive Dimensions of Music Notations usability framework. Such techniques are designed to make understanding musical structure quicker, easier, less error prone, and take better advantage of the intrinsic pattern recognition abilities of humans.
	</div>
	<pre id='bibtex2017-9' class='collapse proc-bibtex'>
@inproceedings{Hunt_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Samuel J. Hunt and Tom Mitchell and Chris Nash },
  Title = {How can music visualisation techniques reveal different perspectives on musical structure?},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {69--78},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/09_Nuss_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Melody retrieval and composer attribution using sequence alignment on RISM incipits</div>
	<div class='proc-auth'>Jelmer van Nuss, Geert-Jan Giezeman, Frans Wiering</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-10'>Bibtex</span>
	<div id='abstract2017-10' class='collapse proc-abstract'>
The RISM A/II database is filled with the musical notations of the beginnings of more than a million melodies. The Monochord search engine can retrieve melodies that are similar to a query melody using several search methods, amongst which pitch raters, weight-based raters and duration-based raters. The performance of all 27 search methods is evaluated using mean average precision metrics and the TREC framework that is suited for retrieval performance analysis. The difference in exact pitch between melodies turns out to be the best factor to search with for musical similarity retrieval. All melodies have metadata such as a composer name, but a portion of the database is labelled as Anonymus. A k-Nearest Neighbours algorithm is optimised for the purpose of deanonymisation and used to classify several Anonymus songs to test the applicability of this classifier for composer labelling. Using a classifier for deanonymisation purposes turns out to be viable with human correction.
	</div>
	<pre id='bibtex2017-10' class='collapse proc-bibtex'>
@inproceedings{Nuss_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Jelmer van Nuss and Geert-Jan Giezeman and Frans Wiering },
  Title = { Melody retrieval and composer attribution using sequence alignment on RISM incipits},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {79--90},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/10_Cherfi_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Formalizing quality rules on music notation. An ontology-based approach.</div>
	<div class='proc-auth'>Samira Cherfi, Fayçal Hamdi, Philippe Rigaux, Virginie Thion, Nicolas Travers</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-11'>Bibtex</span>
	<div id='abstract2017-11' class='collapse proc-abstract'>
We address the issue of expressing and evaluating quality rules on music notation. Since music engraving is a highly flexible process that can hardly be constrained by universal principles and rules, score production still heavily relies on the user expertise in order to make context-dependent decisions. We therefore propose a quality management approach based on a formal modeling of this  expertise.  We show how to use such a  model to express context-aware rules that can be evaluated either a priori to prevent the production of faulty notations, or a posteriori to assess quality indicators regarding a score or a corpus of scores. The paper  proposes a simple ontology for musical notation,  shows how  quality rules can be formally stated and evaluated, and illustrates the approach with examples drawn from a large digital library of scores.
	</div>
	<pre id='bibtex2017-11' class='collapse proc-bibtex'>
@inproceedings{Cherfi_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Samira Cherfi and Fayçal Hamdi and Philippe Rigaux and Virginie Thion and Nicolas Travers },
  Title = { Formalizing quality rules on music notation. An ontology-based approach.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {91--97},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/11_Bell_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>SMARTVOX. A web-based distributed media player as notation tool for choral practices</div>
	<div class='proc-auth'>Jonathan Bell, Benjamin Matuszewski</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-12'>Bibtex</span>
	<div id='abstract2017-12' class='collapse proc-abstract'>
The present paper describes the features and implementation of SmartVox , an application designed to help vocal ensembles learn and perform polyphonic music. Technically, SmartVox  is a distributed web application that delivers audiovisual scores through the performer’s mobile devices. From a singer’s point of view, this setup allows for the synergy between visual and acoustic stimuli, which facilitates the interpretive and performative processes, particularly in polyphonic passages. It also enables spatial separation of the performers (cori spezzati ), and speeds up the learning process of unfamiliar musical materials (e.g. microtonal tuning, texts in a foreign language). The ubiquity of smartphones makes such a distributed system affordable and allows the use of SmartVox  in multiple contexts, from professional ensembles to pedagogical and recreational practices.
	</div>
	<pre id='bibtex2017-12' class='collapse proc-bibtex'>
@inproceedings{Bell_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Jonathan Bell and Benjamin Matuszewski },
  Title = {SMARTVOX. A web-based distributed media player as notation tool for choral practices},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {99--104},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/12_Warren_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notated control as composed liveness in works for digitally extended voice</div>
	<div class='proc-auth'>Kristina Warren</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-13'>Bibtex</span>
	<div id='abstract2017-13' class='collapse proc-abstract'>
This study argues that learning of varying control mappings in digitally extended voice works imbues body and memory into liveness. The author built and uses the Abacus, a unique, microphone-mounted, Arduino-based musical interface, to control granulation of live vocal samples. There are sixteen pre-composed mappings of Abacus control data (eight toggle switches) to granulation parameters, and mapping changes regularly. An animated screen score provides manual toggle control instructions, which didactically supply information on current mapping. The author’s practice is related to other composer-vocalists’ works for digitally extended voice and to a larger context of screen scores and musical games. Extended voice treats vocal presence as body-technology intersection, and screen scores and musical games highlight embodied learning using unchanging control mappings. The author’s work unites these realms, arguing that repeated, notation-driven learning of the action-sound relationship thematizes complex interactions between body, temporality, memory, and presence.
	</div>
	<pre id='bibtex2017-13' class='collapse proc-bibtex'>
@inproceedings{Warren_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Kristina Warren },
  Title = {Notated control as composed liveness in works for digitally extended voice},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {105 --110},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/13_Hron_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notating electroacoustic music for performers from a practitioner's experience</div>
	<div class='proc-auth'>Terri Hron</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-14'>Bibtex</span>
	<div id='abstract2017-14' class='collapse proc-abstract'>
This paper discusses notation practices and experiments within the electroacoustic performance and composition practice of the author. These spring from a performer and performance-oriented position towards notation in a field that has traditionally catered more to notation for analysis and description. As such, the works and experiences discussed offer hybrid solutions and multiple formats to satisfy specific needs for the effective rehearsal and performance of electroacoustic music. The adaptation of tools specific to electroacoustic practice for more contemporary classical performers is discussed using examples from works written for and by the author in collaboration with other performers and composers.
	</div>
	<pre id='bibtex2017-14' class='collapse proc-bibtex'>
@inproceedings{Hron_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Terri Hron },
  Title = {Notating electroacoustic music for performers from a practitioner's experience},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {111--115},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/14_Shafer_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> Performer action modeling in real-time notation</div>
	<div class='proc-auth'>Seth Shafer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-15'>Bibtex</span>
	<div id='abstract2017-15' class='collapse proc-abstract'>
This paper discusses the application of action-based music notation, and in particular performer action modeling, to my real-time notation (RTN) work, Terraformation (2016–17), which uses a combination of common practice notation (CPN), fingerboard tablature, and color gradients.
	</div>
	<pre id='bibtex2017-15' class='collapse proc-bibtex'>
@inproceedings{Shafer_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Seth Shafer },
  Title = { Performer action modeling in real-time notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {117--123},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/15_Martinez-Nieto_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Expression marks for programming interactive music.</div>
	<div class='proc-auth'>Juan Carlos Martínez Nieto, Jason Freeman</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-16'>Bibtex</span>
	<div id='abstract2017-16' class='collapse proc-abstract'>
The present work uses common Western music notation to represent logical and systematic behaviours of computer music processes in the context of score-oriented interactive music. The algorithmic representation is described by adding programming annotations in a controlled natural language to a musical staff as expression marks in the score. We implemented a computational environment that is able to translate these expression marks into coding instructions and execute them in real-time during a live performance of an interactive-music piece. A collection of short interactive music exercises for MIDI-controlled piano based on the proposed notation was composed and edited using music engraving software. During the compilation stage, an encoded version of the score in MusicXML format is translated into scripting code, and during live performance the computational environment executes the code in real time in sync with the human-performed parts. This paper introduces the syntax of expression marks for programming interactive music through a classic “Hello World” example in the context of interactive music and explains the technical details behind the implementation of the computational environment. The main motivation behind this work was to evaluate the viability of creating a cohesive symbolic representation of interactive music that is independent of specific software and hardware frameworks, and is strongly connected with the western music tradition.
	</div>
	<pre id='bibtex2017-16' class='collapse proc-bibtex'>
@inproceedings{Martinez-Nieto_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Juan Carlos Martínez Nieto and Jason Freeman },
  Title = {Expression marks for programming interactive music.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {125--130},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/16_Garcia_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Timed sequences: A framework for computer aided composition with temporal structures</div>
	<div class='proc-auth'>Jérémie Garcia, Dimitri Bouche, Jean Bresson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-17'>Bibtex</span>
	<div id='abstract2017-17' class='collapse proc-abstract'>
The software framework we present implements a simple and generic representation of the temporal dimension of musical structures used in computer-aided composition software. These structures are modelled as ordered sets of abstract “timed items” whose actual dates can be set and determined following different strategies. The timed items can be linked to an underlying action scheduling and rendering system, and can also be used as temporal handles to perform time stretching and hierarchical synchronization operations. A graphical user interface associated with this model can be embedded as a component within musical editors. We give several examples of musical objects implemented in this framework, as well as examples of time-domain operations and user interactions.
	</div>
	<pre id='bibtex2017-17' class='collapse proc-bibtex'>
@inproceedings{Garcia_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Jérémie Garcia and Dimitri Bouche and Jean Bresson },
  Title = {Timed sequences: A framework for computer aided composition with temporal structures},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {131--136},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/17_Faraldo_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> The house harmonic filler: Interactive exploration of chord sequences by means of an intuitive representation</div>
	<div class='proc-auth'>Angel Faraldo, Perfecto Herrera, Sergi Jordà</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-18'>Bibtex</span>
	<div id='abstract2017-18' class='collapse proc-abstract'>
In this paper we present an interactive two-dimensional representation of musical chord progressions, integrated into a computer program that generates house music harmonic loops in MIDI format, based on a user's input. Our aim is to encapsulate relevant tonal information and display it in ways that are easy to understand for novices and untrained musicians, facilitating the creative exploration of musical ideas. We briefly reference previous work on tonal visualisation and interaction, and introduce some measures of tonal properties from the literature. We then present our system and describe the two-dimensional harmonic map, before discussing its outcomes and shortcomings, pointing at future lines of research in the conclusions.
	</div>
	<pre id='bibtex2017-18' class='collapse proc-bibtex'>
@inproceedings{Faraldo_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Angel Faraldo and Perfecto Herrera and Sergi Jordà },
  Title = { The house harmonic filler: Interactive exploration of chord sequences by means of an intuitive representation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {137--143},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/18_Jacquemard_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Generating equivalent rhythmic notations based on rhythm tree languages.</div>
	<div class='proc-auth'>Florent Jacquemard, Adrien Ycart, Masahiko Sakai</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-19'>Bibtex</span>
	<div id='abstract2017-19' class='collapse proc-abstract'>
We propose a compact presentation of languages of preferred rhythm notations as formal grammars. It is based on a standard structure of rhythm trees capturing a wide range of rhythms in Western notation. As an application, we then describe a dynamic programming algorithm for the lazy enumeration of equivalent rhythm notations (i.e. notations defining the same durations), from the simplest to the most complex. This procedure, based on the notion of rhythm grammars has been implemented and may be useful in the context of automated music transcription and computer-assistance to composition.
	</div>
	<pre id='bibtex2017-19' class='collapse proc-bibtex'>
@inproceedings{Jacquemard_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Florent Jacquemard and Adrien Ycart and Masahiko Sakai },
  Title = {Generating equivalent rhythmic notations based on rhythm tree languages.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {145--153},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/19_Mendonca_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'> “Des pas sur l’invisible”. The octave space and the self-multiplication process.</div>
	<div class='proc-auth'>Silvia Mendonça</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-20'>Bibtex</span>
	<div id='abstract2017-20' class='collapse proc-abstract'>
The purpose of this paper is to describe the process, from a composition standpoint, from which my piece Des pas sur le invisible (2016) for clarinet or solo saxophone, was composed. This work is part of a PhD in music in which I propose a model of composition based on a self-multiplication process, and was created within the context of the Frederico de Freitas Interpretation Prize, Universidade de Aveiro (May 2016 edition). Starting from a pre composing point of view, we will consider the octave musical interval as a metaphor for the self-multiplication process. This reflection allows us to think the octave as a space and therefore, how the attribution of this extended dimension can be rethought in music, leading us to new approaches of the composition practice. The piece Des pas sur le invisible will show how this approach can be accomplished, serving to illustrate a thought that takes place outside the proper world of musical elements and considerations that can be decisive in the musical discourse. It will show how the principle behind the conception of this work can develop perspectives for the composition notation practice and for future research.
	</div>
	<pre id='bibtex2017-20' class='collapse proc-bibtex'>
@inproceedings{Mendonca_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Silvia Mendonça },
  Title = { “Des pas sur l’invisible”. The octave space and the self-multiplication process.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {155-159},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/20_Bhagwati_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Vexations of ephemerality.</div>
	<div class='proc-auth'>Sandeep Bhagwati</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-21'>Bibtex</span>
	<div id='abstract2017-21' class='collapse proc-abstract'>
What do we do when we subject musicians and audiences to music prompted by real-time scores? Such situative scores create a new kind of immanent relationship between performers and audiences, between composers and performers, composers and audiences – a relationship whose ingrained disregard of context, memory, and knowledge has often been ignored. The use of situative scores seems to inscribe itself into a more general societal trend that uses technology to ephemeralize our lives, to decouple presence from its history. While this immanence has often been perceived as a force for the emancipation of performers and spectators, it can also give rise to unaccountability. Do artistic practices that ephemeralize our artistic 'regime of perception, sensation and interpretation' (Rancière) - such as situative scores – foster abuses of immanence?. In this paper, I will look at such questions from the perspective of the performers, the audiences and the makers of such scores – the composers.
	</div>
	<pre id='bibtex2017-21' class='collapse proc-bibtex'>
@inproceedings{Bhagwati_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Sandeep Bhagwati },
  Title = {Vexations of ephemerality.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {161--166},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/21_Antila_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A hierarchic diff algorith for collaborative music document editing.</div>
	<div class='proc-auth'>Christopher Antila, Jeffrey Treviño, Gabriel Weaver</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-22'>Bibtex</span>
	<div id='abstract2017-22' class='collapse proc-abstract'>
We describe an application of hierarchic diff to the collaborative editing of tree-based music representations, using Zhang and Shasha’s tree edit distance algorithm as implemented within the XUDiff tool. The edit distance between two trees is the minimum number of edit operations necessary to transform one tree into the other. We consider common operations on the score tree—deleting, changing, and appending tree nodes—to derive a minimal edit sequence, known as an edit script, and we compare the performance of the widely used Longest Common Subsequence algorithm against our approach. We conclude by summarizing implications for the design of collaborative music document software systems.
	</div>
	<pre id='bibtex2017-22' class='collapse proc-bibtex'>
@inproceedings{Antila_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Christopher Antila and Jeffrey Treviño and Gabriel Weaver },
  Title = {A hierarchic diff algorith for collaborative music document editing.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {167--170},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/22_James_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Establishing connectivity between the existing networked music notation packages Quintet.net, Decibel Score Player and MaxScore.</div>
	<div class='proc-auth'>Stuart James, Cat Hope, Lindsay Vickery, Aaron Wyatt, Ben Carey, Xiao Fu, George Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-23'>Bibtex</span>
	<div id='abstract2017-23' class='collapse proc-abstract'>
In this paper we outline a collaboration where live internet-based and local collaboration between research groups/musicians from Decibel New Music Ensemble (Perth, Australia) and ZM (Hamburg, Germany), was facilitated by novel innovations in customised software solutions employed by both groups. The exchange was funded by the Deutscher Akademischer Austauschdienst and Universities Australia. Both groups were previously engaged in the research and performance of similar musical repertoire such as John Cage’s ‘Five’ (1988) and ‘Variations I — VIII’ (1958-67) among others, the performances of which utilise graphic, animated and extended traditional Western music notation. Preliminary steps were taken to achieve communication between the three existing network music notation packages, the Decibel ScorePlayer, MaxScore and quintet.net, facilitating a merging – and ultimately an extension – of notational approaches previously prescribed by each music notation package. In addition to the technical innovations required to achieve such a project, we consider the outcomes and future directions of the project, as well as their relevance for the wider contemporary music community.
	</div>
	<pre id='bibtex2017-23' class='collapse proc-bibtex'>
@inproceedings{James_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Stuart James and Cat Hope and Lindsay Vickery and Aaron Wyatt and Ben Carey and Xiao Fu and George Hajdu },
  Title = {Establishing connectivity between the existing networked music notation packages Quintet.net, Decibel Score Player and MaxScore.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {171--183},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/23_Marco_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Persiles avista Roma</div>
	<div class='proc-auth'>Tomas Marco</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-24'>Bibtex</span>
	<div id='abstract2017-24' class='collapse proc-abstract'>
“Persiles avista Roma” was commissioned as part of the commemorative events set to homage Cervantes on his 4th Centenary. The composer was inspired by one of the sonnets included in "Los trabajos de Persiles and Segismunda", which was the last novel written by Cervantes, posthumous published in 1617. “The composition is built as a formal dialogue between the structure of the sonnet - taken with a flexible perspective - and its musical expression. The music score is written for baritone and violin soloists which interact as a "duo concertante". The composition proposes a contemporary musical view of Cervantes text, which has an eternal life crystallised in a mythical present.
	</div>
	<pre id='bibtex2017-24' class='collapse proc-bibtex'>
@inproceedings{Marco_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Tomas Marco },
  Title = {Persiles avista Roma},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {185--193},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/24_Palma_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Voice Prints</div>
	<div class='proc-auth'>Helena Palma</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-25'>Bibtex</span>
	<div id='abstract2017-25' class='collapse proc-abstract'>
Voice prints (VP) is a homage to our ancestors and the languages they used as tools to create and expand over large locations powerful civilisations. Where are our ancestors now? Have they disappeared? Those people and the locations they lived in are casted in infinite events created by our thoughts. We can hear the resonances of their voices in the roar of time. In VP the ancestors’ voices are articulated by the voice of a baritone and of a violin who melt their timbre in resonances of the words uttered by a distant father: harmonics 2, 3, 4, 5, 7, and 9 of a fundamental Bb1 tone. VP includes phonemes, words and sentences sung and spoken in Scythian, Greek, Celtiberian, Ubykh, Albanian, Catalan, English, Galician, German, Spanish. Music is set to fragments of poems by Espriu,  Handke and Llamazares.
	</div>
	<pre id='bibtex2017-25' class='collapse proc-bibtex'>
@inproceedings{Palma_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Helena Palma },
  Title = {Voice Prints},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {195--207},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/25_Teles_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Des pas sur l’invisible</div>
	<div class='proc-auth'>Silvia Teles</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-26'>Bibtex</span>
	<div id='abstract2017-26' class='collapse proc-abstract'>
In this work, written for clarinet or saxophone and their respective instrument families, the interpreter is confronted with an approach to musical notation that consists of an opening of the sound space and its filling in sound identity. This space is given by octave intervals which, by constituting polarizing sounds, form distinct planes and also by the different gestures associated with them. The performance should be the 'temporal path' imagined by the interpreter.
	</div>
	<pre id='bibtex2017-26' class='collapse proc-bibtex'>
@inproceedings{Teles_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Silvia Teles },
  Title = {Des pas sur l’invisible},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {209--214},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/26_Shafer_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Terraformation</div>
	<div class='proc-auth'>Seth Shafer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-27'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-27'>Bibtex</span>
	<div id='abstract2017-27' class='collapse proc-abstract'>
This paper introduces my real-time notation (RTN) work Terraformation (2016-17) for violin or viola and computer. The piece uses a computer screen to display music notation that changes during the performance based on decisions made by both the musician and the computer. In this way, every performance is unique and unrepeatable. Program notes, performance directions, and two score excerpts from violinist Florian Vlashi's performance on May 25, 2017 at the Third International Conference on Technologies for Music Notation and Representation are included.
	</div>
	<pre id='bibtex2017-27' class='collapse proc-bibtex'>
@inproceedings{Shafer_b_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Seth Shafer },
  Title = {Terraformation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {215--227},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2017/27_Hoadley_tenor2017.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Homenaje a Cervantes</div>
	<div class='proc-auth'>Richard Hoadley</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2017-28'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2017-28'>Bibtex</span>
	<div id='abstract2017-28' class='collapse proc-abstract'>
This is a presentation of the dynamic score “Homenaje a Cervantes”  (Homage to Cervantes) created for violin, computer and projections, originally commissioned for and first performed at the University of A Coruna, Spain in May 2017. The piece has been composed using the software packages SuperCollider and INSCORE; the violin part should be played live from a laptop screen or a projection. The texts used are the original Cervantes text, an English translation and a series of original poems created specially for this project by the poet Phil Terry.
	</div>
	<pre id='bibtex2017-28' class='collapse proc-bibtex'>
@inproceedings{Hoadley_tenor2017,
  Address = {A Coru~{n}a, Spain},
  Author = { Richard Hoadley },
  Title = {Homenaje a Cervantes},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'17},
  Pages = {229-238},
  Year = {2017},
  Editor = {Helena Lopez Palma and Mike Solomon and Emiliana Tucci and Carmen Lage},
  Publisher = {Universidade da Coru~{n}a},
  ISBN = {978-84-9749-666-7}
}
	</pre>
</div>
</div>
</section>

 <!-- ========================================================================= -->

    <section id="2016">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2016</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>

<div class='container'>
<div class='row tenor-paper'>
  <a href='proceedings/TENOR2016-Proceedings.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>

  <div class='proc-title'>FULL TENOR'16 PROCEEDINGS</div>
  <span class='proc-button' data-toggle='collapse' data-target='#bibtex2016'>Bibtex</span>
  | <a href="proceedings/bibtex2016.bib" class="tenor-bibtex">.bib</a>

  <pre id='bibtex2016' class='collapse proc-bibtex'>
@book{tenor2016,
  Address = {Cambridge, UK},
  Title = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
  </pre>
</div>
<hr>
</div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2016/01_Ghisi_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Real-Time Corpus-Based Concatenative Synthesis for Symbolic Notation</div>
	<div class='proc-auth'>Daniele Ghisi and Carlos Agon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-1'>Bibtex</span>
	<div id='abstract2016-1' class='collapse proc-abstract'>
We introduce a collection of modules designed to segment, analyze, display and sequence symbolic scores in real-time. This mechanism, inspired from CataRT’s corpus-based concatenative synthesis, is implemented as a part of the dada library for Max, currently under development.
	</div>
	<pre id='bibtex2016-1' class='collapse proc-bibtex'>
@inproceedings{Ghisi_tenor2016,
  Address = {Cambridge, UK},
  Author = { Daniele Ghisi and Carlos Agon },
  Title = {Real-Time Corpus-Based Concatenative Synthesis for Symbolic Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {1--7},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/02_Herremans_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Tension ribbons: Quantifying and visualising tonal tension</div>
	<div class='proc-auth'>Dorien Herremans and Elaine Chew</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-2'>Bibtex</span>
	<div id='abstract2016-2' class='collapse proc-abstract'>
Tension is a complex multidimensional concept that is not easily quantified. This research proposes three methods for quantifying aspects of tonal tension based on the spiral array, a model for tonality. The cloud diameter measures the dispersion of clusters of notes in tonal space; the cloud momentum measures the movement of pitch sets in the spiral array; finally, tensile strain measures the distance between the local and global tonal context. The three methods are implemented in a system that displays the results as tension ribbons over the music score to allow for ease of interpretation. All three methods are extensively tested on data ranging from small snippets to phrases with the Tristan chord and larger sections from Beethoven and Schubert piano sonatas. They are further compared to results from an existing empirical experiment.
	</div>
	<pre id='bibtex2016-2' class='collapse proc-bibtex'>
@inproceedings{Herremans_tenor2016,
  Address = {Cambridge, UK},
  Author = { Dorien Herremans and Elaine Chew },
  Title = {Tension ribbons: Quantifying and visualising tonal tension},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {8--18},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/03_Vickery_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Hybrid Real/Mimetic Sound Works</div>
	<div class='proc-auth'>Lindsay Vickery</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-3'>Bibtex</span>
	<div id='abstract2016-3' class='collapse proc-abstract'>
In 2013 I began a project to construct a process allowing for data interchange between visual and sonic media: to create a continuum in which sound could be visualized and then resonified through by both live performers and digital means. A number of processes to aid this visualisation/sonification “ecosystem” were developed. Software was created to create scores based on sonic features of “field recordings” through spectral analysis by rendering the frequency of the strongest detected sinusoidal peak of a recording vertically and its timbral characteristics by luminance, hue and saturation on a scrolling score. Along similar principals a second process was developed to generate a realtime score using graphical symbols to represent detected accents in “found sound” speech recordings. In the other direction software was built to render greyscale images (including sonograms) as sound and a second iteration to generate audio from detected analysis parameters. The imperfections in the various transcription processes are intriguing in themselves as they throw into relief the distinctions between the various forms of representation and in particular the timescales in which they are perceived. The implied circularity of processes also opened the potential for re-interrogation of materials through repeated transmutation. This discussion explores these implications in the context of the analysis of field record-ings to generate visual representations that can be reson-ified using both performative (via notation) and machine (visual data-based) processes, to create hybrid re-al/mimetic sound works through the combination (and recombination) of the processes.
	</div>
	<pre id='bibtex2016-3' class='collapse proc-bibtex'>
@inproceedings{Vickery_tenor2016,
  Address = {Cambridge, UK},
  Author = { Lindsay Vickery },
  Title = {Hybrid Real/Mimetic Sound Works},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {19--24},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/04_Jeong_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Visualizing Music in its Entirety using Acoustic Features: Music Flowgram</div>
	<div class='proc-auth'>Dasaem Jeong and Juhan Nam</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-4'>Bibtex</span>
	<div id='abstract2016-4' class='collapse proc-abstract'>
In this paper, we present an automatic method for visualizing a music audio file from its beginning to end, especially for classical music. Our goal is developing an easy-to-use visualization method that is helpful for listeners and can be used for various kinds of classical music, even for complex orchestral music. To represent musical characteristic, the method uses audio features like volume, onset density, and auditory roughness, which describe loudness, tempo, and dissonance, respectively. These features are visually mapped into static two-dimensional graph, so that users can see how the music changes by time at a look. We have implemented the method with Web Audio API, and it works on recent version of web browsers like Chrome, Firefox, Safari, and Opera. Users can access to the visualization system on their web browser and make visualizations from their own music audio files. Two types of user tests were conducted to verify effects and usefulness of the visualization for classical music listeners. The result shows that it helps listeners to memorize and understand a structure of music, and to easily find a specific part of the music.
	</div>
	<pre id='bibtex2016-4' class='collapse proc-bibtex'>
@inproceedings{Jeong_tenor2016,
  Address = {Cambridge, UK},
  Author = { Dasaem Jeong and Juhan Nam },
  Title = {Visualizing Music in its Entirety using Acoustic Features: Music Flowgram},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {25--32},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/05_Misra_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Swaralipi: A Framework for Transcribing and Rendering Indic Music Sheet</div>
	<div class='proc-auth'>Chandan Misra, Tuhin Chakraborty, Anupam Basu and Baidurya Bhattacharya</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-5'>Bibtex</span>
	<div id='abstract2016-5' class='collapse proc-abstract'>
Creating music in computer system through its music notations requires two primary components. The first one is the mechanisms to encode music notations of respective music genres and the other one is a framework to provide the look and feel of the music written like a published or handwritten music sheet. Popular music scorewriters like Finale, Sibelius, MuseScore can edit, render and playback music transcribed in Staff notation. Being vastly different from the Indic music system in grammar, notation symbols, tonic system and encoding style, the architecture used in the music software for western music cannot cater to the Indic music system. For this reason there is a dearth of such scorewriters for Indic music system which is rich with a variety of musical genres, each different from the others in their unique notation system and language for depicting their lyric. In this paper, we propose a new framework for transcribing and rendering Indic music sheets for different genres of Indic music in computer. This framework is designed to support all major Indic notation systems and Indic language scripts and is explained using three major notation systems and language scripts throughout the paper as a case study.
	</div>
	<pre id='bibtex2016-5' class='collapse proc-bibtex'>
@inproceedings{Misra_tenor2016,
  Address = {Cambridge, UK},
  Author = { Chandan Misra and Tuhin Chakraborty and Anupam Basu and Baidurya Bhattacharya },
  Title = {Swaralipi: A Framework for Transcribing and Rendering Indic Music Sheet},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {33--43},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/06_Hurtado_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notating the Non-Notateable: Digital Notation of Txalaparta Practice</div>
	<div class='proc-auth'>Enrike Hurtado and Thor Magnusson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-6'>Bibtex</span>
	<div id='abstract2016-6' class='collapse proc-abstract'>
This paper explores notation practices related to the ancient Basque musical tradition of the txalaparta. It will firstly present the txalaparta practice, introduce the im-provisational rules of txalaparta playing, and discuss attempts in creating notation systems for the instrument. Due to the nature of txalaparta playing, Common West-ern Notation is not a suitable notation, and we will pre-sent the notation system we have developed as part of the Digital Txalaparta project. This system captures the key parts of playing and serves for both playback and a rich documentation of what players actually perform.
	</div>
	<pre id='bibtex2016-6' class='collapse proc-bibtex'>
@inproceedings{Hurtado_tenor2016,
  Address = {Cambridge, UK},
  Author = { Enrike Hurtado and Thor Magnusson },
  Title = {Notating the Non-Notateable: Digital Notation of Txalaparta Practice},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {44--49},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/07_Sonnenfeld_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>S-notation: A complete musical notation system for scratching and sample music derived from "Theory of Motions"</div>
	<div class='proc-auth'>Alexander Sonnenfeld and Kjetil Falkenberg Hansen</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-7'>Bibtex</span>
	<div id='abstract2016-7' class='collapse proc-abstract'>
In this paper, we present and discuss S-notation for sample-based music, and particularly for DJ scratching and turntablism. Sonnenfeld developed S-notation based on his Theory of Motion where scratch music is seen as constructions of concurrent musical gestures (motion parameters), and not only turntable actions. The detailed symbolic notation was inspired by traditional musical notation, and among its advantages it covers current musical needs, it can be read and played live in performance, it provides a tool for composers to convey musical ideas, it can be expanded towards new styles and techniques, and it is generalizable to other types of sample-based music. In addition to motion parameters, the new notation system involves an analysis of the sampled sound. Finally, S-notation is also applicable for documenting and for teaching situations.
	</div>
	<pre id='bibtex2016-7' class='collapse proc-bibtex'>
@inproceedings{Sonnenfeld_tenor2016,
  Address = {Cambridge, UK},
  Author = { Alexander Sonnenfeld and Kjetil Falkenberg Hansen },
  Title = {S-notation: A complete musical notation system for scratching and sample music derived from "Theory of Motions"},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {50--57},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/08_Hall_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Pitchcircle3D: A Case Study in Live Notation for Interactive Music Performance</div>
	<div class='proc-auth'>Tom Hall</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-8'>Bibtex</span>
	<div id='abstract2016-8' class='collapse proc-abstract'>
Recent decades have seen the establishment of computer software live notations intended as music scores, affording new modes of interaction between composers, improvisers, performers and audience. This paper presents a live notations project situated within the research domains of algorithmic music composition, improvisation, performance and software interaction design. The software enables the presentation of live animated scores which display 2D and 3D pitch-space representations of note collections including a spiral helix and pitch-class clock. The software has been specifically engineered within an existing sound synthesis environment, SuperCollider, to produce tight integration between sound synthesis and live notation. In a performance context, the live notation is usually presented as both music score and visualisation to the performers and audience respectively. The case study considers the performances of two of the author's contrasting compositions utilising the software. The results thus far from the project demonstrate the ways in which the software can afford different models of algorithmic and improvised interaction between the composer, performers and the music itself. Also included is a summary of feedback from musicians who have used the software in public music performances over a number of years.
	</div>
	<pre id='bibtex2016-8' class='collapse proc-bibtex'>
@inproceedings{Hall_tenor2016,
  Address = {Cambridge, UK},
  Author = { Tom Hall },
  Title = {Pitchcircle3D: A Case Study in Live Notation for Interactive Music Performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {58--64},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/09_Shafer_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Performance Practice of Real-Time Notation</div>
	<div class='proc-auth'>Seth Shafer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-9'>Bibtex</span>
	<div id='abstract2016-9' class='collapse proc-abstract'>
The primary distinction between real-time and non-real-time notation is the ability for the performer to know ahead of time the exact details of what they will be asked to perform. This paper address the myriad of performance practice issues encountered when the notation of a work loosens its bounds in the world of the fixed and knowable, and instead explores the realms of chance, spontaneity, and interactivity. Some of these issues include: the problem of rehearsal, the problem of ensemble synchronization, the extreme limits of sight reading, failure as a compositional device, new freedoms for the performer and composer, and the new opportunities offered by the ephemerality and multiplicity of real-time notation.
	</div>
	<pre id='bibtex2016-9' class='collapse proc-bibtex'>
@inproceedings{Shafer_tenor2016,
  Address = {Cambridge, UK},
  Author = { Seth Shafer },
  Title = {Performance Practice of Real-Time Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {65--70},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/10_Zitellini_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Representing atypical music notation practices: An example with late 17th century music</div>
	<div class='proc-auth'>Rodolfo Zitellini and Laurent Pugin</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-10'>Bibtex</span>
	<div id='abstract2016-10' class='collapse proc-abstract'>
From the 17th century towards the first decades of the 18th century music notation slowly looses all influences from mensural music, becoming virtually identical to what we would consider common modern notation. But in these five decades of transformation composers did not just suddenly abandon older notation styles, but they were used alongside the ones that would become standard. Void notation, black notation and uncommon tempi were all mixed together. The scholar preparing modern editions of this music is normally forced to normalize all these atypical notations as many software applications do not support them natively. This paper exemplifies the flexibility of the encoding scheme proposed by the Music Encoding Initiative (MEI) and of Verovio, a visualisation library designed for it. The modular approach of these tools means that particular notation systems can be easily added whilst maintaining compatibility to other encoded notations.
	</div>
	<pre id='bibtex2016-10' class='collapse proc-bibtex'>
@inproceedings{Zitellini_tenor2016,
  Address = {Cambridge, UK},
  Author = { Rodolfo Zitellini and Laurent Pugin },
  Title = {Representing atypical music notation practices: An example with late 17th century music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {71--77},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/11_Palma_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Expressive Function in Wor Songs</div>
	<div class='proc-auth'>Helena Palma</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-11'>Bibtex</span>
	<div id='abstract2016-11' class='collapse proc-abstract'>
We study some musical and expressive features of traditional Wor vocal music, an ancestral gender of the Biaks (West Papua). A core aspect in Wor songs is the expression of wonder, which Biaks have developed into an Aesthetics of Surprise. We describe some key structural features in the pitch and time domain used as means to express such an aesthetics. We represent the acoustic and prosodic features encoding expressive content by means of an Expressive Function which contains expressive indices with internal structure. We propose an augmented expressive score for the transcription of unaccompanied Wor songs.
	</div>
	<pre id='bibtex2016-11' class='collapse proc-bibtex'>
@inproceedings{Palma_tenor2016,
  Address = {Cambridge, UK},
  Author = { Helena Palma },
  Title = {The Expressive Function in Wor Songs},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {78--84},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/12_Fournier_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Is There a Data Model in Music Notation?</div>
	<div class='proc-auth'>Raphaël Fournier-S'niehotta, Philippe Rigaux and Nicolas Travers</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-12'>Bibtex</span>
	<div id='abstract2016-12' class='collapse proc-abstract'>
Scores are structured objects, and we can therefore envisage operations that change the structure of a score, combine several scores, and produce new score instances from some pre-existing material. Current score encodings, however, are designed for rendering and exchange purposes, and cannot directly be exploited as instances of a clear data model supporting algebraic manipulations. We propose an approach that leverages a music content model hidden in score notation, and define a set of composable operations to derive new "scores" from a corpus of existing ones. We show that this approach supplies a high-level tool to express common, useful applications, can easily be implemented on top of standard components, and finally gives rise to interesting conceptual issues related to the modeling of music notation.
	</div>
	<pre id='bibtex2016-12' class='collapse proc-bibtex'>
@inproceedings{Fournier_tenor2016,
  Address = {Cambridge, UK},
  Author = { Raphaël Fournier-S'niehotta and Philippe Rigaux and Nicolas Travers },
  Title = {Is There a Data Model in Music Notation?},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {85--91},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/13_Kim-Boyle_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Ontology of Live Notations Through Assemblage Theory</div>
	<div class='proc-auth'>David Kim-Boyle</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-13'>Bibtex</span>
	<div id='abstract2016-13' class='collapse proc-abstract'>
This paper uses assemblage theory to help develop an ontological framework for better understanding live notation practice. Originally developed by Deleuze and Guattari across a range of theoretical writings, assemblage theory is more fully explicated in the work of Manuel de Landa in the more focused context of social ontology. This paper examines the basic concepts of assemblage theory such as material components, expressive capacities, and relations of exteriority and how they may pro-vide useful insights in the analysis of music which explores the creative potential of live notation. The temporal dynamics of non-linear musical forms are discussed and assemblage theory is shown to be a powerful tool for promoting a better understanding of how the various interactions between material and expressive components help catalyze the emergent properties of the assemblage and through it, the ontological identity of a live notation aesthetic practice.
	</div>
	<pre id='bibtex2016-13' class='collapse proc-bibtex'>
@inproceedings{Kim-Boyle_tenor2016,
  Address = {Cambridge, UK},
  Author = { David Kim-Boyle },
  Title = {The Ontology of Live Notations Through Assemblage Theory},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {92--97},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/14_Ross-Smith_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>[Study no. 50][Notational Becoming][Speculations]</div>
	<div class='proc-auth'>Ryan Ross Smith</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-14'>Bibtex</span>
	<div id='abstract2016-14' class='collapse proc-abstract'>
The use of animation in contemporary notational practices has become increasingly prevalent over the last ten years, due in large part to the increased compositional activities throughout Europe, the United Kingdom, and North America, and in particular Iceland and Western Australia.1 The publication of several foundational texts,2 and the materialization of focused scholarly meetings3 and online consolidation projects4 have also contributed to the expansion of this growing field of animated notational practice. The range of compositional ideas repre- sented by these scores is vast, encompassing a wide va- riety of stylistic approaches and technological experimentation. While these ideas often demonstrate intriguing compositional directions, and the unique dynamic functionalities and visual characteristics of animated scores are clearly distinct from traditionally-fixed scores, it is the real-time generative processes of these scores that represent a shift in the very ontology of the musical score. In this paper I speculate on one possible framing for this ontological distinction by focusing on several attributes that, in combination, most explicitly demonstrate this distinction. These include the real-time, process-based qualities of generative animated notations, the openness that enables these procedural functionalities, the displacement of interpretive influence, and the timeliness of these processes in respect to the temporal relationship between generation, representation as notation, and sonic realization. A new work, Study no. 50, will be examined as a practical demonstration of these attributes, and will function as a jumping off point for a speculative discussion of the concept of Notational Becoming.
	</div>
	<pre id='bibtex2016-14' class='collapse proc-bibtex'>
@inproceedings{Ross-Smith_tenor2016,
  Address = {Cambridge, UK},
  Author = { Ryan Ross Smith },
  Title = {[Study no. 50][Notational Becoming][Speculations]},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {98--104},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/15_Fox_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Autonomy, Control, and Notation in Interactive Music</div>
	<div class='proc-auth'>K. Michael Fox</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-15'>Bibtex</span>
	<div id='abstract2016-15' class='collapse proc-abstract'>
This paper proposes a conceptualization of notation for interactive musical environments. The notational approach describes the relationship between both human and non-human agents, instead of actions to be taken or sounds to be made. Of critical importance in contemporary networked culture is the degree to which technological devices and networks constrain (or control) the actions of their users. The author has developed a conception of interactivity and notational considerations which instead foreground the autonomous potential of participants and the computational systems. The author analyzes three case studies that demonstrate either a direct connection or a broader conceptual link to the described notational approach. The larger implication is a need for notational systems which do not constrain the identity of the users of interactive systems while also acknowledging and representing the agency of the systems themselves.
	</div>
	<pre id='bibtex2016-15' class='collapse proc-bibtex'>
@inproceedings{Fox_tenor2016,
  Address = {Cambridge, UK},
  Author = { K. Michael Fox },
  Title = {Autonomy, Control, and Notation in Interactive Music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {105--109},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/16_Tomas_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Musical Instruments as Scores: A Hybrid Approach</div>
	<div class='proc-auth'>Enrique Tomás</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-16'>Bibtex</span>
	<div id='abstract2016-16' class='collapse proc-abstract'>
The development of new approaches to instrumentality during the decade of 1960 contributed to the dual perception of instruments as scores. For many performers, the instrument became the score of what they played. This artistic hybridization carries substantial questions about the nature of our scores and about the relationships among instruments, performers and musical works. This paper contextualizes the historical origins of this instrumental development within Drucker's theory of performative materiality. Then we examine the nature and notational scheme of this type of scores making use of the concept of "inherent score". Finally, through the analysis of two examples ("tangible scores" and "choreographic objects") and the notions of "affordance" and "constraint", a compositional framework for shaping the inherent instrument score is presented.
	</div>
	<pre id='bibtex2016-16' class='collapse proc-bibtex'>
@inproceedings{Tomas_tenor2016,
  Address = {Cambridge, UK},
  Author = { Enrique Tomás },
  Title = {Musical Instruments as Scores: A Hybrid Approach},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {110--120},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/17_Bhagwati_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Musicking the Body Electric. The "body:suit:score" as a polyvalent score interface for situational scores.</div>
	<div class='proc-auth'>Sandeep Bhagwati, Marcello Giordano, Joanna Berzowska, Alex Bachmayr, Julian Stein, Joseph Browne, Felix Del Tredici, Deborah Egloff, John Sullivan, Marcelo Wanderley and Isabelle Cossette</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-17'>Bibtex</span>
	<div id='abstract2016-17' class='collapse proc-abstract'>
Situational scores, in this paper, are defined as scores that deliver time- and context-sensitive score information to musicians at the moment when it becomes relevant. Mnemonic (rule/style-based) scores are the oldest score models of this type. Lately, animated, interactive, locative scores have added new options to situative scoring. The body:suit:score is an interface currently developed in collaboration of four labs at Concordia and McGill Universities in Montréal - an interface that will allow the musical use of all four types of situational score. Musicians are clad in a body-hugging suit with embedded technology - this suit becomes their score interface. Ultimately intended to enable ensembles to move through performance spaces unencumbered by visual scores and their specific locations, the project currently enters its second year of research-creation. The paper discusses the closely intertwined technological, ergonomic, music-psychology based and artistic decisions that have led to a first bodysuit prototype - a vibrotactile suit for a solo musician. It will also discuss the so-far three etude compositions by Sandeep Bhagwati and Julian Klein for this prototype, and their widely divergent conceptual approaches to an artistic use of the body:suit:score interface. Finally, the paper discusses next steps and emergent problems and opportunities, both technological and artistic.
	</div>
	<pre id='bibtex2016-17' class='collapse proc-bibtex'>
@inproceedings{Bhagwati_tenor2016,
  Address = {Cambridge, UK},
  Author = { Sandeep Bhagwati and Marcello Giordano and Joanna Berzowska and Alex Bachmayr and Julian Stein and Joseph Browne and Felix Del Tredici and Deborah Egloff and John Sullivan and Marcelo Wanderley and Isabelle Cossette },
  Title = {Musicking the Body Electric. The "body:suit:score" as a polyvalent score interface for situational scores.},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {121--126},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/18_Antoniadis_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Processing of symbolic music notation via multimodal performance data: Brian Ferneyhough’s Lemma-Icon-Epigram for solo piano, phase 1</div>
	<div class='proc-auth'>Pavlos Antoniadis and Frédéric Bevilacqua</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-18'>Bibtex</span>
	<div id='abstract2016-18' class='collapse proc-abstract'>
In the “Performance Notes” to his formidable solo piano work Lemma-Icon-Epigram, British composer Brian Ferneyhough proposes a top-down learning strategy: Its first phase would consist in an “overview of gestural patterning”, before delving into the notorious rhythmic intricacies of this most complex notation. In the current paper, we propose a methodology for inferring such patterning from multimodal performance data. In particular, we have a) conducted qualitative analysis of the correlations between the performance data -an audio recording, 12-axis acceleration and gyroscope signals captured by inertial sensors, kinect video and MIDI- and the implicit annotation of pitch during a ‘sight-reading’ performance; b) observed and documented the correspondence between patterns in the gestural signals and patterns in the score annotations and c) produced joint tablature-like representations, which inscribe the gestural patterning back into the notation, while reducing the pitch material by 70-80% of the original. In addition, we have incorporated this representation in videos and interactive multimodal tablatures using the INScore. Our work is drawing from recent studies in the fields of gesture modeling and interaction. It is extending the authors’ previous work on an embodied model of navigation of complex notation and on an application for offline and real-time gestural control of complex notation by the name GesTCom. Future prospects include the probabilistic modeling of gesture-to-notation mappings, towards the design of interactive systems which learn along with the performer while cutting through textual complexity.
	</div>
	<pre id='bibtex2016-18' class='collapse proc-bibtex'>
@inproceedings{Antoniadis_tenor2016,
  Address = {Cambridge, UK},
  Author = { Pavlos Antoniadis and Frédéric Bevilacqua },
  Title = {Processing of symbolic music notation via multimodal performance data: Brian Ferneyhough’s Lemma-Icon-Epigram for solo piano, phase 1},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {127--136},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/19_Lepetit-Aimon_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>INScore expressions to compose symbolic scores</div>
	<div class='proc-auth'>Gabriel Lepetit-Aimon, Dominique Fober, Yann Orlarey and Stéphane Letz</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-19'>Bibtex</span>
	<div id='abstract2016-19' class='collapse proc-abstract'>
INScore is an environment for the design of augmented interactive music scores turned to non-conventional use of music notation. The environment allows arbitrary graphic resources to be used and composed for the music representation. It supports symbolic music notation, described using Guido Music Notation or MusicXML formats. The environment has been extended to provided score level composition using a set of operators that consistently take scores as arguments to compute new scores as output. INScore API supports now score expressions both at OSC and at scripting levels. The work is based on a previous research that solved the issues of the notation consistency across scores composition. This paper focuses on the language level and explains the different strategies to evaluate score expressions.
	</div>
	<pre id='bibtex2016-19' class='collapse proc-bibtex'>
@inproceedings{Lepetit-Aimon_tenor2016,
  Address = {Cambridge, UK},
  Author = { Gabriel Lepetit-Aimon and Dominique Fober and Yann Orlarey and Stéphane Letz },
  Title = {INScore expressions to compose symbolic scores},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {137--143},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/20_Haddad_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>OMLILY: Filling the notational gap between composition and performance</div>
	<div class='proc-auth'>Karim Haddad and Carlos Agon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-20'>Bibtex</span>
	<div id='abstract2016-20' class='collapse proc-abstract'>
This paper describes the design, the development, the usage, limitations and prospect of future development of Omlily, an OpenMusic library, for editing scores with Lilypond, using OM musical editors.
	</div>
	<pre id='bibtex2016-20' class='collapse proc-bibtex'>
@inproceedings{Haddad_tenor2016,
  Address = {Cambridge, UK},
  Author = { Karim Haddad and Carlos Agon },
  Title = {OMLILY: Filling the notational gap between composition and performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {144--150},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/21_Carey_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Netscore: an Image Server/Client Package for Transmitting Notated Music to Browser and Virtual Reality Interfaces</div>
	<div class='proc-auth'>Benedict Carey and Georg Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-21'>Bibtex</span>
	<div id='abstract2016-21' class='collapse proc-abstract'>
NetScore is an extension of the existing MaxScore pack-age (Hajdu, Didkovsky) which adds new functionality for the rapid transmission and display of music notation on remote devices through standard modern browsers with WebSocket support. This was seen as a necessary development for MaxScore due to the ubiquity of tablets and other mobile devices, among other advantages for the user, and future applications of the software. We chose a server based solution executed in Java using the Jetty library for both portability between different platforms, and scalability. Novel applications facilitated by NetScore include transmitting scores generated in Max/MSP into virtual reality interfaces and more convenient performance/ rehearsal of real-time generated music, whereby devices commonly on hand such as smartphones, tablets and laptops are used as e-scores without requiring the installation of additional software.
	</div>
	<pre id='bibtex2016-21' class='collapse proc-bibtex'>
@inproceedings{Carey_tenor2016,
  Address = {Cambridge, UK},
  Author = { Benedict Carey and Georg Hajdu },
  Title = {Netscore: an Image Server/Client Package for Transmitting Notated Music to Browser and Virtual Reality Interfaces},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {151--156},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/22_Olowe_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>FEATUR.UX: exploiting multitrack information for artistic visualization</div>
	<div class='proc-auth'>Ireti Olowe, Mathieu Barthet, Mick Grierson and Nick Bryan-Kinns</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-22'>Bibtex</span>
	<div id='abstract2016-22' class='collapse proc-abstract'>
FEATUR.UX (Feature - ous) is an audio visualization tool, currently in the process of development, which proposes to introduce a new approach to sound visualization using pre-mixed, independent multitracks and audio feature extraction. Sound visualization is usually performed using a final mix, mono or stereo track of audio. Audio feature extraction is commonly used in the field of music information retrieval to create search and recommendation systems for large music databases rather than generating live visualizations. Visualizing multitrack audio circumvents problems related to the source separation of mixed audio signals and presents an opportunity to examine interdependent relationships within and between separate streams of music. This novel approach to sound visualization aims to provide an enhanced accession to the listening experience corresponding to this use case that employs non-tonal, non-notated forms of electronic music. Findings from prior research studies focused on live performance and preliminary quantitative results from a user survey have provided the basis from which to develop a prototype that will be used throughout an iterative design study to examine the impact of using multitrack audio and audio feature extraction on sound visualization practice.
	</div>
	<pre id='bibtex2016-22' class='collapse proc-bibtex'>
@inproceedings{Olowe_tenor2016,
  Address = {Cambridge, UK},
  Author = { Ireti Olowe and Mathieu Barthet and Mick Grierson and Nick Bryan-Kinns },
  Title = {FEATUR.UX: exploiting multitrack information for artistic visualization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {157--166},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/23_Janin_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A robust algebraic framework for high-level music programming</div>
	<div class='proc-auth'>David Janin</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-23'>Bibtex</span>
	<div id='abstract2016-23' class='collapse proc-abstract'>
In this paper, we present a new algebraic model for music programming : tiled musical graphs. It is based on the idea that the definition of musical objects~: what they are, and the synchronization of these objects~: when they should be played, are two orthogonal aspects of music programming that should be kept separate although handled in a combined way. This leads to the definition of an algebra of music objects~: tiled music graphs, which can be combined by a single operator : the tiled product, that is neither sequential nor parallel but both. From a mathematical point of view, this algebra is known to be especially robust since it is an inverse monoid. Various operators such as the reset and the coreset projections derive from these algebra and turned out to be fairly useful for music modeling. From a programming point of view, it provide a high level domain specific language (DSL) that is both hierarchical and modular. This language is currently under implementation in the functional programming language Haskell. From an applicative point of view, various music modeling examples are provided to show how notes, chords, melodies, musical meters and various kind of interpretation aspects can easily and robustly be encoded in this formalism.
	</div>
	<pre id='bibtex2016-23' class='collapse proc-bibtex'>
@inproceedings{Janin_tenor2016,
  Address = {Cambridge, UK},
  Author = { David Janin },
  Title = {A robust algebraic framework for high-level music programming},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {167--175},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/24_Hope_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Possibilities of a Line: Marking the Glissando in Music</div>
	<div class='proc-auth'>Cat Hope and Michael Terren</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-24'>Bibtex</span>
	<div id='abstract2016-24' class='collapse proc-abstract'>
Despite the prevalence of the term "line" in musicology to suggest a trajectory or contour of a melody, these do not embody the line in the Euclidean sense of the word, due to the striated, stepwise nature of pitches in the chromatic scale in traditional harmonic music. The glissando, however, embodies this literal and smooth line without fragmentation and has become a way to align music with other disciplines such as architecture, mathematics and physics. In a more figurative sense, the glissando has been used in a mimetic capacity to signify an irrational, metaphysical otherness. From modernist stochasticism to science fiction film scores, the glissando has a dynamic and complex relationship with representation.<br/>Glissandi explore ideas of sonic trace, surface-ness and stasis. The notation of glissandi, in traditional Western and graphical notation as well as spectrographic visualisation, is presented as a line, its horizontal axis being a measure of time, and its vertical axis being a measure of pitch. This “pitch-time space” enables the consideration of the line as a sonic trace—of motion, gesture or time itself. This also permits the conceptualisation of the line as a surface.<br/>Some glissandi also tend to operate in structural stasis, working against the glissando's function as a sonic trace, thus the glissando-as-stasis, especially as related to drone music, is explored. Deriving inspiration from works by composers, Iannis Xeankis, James Tenney and Giacinto Scelsi, compositional attempts to combine the nature of glissando with drone in the author’s own work are de-scribed, providing an examination of examples of the way glissandi and related concepts can be notated formal-ly, rather than decoratively, in musical works.
	</div>
	<pre id='bibtex2016-24' class='collapse proc-bibtex'>
@inproceedings{Hope_tenor2016,
  Address = {Cambridge, UK},
  Author = { Cat Hope and Michael Terren },
  Title = {The Possibilities of a Line: Marking the Glissando in Music},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {176--180},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/25_Hajdu_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Resurrecting a Dinosaur - The Adaptation of Clarence Barlow's Legacy Software Autobusk</div>
	<div class='proc-auth'>Georg Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-25'>Bibtex</span>
	<div id='abstract2016-25' class='collapse proc-abstract'>
This paper aims at describing efforts to conserve and further develop the legacy real-time generative music program AUTOBUSK by Clarence Barlow. We present a case study demonstrating that a simple port of 30+ year old code may not suffice to infuse new life into a project that suffered from the abandonment of the hardware it was developed on. In the process of resurrecting this dinosaur, AUTOBUSK was entirely redesigned for the popular music software environments Max and Ableton Live (via Max for Live) and renamed DJster. It comes in several incarnations, the most recent ones being DJster Autobus for Ableton Live, a device for real-time event generation and DJster Autobus Scorepion, a plugin for the MaxScore Editor. These incarnations take advantage of being embedded in current environments running on modern operating systems and have since acquired some new and useful features. As AUTOBUSK/DJster is based on universal musical principles, which Barlow formalized during the 1970’s while working on his generative piano piece Çoǧluotobüsişletmesi, its algorithms are of general applicability for composers and performers working in diverse fields such as microtonality, interactive installations and/or film music. It has therefore inspired me to lay the foundations of a shorthand notation, which we will discuss in the last section.
	</div>
	<pre id='bibtex2016-25' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2016,
  Address = {Cambridge, UK},
  Author = { Georg Hajdu },
  Title = {Resurrecting a Dinosaur - The Adaptation of Clarence Barlow's Legacy Software Autobusk},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {181--186},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/26_Angulo_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Hexaphonic Guitar Transcription and Visualization</div>
	<div class='proc-auth'>Iñigo Angulo, Sergio Giraldo and Rafael Ramirez</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-26'>Bibtex</span>
	<div id='abstract2016-26' class='collapse proc-abstract'>
Music representation has been a widely researched topic through centuries. Transcription of music through the conventional notation system has dominated the field, for the best part of the last centuries. However, this notational system often falls short of communicating the essence of music to the masses, especially to the people with no music training. Advances in signal processing and computer science over the last few decades have bridged this gap to an extent, but conveying the meaning of music remains a challenging research field. Music visualization is one such bridge, which we explore in this paper. This paper presents an approach to visually represent music produced by a guitar. To achieve this, hexaphonic guitar processing is carried out (i.e. processing each of the six strings as an independent monophonic sound source). Once this information is obtained, different approaches for representing it visually are explored. As a final result, a system is proposed to enrich the musical listening experience, by extending the perceived auditory sensations to include visual stimuli.
	</div>
	<pre id='bibtex2016-26' class='collapse proc-bibtex'>
@inproceedings{Angulo_tenor2016,
  Address = {Cambridge, UK},
  Author = { Iñigo Angulo and Sergio Giraldo and Rafael Ramirez },
  Title = {Hexaphonic Guitar Transcription and Visualization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {187--192},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/27_Eldridge_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Designing Dynamic Networked Scores to Enhance the Experience of Ensemble Music Making</div>
	<div class='proc-auth'>Alice Eldridge, Ed Hughes and Chris Kiefer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-27'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-27'>Bibtex</span>
	<div id='abstract2016-27' class='collapse proc-abstract'>
This paper describes the impetus for, and design and evaluation of, a pilot project examining the potential for digital, dynamic networked scores to enhance the experience of ensemble music making. We present a new networked score presentation system, and describe how it has evolved through a participatory design approach. Feedback has highlighted key issues concerning synchronisation between conductor, performers and notation, and autonomy and adaptation for performers; we discuss these key points and present our future plans for the project.
	</div>
	<pre id='bibtex2016-27' class='collapse proc-bibtex'>
@inproceedings{Eldridge_tenor2016,
  Address = {Cambridge, UK},
  Author = { Alice Eldridge and Ed Hughes and Chris Kiefer },
  Title = {Designing Dynamic Networked Scores to Enhance the Experience of Ensemble Music Making},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {193--199},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/28_Saito_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Conversion from Standard MIDI Files to Vertical Line Notation Scores and Automatic Decision of Piano Fingering for Beginners</div>
	<div class='proc-auth'>Yasuyuki Saito, Eita Nakamura, Riku Sato, Suguru Agata, Yuu Igarashi and Shigeki Sagayama</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-28'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-28'>Bibtex</span>
	<div id='abstract2016-28' class='collapse proc-abstract'>
This paper introduces "vertical line notation'' (VLN) of music for piano beginners, a conversion method from standard MIDI files to VLN scores, and an algorithm of automatic decision of piano fingering for it. Currently, staff notation is widely used for various instruments including piano. However, this notation often appears hard to beginners. On the other hand, VLN is intuitive and easy to understand for piano beginners since it graphically indicates the time order of notes as well as fingering. With the VLN score, piano beginners can make smooth progress with correct fingering. VLN scores are expected to help piano beginners make smooth progress with correct fingering. An issue with VLN is that it is currently created by hand with a spreadsheet software. It would be desirable to automatically produce VLN scores from existing digital scores. In this paper, we propose a method of converting standard MIDI files into VLN scores and an algorithm of automatic fingering decision for piano beginners. Some examples of practical and successful use of VLN scores are shown.
	</div>
	<pre id='bibtex2016-28' class='collapse proc-bibtex'>
@inproceedings{Saito_tenor2016,
  Address = {Cambridge, UK},
  Author = { Yasuyuki Saito and Eita Nakamura and Riku Sato and Suguru Agata and Yuu Igarashi and Shigeki Sagayama },
  Title = {Conversion from Standard MIDI Files to Vertical Line Notation Scores and Automatic Decision of Piano Fingering for Beginners},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {200--211},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/29_Ellberger_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Taxonomy and Notation of Spatialization</div>
	<div class='proc-auth'>Emile Ellberger, Germán Toro Pérez, Linda Cavaliero, Johannes Schuett, Basile Zimmermann and Giorgio Zoia</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-29'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-29'>Bibtex</span>
	<div id='abstract2016-29' class='collapse proc-abstract'>
The SSMN Spatial Taxonomy and its symbols libraries, which are the corner stone of the Spatialization Symbolic Music Notation (SSMN) project, emanates from research into composers’ attitudes in this domain. It was conceived as the basis for the development of dedicated notation and rendering tools within the SSMN project. The taxonomy is a systematic representation of all relevant features necessary to specify sound spatiality: shape and acoustic quality of the space, structure, position and movement of sound sources. It is based on single descriptors that can be combined in order to define complex spatial configurations. Descriptors can be transformed locally and globally and can be the object of structural and behavioral operations. The SSMN Spatial Taxonomy proposes a corresponding graphic symbolic representation of descriptors, operations and other functional elements facilitating the communication of creative ideas to performers and technical assistants. This paper focuses on the presentation of the taxonomy and the symbols. Additionally it describes the workflow  proposed for using symbols inside a notation software prototype developed within the project. Finally, further aspects concerning the actual and future developments of SSMN are mentioned.
	</div>
	<pre id='bibtex2016-29' class='collapse proc-bibtex'>
@inproceedings{Ellberger_tenor2016,
  Address = {Cambridge, UK},
  Author = { Emile Ellberger and Germán Toro Pérez and Linda Cavaliero and Johannes Schuett and Basile Zimmermann and Giorgio Zoia },
  Title = {Taxonomy and Notation of Spatialization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {212--219},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/30_Li_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Music Analysis Through Visualization</div>
	<div class='proc-auth'>Jia Li</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-30'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-30'>Bibtex</span>
	<div id='abstract2016-30' class='collapse proc-abstract'>
In this paper analytic visualizations are used to selectively highlight salient musical features in four modern compositions, focusing on micro or macro structures: from motivic pitch contour to large-scale form. At a glance these visualizations allow a quick grasp of the structure and assist listeners to make connections between local features and global trends. Textures obscured by musical notation become more apparent when displayed in a graphical format, such as broad registral shifts, polyphonic streaming, as well as interplay between instruments.  Pitch, timbre and voicing are plotted against time to show large-scale patterns that would otherwise be difficult to recognize in a musical score or compare between different works. Music analysis through compositional data visualization not only makes sense to musicians but also to non-musicians, facilitating collaboration and exchange with artists and technicians in other media.
	</div>
	<pre id='bibtex2016-30' class='collapse proc-bibtex'>
@inproceedings{Li_tenor2016,
  Address = {Cambridge, UK},
  Author = { Jia Li },
  Title = {Music Analysis Through Visualization},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {220--225},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/31_Maestri_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notation as Temporal Instrument</div>
	<div class='proc-auth'>Eric Maestri</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-31'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-31'>Bibtex</span>
	<div id='abstract2016-31' class='collapse proc-abstract'>
In this paper the author proposes a descriptive musicological framework built on the notion of notation as temporal instrument in today's context of electronic music. The principal goal is to discuss a research categorization of musical notation that consider the performative character of musical writing in electronic music performance. In the intentions of the author, this framework could resume the multiple enhancement of the temporal dimension of notation implied by the new means of performance in electronic music.
	</div>
	<pre id='bibtex2016-31' class='collapse proc-bibtex'>
@inproceedings{Maestri_tenor2016,
  Address = {Cambridge, UK},
  Author = { Eric Maestri },
  Title = {Notation as Temporal Instrument},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {226--229},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/32_Wood_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Visual Confusion in Piano Notation</div>
	<div class='proc-auth'>Marion Wood</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-32'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-32'>Bibtex</span>
	<div id='abstract2016-32' class='collapse proc-abstract'>
This series of Reaction Time experiments investigates how quickly notes can be read from a screen and immediately executed on a MIDI keyboard. This makes it possible to study pitch reading and motor coordination in considerable detail away from the customary confounds of rhythm reading or pulse entrainment. The first experiment found that reaction times were slower in extreme keys (3#, 4#, 3b, 4b), even for very experienced sightreaders, a large effect of clef in most individuals, and other results suggesting that, in this simple paradigm at least, reading notation presents more of a difficulty to execution than motor coordination. A second experiment found, in addition, an effect of order in which the notes were presented. A clarified form of notation was devised that disambiguates visual confusion across key signatures, and to some extent across clefs. Initial results from an experiment to contrast traditional noteheads with the clearer ones found substantial improvements in both Reaction Time and accuracy for the clarified notation. The possible applications of improved notation to the wider field of piano playing are discussed.
	</div>
	<pre id='bibtex2016-32' class='collapse proc-bibtex'>
@inproceedings{Wood_tenor2016,
  Address = {Cambridge, UK},
  Author = { Marion Wood },
  Title = {Visual Confusion in Piano Notation},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {230--239},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2016/33_Tahon_tenor2016.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>From Transcription to Signal Representation: Pitch, Rhythm and Performance</div>
	<div class='proc-auth'>Marie Tahon and Pierre-Eugène Sitchet</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2016-33'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2016-33'>Bibtex</span>
	<div id='abstract2016-33' class='collapse proc-abstract'>
Musical transcription is a real challenge, moreover in a folk music context. Signal visualization tools could be of interest for such music. The present paper is a comparison of a musical transcription and two signal representations (pitch and rhythm) applied to a song from the Gwoka repertoire. The study aims at finding similar elements and differences on pitch, rhythm and performance features in both the transcription and the signal visualization. Signal visualization is founded on vowel segmentation, and extraction of pitch and duration information. On the one hand transcription gives general characteristics on the music (harmony, tonality and rhythmic structure) and on the other hand, signal visualization gives performance-related characteristics. The main conclusion is that both approaches are of great interest for understanding such a music.
	</div>
	<pre id='bibtex2016-33' class='collapse proc-bibtex'>
@inproceedings{Tahon_tenor2016,
  Address = {Cambridge, UK},
  Author = { Marie Tahon and Pierre-Eugène Sitchet },
  Title = {From Transcription to Signal Representation: Pitch, Rhythm and Performance},
  Booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'16},
  Pages = {240--245},
  Year = {2016},
  Editor = {Richard Hoadley and Chris Nash and Dominique Fober},
  Publisher = {Anglia Ruskin University},
  ISBN = {978-0-9931461-1-4}
}
	</pre>
</div>
</div>
</section>

 <!-- ========================================================================= -->

    <section class="proc-altern" id="2015">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading tenor-year">2015</h2>
                    <hr class="primary">
                </div>
            </div>
        </div>

<div class='container'>
<div class='row tenor-paper'>
  <a href='proceedings/TENOR2015-Proceedings.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
  <div class='proc-title'>FULL TENOR'15 PROCEEDINGS</div>
  <span class='proc-button' data-toggle='collapse' data-target='#bibtex2015'>Bibtex</span>
  | <a href="proceedings/bibtex2015.bib" class="tenor-bibtex">.bib</a>

  <pre id='bibtex2015' class='collapse proc-bibtex'>
@book{tenor2015,
  Address = {Paris, France},
  Title = {Proceedings of the International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {Institut de Recherche en Musicologie, IReMus},
  ISBN = {978-2-9552905-0-7}
  </pre>
</div>
<hr>
</div>
<div class='container'>
<div class='row tenor-paper'>
	<a href='proceedings/2015/01-Martin-LeadsheetJS.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>LEADSHEETJS: A Javascript Library for Online Lead Sheet Edition</div>
	<div class='proc-auth'>Daniel Martín, Timotée Neullas and François Pachet</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-1'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-1'>Bibtex</span>
	<div id='abstract2015-1' class='collapse proc-abstract'>
Lead sheets are routinely used in many genres of popular music. Lead sheets are music scores consisting of a melody and a chord grid. With the increase of online and portable music applications, the need for easily embeddable, adaptable and extensible lead sheet editing tools is pressing. We introduce LeadsheetJS, a javascript library for visualizing, editing and rendering lead sheets on multiple devices. LeadsheetJS provides lead sheet edition as well as support for extensions such as score augmentation and peer feedback. LeadsheetJS is a client-based component that can be embedded from arbitrary third-party websites. We describe the main design aspects of LeadsheetJS and some applications in online computer-aided composition tools.
	</div>
	<pre id='bibtex2015-1' class='collapse proc-bibtex'>
@inproceedings{Martin_tenor2015,
  Address = {Paris, France},
  Author = { Daniel Martín and Timotée Neullas and François Pachet },
  Title = {LEADSHEETJS: A Javascript Library for Online Lead Sheet Edition},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {1--10},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/02-PerezLopez-Bigram.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Bigram Editor: a score editor for the Bigram Notation</div>
	<div class='proc-auth'>Andres Perez-Lopez, Pep Alcantara-Noalles and Bertrand Kientz</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-2'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-2'>Bibtex</span>
	<div id='abstract2015-2' class='collapse proc-abstract'>
The Bigram Notation is an alternative approach to musical notation, based on the chromatic nature of Western music. As observed historically with alternative notation systems, their spread and consolidation is based on the existence of complementary and supportive tools, as ideosyncratic instruments and specific written material. Accordingly, we present the binary keyboards and the Bigram Editor, a graphical bigram score editor with automatic transcription and reproduction capabilities
	</div>
	<pre id='bibtex2015-2' class='collapse proc-bibtex'>
@inproceedings{Perez-Lopez_tenor2015,
  Address = {Paris, France},
  Author = { Andres Perez-Lopez and Pep Alcantara-Noalles and Bertrand Kientz },
  Title = {Bigram Editor: a score editor for the Bigram Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {11--17},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/03-Rodriguez-ExpressiveQuantization.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Expressive Quantization of Complex Rhythmic Structures for Automatic Music Transcription</div>
	<div class='proc-auth'>Mauricio Rodriguez</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-3'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-3'>Bibtex</span>
	<div id='abstract2015-3' class='collapse proc-abstract'>
Two quantization models for ‘expressive’ rendering of complex rhythmic patterns are discussed. A multi-nesting quantizer captures expressivity by allowing fine-grained/high-quality resolution, thus covering the automatic transcription of a wide range of rhythmic configurations, yielding from simple to rather complex music notations. A look-up table quantizer is discussed as another model to attain expressivity and musical consistency; input is quantized by comparison of 'rhythmic similarity' from a user-defined data-set or look-up 'dictionary'. Both quantizers are presented as computing assisting tools to facilitate the transcription of rhythmic structures into the symbolic domain (i.e. music notation).
	</div>
	<pre id='bibtex2015-3' class='collapse proc-bibtex'>
@inproceedings{Rodriguez_tenor2015,
  Address = {Paris, France},
  Author = { Mauricio Rodriguez },
  Title = {Expressive Quantization of Complex Rhythmic Structures for Automatic Music Transcription},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {18--22},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/04-Mauch-Tony.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Computer-aided Melody Note Transcription Using the Tony Software: Accuracy and Efficiency</div>
	<div class='proc-auth'>Matthias Mauch, Chris Cannam, Rachel Bittner, George Fazekas, Justin Salamon, Jiajie Dai, Juan Bello and Simon Dixon</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-4'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-4'>Bibtex</span>
	<div id='abstract2015-4' class='collapse proc-abstract'>
We present Tony, a software tool for the interactive evaluation of melodies from monophonic audio recordings, and evaluate its usability and the accuracy of its note extraction method. The scientific study of acoustic performances of melodies, whether sung or played, requires the accurate transcription of notes and pitches. To achieve the desired transcription accuracy for a particular application, researchers manually correct results obtained by automatic methods. Tony is an interactive tool directly aimed at making this correction task efficient. It provides (a) state-of-the art algorithms for pitch and note estimation, (b) visual and auditory feedback for easy error-spotting, (c) an intelligent graphical user interface through which the user can rapidly correct estimation errors, d) extensive export functions enabling further processing in other applications. We show that Tony's built in automatic note transcription method compares favorably against existing tools. We report how long it takes to annotate recordings on a set of 96 recordings and study the effect of piece, the number of edits made and the annotator's increasing mastery of the software. Tony is Open Source software, with source code and compiled binaries for Windows and Mac OS X available from https://code.soundsoftware.ac.uk/projects/tony/.
	</div>
	<pre id='bibtex2015-4' class='collapse proc-bibtex'>
@inproceedings{Mauch_tenor2015,
  Address = {Paris, France},
  Author = { Matthias Mauch and Chris Cannam and Rachel Bittner and George Fazekas and Justin Salamon and Jiajie Dai and Juan Bello and Simon Dixon },
  Title = {Computer-aided Melody Note Transcription Using the Tony Software: Accuracy and Efficiency},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {23--30},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/05-Fischer-AnimatedNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Understanding Animated Notation</div>
	<div class='proc-auth'>Christian Fischer</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-5'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-5'>Bibtex</span>
	<div id='abstract2015-5' class='collapse proc-abstract'>
Alternative notation approaches become more and more popular. Animated notation is one of them. Mainly because it seems easy to apply. On the other hand, practice shows that classically trained musicians, composers and musicologists tend to reject this kind of notation. Furthermore some musical performances based on animated notation should face the question whether a regular notation would not have been more efficient. Overall there is still a lack of knowledge and some misconceptions when it comes to animated notation and its practical application. A brief look into the development of animated notation, examples of actual fields of application and especially an examination of the visual communication process and the design of animated scores will shed a little light into the darkness.
	</div>
	<pre id='bibtex2015-5' class='collapse proc-bibtex'>
@inproceedings{Fischer_tenor2015,
  Address = {Paris, France},
  Author = { Christian Fischer },
  Title = {Understanding Animated Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {31--38},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/06-RossSmith-AtomicAMN.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>An Atomic Approach to Animated Music Notation</div>
	<div class='proc-auth'>Ryan Ross Smith</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-6'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-6'>Bibtex</span>
	<div id='abstract2015-6' class='collapse proc-abstract'>
Since the turn of the century, and in particular the last 5 years, the discourse surrounding dynamic scoring techniques and practices has increased dramatically, while leading to an increasingly disparate terminological melee. With an awareness of what implications exist in the premature analysis and theorization of an emerging field of practice, the author argues that in order to further develop a taxonomy of dynamic scoring techniques and practices, it may be useful to take a reductionist approach toward defining the various low-level elements of dynamic scoring, in the case of this paper those elements that features prominently in Animated Music Notation [AMN]. By suggesting a set of low-level elements, and isolating the actualized indicators of contact and intersection as the primary functional components of AMN, the author will propose a working definition of AMN supported by examples drawn from the author’s work and others. This definition is not intended to satisfy the broad range of dynamic scoring techniques that implement AMN, but to highlight prevalent methodologies, and to point toward the extension of existing taxonomies, specifically regard-ing their respective global functionalities.
	</div>
	<pre id='bibtex2015-6' class='collapse proc-bibtex'>
@inproceedings{RSmith_tenor2015,
  Address = {Paris, France},
  Author = { Ryan Ross Smith },
  Title = {An Atomic Approach to Animated Music Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {39--47},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/07-Hoadley-Semaphore.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>SEMAPHORE: Cross-Domain Expressive Mapping with Live Notation</div>
	<div class='proc-auth'>Richard Hoadley</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-7'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-7'>Bibtex</span>
	<div id='abstract2015-7' class='collapse proc-abstract'>
This paper describes research, investigations, creative experiments and performances undertaken by the author in collaboration with practitioners in different creative and performance domains. The research focuses on the translation of expression between these domains and its implementation using technology. This paper focuses primarily on the role of notation in this process. The domains involved include music (audio and notation), movement (dance) and text (poetry). The data arising from performers’ movements are collected and investigated; consideration is given to the use of image and graphics enabling elementary algorithmically generated dance notation.
	</div>
	<pre id='bibtex2015-7' class='collapse proc-bibtex'>
@inproceedings{Hoadley_tenor2015,
  Address = {Paris, France},
  Author = { Richard Hoadley },
  Title = {SEMAPHORE: Cross-Domain Expressive Mapping with Live Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {48--57},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/08-Hope-Decibel.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The DECIBEL Scoreplayer - A Digital Tool for Reading Graphic Notation</div>
	<div class='proc-auth'>Cat Hope, Lindsay Vickery, Aaron Wyatt and Stuart James</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-8'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-8'>Bibtex</span>
	<div id='abstract2015-8' class='collapse proc-abstract'>
These implementations are taken to be a part of the creative process. This research is about creating and investigating stimulating experiences where connections between one domain and the other are perceivable and where this connection itself provides an aesthetic experience. They are not intended to be fixed and permanent (although may remain so for the duration of a composition). The research is about creating dynamic environments, not musical instruments or general purpose tools.
	</div>
	<pre id='bibtex2015-8' class='collapse proc-bibtex'>
@inproceedings{Hope_tenor2015,
  Address = {Paris, France},
  Author = { Cat Hope and Lindsay Vickery and Aaron Wyatt and Stuart James },
  Title = {The DECIBEL Scoreplayer - A Digital Tool for Reading Graphic Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {58--69},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/11-Abdullah-SpectromorphologicalNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Spectromorphological Notation: Exploring the Uses of Timbral Visualisations in Ethnomusicological Works</div>
	<div class='proc-auth'>Hassan Abdullah Mohd and Andrew Blackburn</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-9'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-9'>Bibtex</span>
	<div id='abstract2015-9' class='collapse proc-abstract'>
Ethnomusicologists often face problem in precisely de-scribing characteristic of a sound recorded in the field-work. Written explanation normally will use the meta-phoric words to represent the timbral characteristic of a sound produced by ethnic musical instruments. But to what extend the reader will understand and perceive the sound based on the writer explanation? This study will explore all the possibilities of using timbral visualization in recognizing the Malaysian traditional musical instru-ments. We introduce an instrument recognition process in solo recordings of a set of Malay traditional instruments (gedombak), which yields a high recognition rate. A large sound profile is used in order to encompass the different sound characteristic of each instrument and evaluate the generalization abilities of the recognition process.
	</div>
	<pre id='bibtex2015-9' class='collapse proc-bibtex'>
@inproceedings{Mohd_tenor2015,
  Address = {Paris, France},
  Author = { Hassan Abdullah Mohd and Andrew Blackburn },
  Title = {Spectromorphological Notation: Exploring the Uses of Timbral Visualisations in Ethnomusicological Works},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {70--73},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/12-Bean-DENM.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>denm (dynamic environmental notation for music): Introducing a Performance-Centric Musical Interface</div>
	<div class='proc-auth'>James Bean</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-10'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-10'>Bibtex</span>
	<div id='abstract2015-10' class='collapse proc-abstract'>
denm (dynamic environmental notation for music) is an automatic notation renderer written for tablet computers in the Swift language and the Cocoa Touch Frameworks. denm is a performance-centric notation environment with many tools built into an interactive graphical representation of music. These tools, for both individual- and group-rehearsal contexts, invite multi-dimensional learning strategies to performing the complex musics written today. There are many excellent tools currently available that automatically generate musical scores, but the focus of these tools is often towards the compositional and/or theoretical end of the musical process. denm focuses its efforts on the performance end of the process, allowing performers to interact directly with the musical notation. This paper describes the impetus for the denm project, the current state of its development, and areas of continued implementation and exploration.
	</div>
	<pre id='bibtex2015-10' class='collapse proc-bibtex'>
@inproceedings{Bean_tenor2015,
  Address = {Paris, France},
  Author = { James Bean },
  Title = {denm (dynamic environmental notation for music): Introducing a Performance-Centric Musical Interface},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {74--80},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/13-Celerier-OSSIA.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>OSSIA: towards a unified interface for scoring time and interaction</div>
	<div class='proc-auth'>Jean-Michaël Celerier, Pascal Baltazar, Clément Bossut, Nicolas Vuaille, Jean-Michel Couturier and Myriam Desainte-Catherine</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-11'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-11'>Bibtex</span>
	<div id='abstract2015-11' class='collapse proc-abstract'>
The theory of interactive scores addresses the writing and execution of temporal constraints between musical objects, with the ability to describe the use of interactivity in the scores. In this paper, a notation for the use of conditional branching in interactive scores will be introduced. It is based on a high level formalism for the authoring of interactive scores developed during the course of the OSSIA research project. This formalism is meant to be at the same time easily manipulated by composers, and translatable to multiple formal methods used in interactive scores like Petri nets and timed automaton. An application programming interface that allows the interactive scores to be embedded in other software and the authoring software, i-score, will be presented.
	</div>
	<pre id='bibtex2015-11' class='collapse proc-bibtex'>
@inproceedings{Celerier_tenor2015,
  Address = {Paris, France},
  Author = { Jean-Michaël Celerier and Pascal Baltazar and Clément Bossut and Nicolas Vuaille and Jean-Michel Couturier and Myriam Desainte-Catherine },
  Title = {OSSIA: towards a unified interface for scoring time and interaction},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {81--90},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/14-DiSanto-AcousmaticScores.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Sign to write Acousmatic Scores</div>
	<div class='proc-auth'>Jean-Louis Di Santo</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-12'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-12'>Bibtex</span>
	<div id='abstract2015-12' class='collapse proc-abstract'>
This paper aims at describing an approach meant to build a sign adapted to acousmatic music and based on reduced listening. The sign, to be efficient, must obey to a certain number of requisits: precision, ergonomy, relevance... It must be both easy to use and able to create relations between sounds. A simple description of their qualities is not enough: it must be able to create or analyse sound compositions and structures, such as instrumental scores. To fulfill this purpose, it must be able to give each sound a value, in a saussurian meaning of the word. I will try to show the genealogy of my sign, how I took elements of reflexion from musical knowledge, linguistics, semiotics and aesthetics. From there I deduced the concept of minimal unit of sound applied to electroacoustic music and I created a sign combining symbols to decribe its features. I'll show how I have reorganised sound paramaters described by Schaeffer and how this sign works. At last, I will show the possibilities of writing scores sound by sound and I'll show two kinds of analysis: the analysis of a pure acousmatic work from a formal point of view and the analysis of a work for tape and instruments both from a formal and a symbolic point of view.
	</div>
	<pre id='bibtex2015-12' class='collapse proc-bibtex'>
@inproceedings{DiSanto_tenor2015,
  Address = {Paris, France},
  Author = { Jean-Louis Di Santo },
  Title = {A Sign to write Acousmatic Scores},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {91--97},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/15-Ellberger-SpacializationNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>A Paradigm for Scoring Spatialization Notation</div>
	<div class='proc-auth'>Emile Ellberger, Germán Toro-Perez, Johannes Schuett, Linda Cavaliero and Giorgio Zoia</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-13'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-13'>Bibtex</span>
	<div id='abstract2015-13' class='collapse proc-abstract'>
SSMN intends to develop a conceptual framework and a tool set that allows composers to integrate spatialization in musical notation from the onset of the creation process. As the composition takes form and graphic symbols ex-pressing spatialization is introduced into the score, instant audio rendering provides feedback within a surround sound configuration. In parallel, SSMN helps interpreters and audio engineers to learn and master scores that con-tain complex instructions of motion in space easily re-cognizable both in printed and animated electronic for-mat. At first a SSMN Spatial Taxonomy was established to identify key motion in space possibilities within musi-cal context; consequently, a collection of SSMN Symbols has been designed and implemented in a software library of graphical objects within MuseScoreSSMN, a dedicated editor that has been developed to allow interactive use of this library along with CWMN. In order to bridge the gap between visual elements and audio perception, an SSMN-Rendering-Engine application is at the heart of OSC inter-application communication strategies allowing the use of DAW and user-defined programming envi-ronments along with MuseScoreSSMN. A prototype has been prepared and tested by a user group consisting of composers and performers. Further research shall address other user cases integrating electroacoustic paradigms.
	</div>
	<pre id='bibtex2015-13' class='collapse proc-bibtex'>
@inproceedings{Ellberger_tenor2015,
  Address = {Paris, France},
  Author = { Emile Ellberger and Germán Toro-Perez and Johannes Schuett and Linda Cavaliero and Giorgio Zoia },
  Title = {A Paradigm for Scoring Spatialization Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {98--102},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/16-Fox-Accretion.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Accretion: Flexible, Networked Animated Music Notation For Orchestra With the Raspberry Pi</div>
	<div class='proc-auth'>Kelly Fox</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-14'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-14'>Bibtex</span>
	<div id='abstract2015-14' class='collapse proc-abstract'>
In 2014, the author set out to expand the notational potential of their generative music systems to be performed by the Rensselaer Orchestra in Troy, NY. The experiments resulted in the use of several networked Raspberry Pi devices delivering a realtime, generative Animated Music Notation to subsections of the live orchestra during performance. This paper outlines the structure of the piece, Accretion; the technical details of its implementation; and the possibilities presented by using the Raspberry Pi to deliver scored materials to performers. Ultimately, the paper seeks to make a case for adopting the Raspberry Pi as a powerful device and method of distribution/performance of Animated Music Notation.
	</div>
	<pre id='bibtex2015-14' class='collapse proc-bibtex'>
@inproceedings{Fox_tenor2015,
  Address = {Paris, France},
  Author = { Kelly Fox },
  Title = {Accretion: Flexible, Networked Animated Music Notation For Orchestra With the Raspberry Pi},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {103--108},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/17-Fujinaga-Simssa8.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Single Interface for Music Score Searching and Analysis (SIMSSA)</div>
	<div class='proc-auth'>Ichiro Fujinaga and Andrew Hankinson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-15'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-15'>Bibtex</span>
	<div id='abstract2015-15' class='collapse proc-abstract'>
Single Interface for Music Score Searching and Analysis (SIMSSA) project targets digitized music scores to de-sign a global infrastructure for searching and analyzing music scores. Specifically, we seek to provide research-ers, musicians, and others to access the contents and metadata of a large number of scores in a searchable, digital format. In this project, we are developing proto-types for processing and accessing the scores by consult-ing closely music researchers, musicians, and librarians.
	</div>
	<pre id='bibtex2015-15' class='collapse proc-bibtex'>
@inproceedings{Fujinaga_tenor2015,
  Address = {Paris, France},
  Author = { Ichiro Fujinaga and Andrew Hankinson },
  Title = {Single Interface for Music Score Searching and Analysis (SIMSSA)},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {109--115},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/18-Guyot-BrowsingSoundscapes.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Browsing soundscapes</div>
	<div class='proc-auth'>Patrice Guyot and Julien Pinquier</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-16'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-16'>Bibtex</span>
	<div id='abstract2015-16' class='collapse proc-abstract'>
Browsing soundscapes is generally based on the waveform of the audio signal or textual metadata, which may be not informative. The TM-charts provide an efficient tool to represent and compare soundscapes. However, they remain little used probably due to the human annotation they need. In this paper, we describe a new approach to compute charts of soundscapes, that we call Samocharts. The Samocharts are inspired by TM-charts and can be computed without a human annotation. We present two methods for Samochart computation. The first one is based on a segmentation of the signal from a set of predefined sound events. The second one is based on the confidence score of the detection algorithms. We describe two application cases on corpora of field recording from the CIESS and the UrbanSound projects. Finally, Samocharts provide a compact and efficient representation of soundscapes, which can be used in different kind of applications.
	</div>
	<pre id='bibtex2015-16' class='collapse proc-bibtex'>
@inproceedings{Guyot_tenor2015,
  Address = {Paris, France},
  Author = { Patrice Guyot and Julien Pinquier },
  Title = {Browsing soundscapes},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {116-123},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/20-Sapp-GraphicToSymbolic.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Graphic to Symbolic Representations of Musical Notation</div>
	<div class='proc-auth'>Craig Sapp</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-17'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-17'>Bibtex</span>
	<div id='abstract2015-17' class='collapse proc-abstract'>
This paper discusses a graphically oriented representation for music and how such representation systems can be converted into more symbolic/semantic representations of music. Specifically the representation system of the SCORE notation editor is presented along with case studies converting into other symbolic formats such as MIDI, Humdrum, Dox, MuseData, MusicXML and MEI using scorelib, an open-source library. Knowledge of the SCORE data format is useful for projects working on OMR (Optical Music Recognition) as it can be used as an intermediate layer between the raw scans and other digital music notation representation systems, as well as going in the other direction again from generalized music representations to specific graphical layouts.
	</div>
	<pre id='bibtex2015-17' class='collapse proc-bibtex'>
@inproceedings{Sapp_tenor2015,
  Address = {Paris, France},
  Author = { Craig Sapp },
  Title = {Graphic to Symbolic Representations of Musical Notation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {124--132},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/21-Magnusson-CodeScores.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Code scores in Live Coding</div>
	<div class='proc-auth'>Thor Magnusson</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-18'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-18'>Bibtex</span>
	<div id='abstract2015-18' class='collapse proc-abstract'>
This paper explores the idea of live coding programming environments as notational systems. The improvisational practice of live coding as combining both composition and performance is introduced and selected systems are discussed. The author's Threnoscope system is then intro- duced, but this is a system that contains both descriptive and prescriptive scores that can be changed in real-time.
	</div>
	<pre id='bibtex2015-18' class='collapse proc-bibtex'>
@inproceedings{Magnusson_tenor2015,
  Address = {Paris, France},
  Author = { Thor Magnusson },
  Title = {Code scores in Live Coding},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {133--138},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/23-McCulloch-Thema.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>THEMA: A Music Notation Software Package with Integrated and Automatic Data Collection</div>
	<div class='proc-auth'>Peter McCulloch</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-19'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-19'>Bibtex</span>
	<div id='abstract2015-19' class='collapse proc-abstract'>
This paper introduces Thema, a custom music notation software environment designed to automatically and transparently capture quantitative data into a relational database. The majority of research into musical creativity is qualitative in nature, and this software addresses several areas, such as search and improvisational data, which are not well-addressed in the qualitative toolkit. Thema's database provides advantages over ad hoc file collection mechanisms by providing integrated search; the software also is able to consistently identify musical material via automatically assigned identification codes, and this provides a useful supplement to content-based search. In 2013, a study was conducted of ten graduate-level composers using Thema, and the dataset from this study was used to develop new analytical tools for examining compositional data.
	</div>
	<pre id='bibtex2015-19' class='collapse proc-bibtex'>
@inproceedings{McCulloch_tenor2015,
  Address = {Paris, France},
  Author = { Peter McCulloch },
  Title = {THEMA: A Music Notation Software Package with Integrated and Automatic Data Collection},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {139--145},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/24-Spreadbury-SMuFL.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Standard Music Font Layout (SMuFL)</div>
	<div class='proc-auth'>Daniel Spreadbury and Robert Piéchaud</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-20'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-20'>Bibtex</span>
	<div id='abstract2015-20' class='collapse proc-abstract'>
Digital typefaces containing the symbols used in Western common music notation have been in use for 30 years, but the development of the repertoire of symbols that are included, their assignment to code points, and design considerations such as glyph metrics and registration, have been rather ad hoc. The Standard Music Font Layout (SMuFL) establishes guidelines for all of these areas, and a reference implementation is available in the Bravura font family. Software developers and font designers alike are beginning to develop implementations of SMuFL in their products, and benefits including easier data interchange, interoperability of fonts with a variety of software packages, are already being felt.
	</div>
	<pre id='bibtex2015-20' class='collapse proc-bibtex'>
@inproceedings{Spreadbury_tenor2015,
  Address = {Paris, France},
  Author = { Daniel Spreadbury and Robert Piéchaud },
  Title = {Standard Music Font Layout (SMuFL)},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {146--153},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/25-Gottfried-SVG-OSC-Notation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>SVG to OSC Transcoding as a Platform for Notational Praxis and Electronic Performance</div>
	<div class='proc-auth'>Rama Gottfried</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-21'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-21'>Bibtex</span>
	<div id='abstract2015-21' class='collapse proc-abstract'>
In this paper presents a case study in the creation of an open notational framework for experimentation with new types of notation that may be applied in a wide variety of contexts. By separating the visual representation from the act of rendering, a space for an interpretive grammar layer is created in which symbolic notation may be translated into a format that is understood by another form of rendering. Technical details of preliminary work on this topic is presented, using Scalable Vector Graphics (SVG) as a container for hierarchical score information which is then transcoded to OpenSoundControl (OSC) as an intermediate data processing before being passed to a given rendering context.
	</div>
	<pre id='bibtex2015-21' class='collapse proc-bibtex'>
@inproceedings{Gottfried_tenor2015,
  Address = {Paris, France},
  Author = { Rama Gottfried },
  Title = {SVG to OSC Transcoding as a Platform for Notational Praxis and Electronic Performance},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {154--161},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/26-Baca-ABJAD.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Abjad: An Open-source Software System for Formalized Score Control</div>
	<div class='proc-auth'>Trevor Bača, Josiah Oberholtzer, Jeffrey Treviño and Víctor Adán</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-22'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-22'>Bibtex</span>
	<div id='abstract2015-22' class='collapse proc-abstract'>
The Abjad API for Formalized Score Control extends the Python programming language with an open-source, object-oriented model of common-practice music notation that enables composers to build scores through the aggregation of elemental notation objects. A summary of widely used notation systems’ intended uses motivates a discussion of system design priorities via examples of system use.
	</div>
	<pre id='bibtex2015-22' class='collapse proc-bibtex'>
@inproceedings{Baca_tenor2015,
  Address = {Paris, France},
  Author = { Trevor Bača and Josiah Oberholtzer and Jeffrey Treviño and Víctor Adán },
  Title = {Abjad: An Open-source Software System for Formalized Score Control},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {162--169},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/27-Laurenzi-DynamicLevels.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Notation of Dynamic Levels in the Performance of Electronic Music</div>
	<div class='proc-auth'>Carlo Laurenzi and Marco Stroppa</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-23'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-23'>Bibtex</span>
	<div id='abstract2015-23' class='collapse proc-abstract'>
The “sound diffusion” (or “sound projection”), that is, “the projection and the spreading of sound in an acoustic space for a group of listeners”[1], of works for solo electronics or for acoustic instruments and electronics (so called, “mixed pieces”), has always raised the issue of notating the levels to be reproduced during a concert or the correct balance between the electronics and the instruments. If, in the last decades, some attempts were made by few composers or computer-music designers, mostly in the form of scores, none of these managed to establish a common practice. In addition, little theoretical work has been done so far to address the performative aspects of a piece, that is, to provide just the useful information to the person in charge of the sound diffusion. Through the discussion of three historical examples and the analysis of two experiences we developed, we will try to identify some possibly general solutions that could be adopted independently on the aesthetic or tech-nological choices of a given piece.
	</div>
	<pre id='bibtex2015-23' class='collapse proc-bibtex'>
@inproceedings{Laurenzi_tenor2015,
  Address = {Paris, France},
  Author = { Carlo Laurenzi and Marco Stroppa },
  Title = {The Notation of Dynamic Levels in the Performance of Electronic Music},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {170--179},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/28-Hirst-PerceptualModels.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Automated Representations of Temporal Aspects of Electroacoustic Music: Recent Experiments Using Perceptual Models</div>
	<div class='proc-auth'>David Hirst</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-24'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-24'>Bibtex</span>
	<div id='abstract2015-24' class='collapse proc-abstract'>
Within this paper we firstly examine the determination of a number of temporal aspects of Electroacoustic Music, and their representations. Then various automated segmentation methods, for Harrison’s Unsound Objects, are investigated. We find the multi-granular approach outlined by Lartillot et al, combined with the use of MFCCs, is a very efficient and salient segmentation strategy for music structured predominantly according to timbre. Further, the ‘Contrast’ parameter is both versatile and effective in determining the granularity of segmentation.
	</div>
	<pre id='bibtex2015-24' class='collapse proc-bibtex'>
@inproceedings{Hirst_tenor2015,
  Address = {Paris, France},
  Author = { David Hirst },
  Title = {Automated Representations of Temporal Aspects of Electroacoustic Music: Recent Experiments Using Perceptual Models},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {180--189},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/29-Nash-CognitiveDimension.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>The Cognitive Dimensions of Music Notations</div>
	<div class='proc-auth'>Chris Nash</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-25'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-25'>Bibtex</span>
	<div id='abstract2015-25' class='collapse proc-abstract'>
This paper presents and adapts the Cognitive Dimensions of Notations framework (Green and Petre, 1996) for use in designing and analysing notations (and user interfaces) in both digital and traditional music practice and study. Originally developed to research the psychology of programming languages, the framework has since found wider use in both general HCI and music. The paper provides an overview of the framework, its application, and a detailed account of the core cognitive dimensions, each discussed in the context of three music scenarios: the score, Max/MSP, and sequencer/DAW software. Qualitative and quantitative methodologies for applying the framework are presented in closing, highlighting directions for further development of the framework.
	</div>
	<pre id='bibtex2015-25' class='collapse proc-bibtex'>
@inproceedings{Nash_tenor2015,
  Address = {Paris, France},
  Author = { Chris Nash },
  Title = {The Cognitive Dimensions of Music Notations},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {190--202},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/30-Bacon-TufteDesign.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Tufte Design Concepts in Musical Score Creation</div>
	<div class='proc-auth'>Benjamin Bacon and Marcelo Wanderley</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-26'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-26'>Bibtex</span>
	<div id='abstract2015-26' class='collapse proc-abstract'>
This paper introduces several examples of utilizing the information design concepts of Edward Tufte in musical no- tation and score design. Tufte is generally considered a modern pioneer in the field of information design. With several authoritative texts, Tufte’s work displays countless examples of successful and unsuccessful attempts of displaying information while also offering a few personal redesigns of especially troubled instances. Overall, Tufte reveals interesting concepts which could be useful when applied to designing musical notation systems. The author presents three personal notational examples which have been aided by Tufte’s work. Information design is a vast multidisciplinary field which could provide composers and musicians with an abundance of technical approaches to complex notational challenges.
	</div>
	<pre id='bibtex2015-26' class='collapse proc-bibtex'>
@inproceedings{Bacon_tenor2015,
  Address = {Paris, France},
  Author = { Benjamin Bacon and Marcelo Wanderley },
  Title = {Tufte Design Concepts in Musical Score Creation},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {203--209},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/31-Maestri-NotationAsInstrument.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Notation as Instrument: From Representation to Enaction</div>
	<div class='proc-auth'>Eric Maestri and Pavlos Antoniadis</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-27'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-27'>Bibtex</span>
	<div id='abstract2015-27' class='collapse proc-abstract'>
The paper explores the hybridization of notation and instrument as a cognitive movement from representation to enaction. Features of such hybridization are latent in every notation, as a mix of descriptive and prescriptive functions. Current advances in the fields of computer music representation (interactive scores) and New Interfaces for Musical Expression, with precedents in graphic and action-oriented scores, are turning notation into a shared multimodal platform between composer and performer, liquidizing the limit between notation and instrument. We will present this dynamic rapport between scores and interfaces (haptic interactions, INScore, GesTCom, post-Klaus K. Hübler tablature notations of decoupled action-structures) in the light of theoretical models (enaction defined as navigation of affordances from the field of embodied and extended cognition, Leman’s action-reaction cycle extended from instrument-making into notation, Veitl’s conception of software as tablature, Atau Tanaka’s definition of instruments as open-ended systems etc.). We are following an explicit line from new interfaces involving notation back to graphic and action-oriented scores, considering them in the theoretical framework of enaction.
	</div>
	<pre id='bibtex2015-27' class='collapse proc-bibtex'>
@inproceedings{Maestri_tenor2015,
  Address = {Paris, France},
  Author = { Eric Maestri and Pavlos Antoniadis },
  Title = {Notation as Instrument: From Representation to Enaction},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {210--217},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/32-Blackburn-TimbralNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Timbral Notation from Spectrograms: Notating the Un-Notatable?</div>
	<div class='proc-auth'>Andrew Blackburn and Jean Penny</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-28'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-28'>Bibtex</span>
	<div id='abstract2015-28' class='collapse proc-abstract'>
This paper outlines the background to a research project currently underway in Malaysia that, through spectography seeks to find models that might assist in the future development of a timbral notation. Located within the music creation and performance practices of the researchers, the project has elements of interculturality which both enrich and inform the research. The authors consider the nature of a music score, the explicit and implicit information it carries, and how this impacts on the models being developed. The understandings elicited to date are not only located in music practice, but are underpinned and supported by the theoretical works of a number of recent philosophers and theorists. The overall research project is broken down into smaller discrete sub-projects which are discussed, and the findings of each sub-project are then contextualized in the wider project. These findings include a discussion of the score as artifact and the potential contained within it. The finding in two sub-projects of a possible model of gestural notation, albeit with different purposes, suggests this as a further avenue of research. The paper concludes with some suggestions of future research areas that will follow on from the models of timbral notation being explored in this project.
	</div>
	<pre id='bibtex2015-28' class='collapse proc-bibtex'>
@inproceedings{Blackburn_tenor2015,
  Address = {Paris, France},
  Author = { Andrew Blackburn and Jean Penny },
  Title = {Timbral Notation from Spectrograms: Notating the Un-Notatable?},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {218--225},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/33-Rebelo-CompositionWithGraphics.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Composing with Graphics: Revealing the Compositional Process through Performance</div>
	<div class='proc-auth'>Pedro Rebelo</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-29'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-29'>Bibtex</span>
	<div id='abstract2015-29' class='collapse proc-abstract'>
The research presented here is product of a practice-based process that primarily generates knowledge through col-laboration and exchange in performance situations. It is this collaboration and exchange with various musicians over a period of five years that constitutes a body of practice that is here reflected upon. The paper focuses on non-instructional graphic scores and presents some insights based on performances of works by the author. We address how composition processes are revealed in graphic scores by looking at the conditions of decision making at the point of preparing a performance. We argue that three key elements are at play in the interpretation of these types of graphic scores: performance practice, mapping and musical form. By reflecting particularly on the work Cipher Series (Rebelo, 2010) we offer insights into the strategies for approaching the performance of graphic scores that go beyond symbolic codification.
	</div>
	<pre id='bibtex2015-29' class='collapse proc-bibtex'>
@inproceedings{Rebelo_tenor2015,
  Address = {Paris, France},
  Author = { Pedro Rebelo },
  Title = {Composing with Graphics: Revealing the Compositional Process through Performance},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {226--230},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/34-BaptisteJessel-NotationForBlindPeople.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Access to musical information for blind people</div>
	<div class='proc-auth'>Nadine Baptiste</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-30'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-30'>Bibtex</span>
	<div id='abstract2015-30' class='collapse proc-abstract'>
In this paper we describe our approach to help blind people to access musical information. Guidelines of our approach are centered on information accessibility according to user disability. We present the process which permits to code and transform musical information to be read, treat and analyze by a Blind musician. We focus our proposition on the various level of description of the score done by several code and we exploit and describe existing results like BMML (Braille Music Markup Lan-guage) defined during Contrapunctus European project. We describe and comment different scenarios using existing free transformation modules and software to obtain a score in BMML in order to be read and manipulate by a Blind people with BMR (Braille Music Reader) and the recommendation and tutorials propositions done during the Musi4vip European project.
	</div>
	<pre id='bibtex2015-30' class='collapse proc-bibtex'>
@inproceedings{Baptiste_tenor2015,
  Address = {Paris, France},
  Author = { Nadine Baptiste },
  Title = {Access to musical information for blind people},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {231--235},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/35-Burloiu-Ascograph.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Non-overlapping, Time-coherent Visualisation of Action Commands in the AscoGraph Interactive Music User Interface</div>
	<div class='proc-auth'>Grigore Burloiu and Arshia Cont</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-31'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-31'>Bibtex</span>
	<div id='abstract2015-31' class='collapse proc-abstract'>
Integrated authoring and performing of Mixed Music scores, where musicians interact dynamically with computer-controlled electronics, is enabled by the Antescofo state-of-the-art software package. Composers are able to plan computerised actions through a dedicated programming language, and performances are then synchronised in real time. AscoGraph is the dedicated graphical interface that allows users to configure Antescofo behaviours and visualise their layout over a Mixed Music score. This paper presents developments in the direction of increased clarity and coherence of AscoGraph’s visualisation of computerised action scores. Algorithms for efficient automatic stacking of time-overlapping action blocks are presented, as well as a simplified model for displaying atomic actions. The paper presents the improvements in score readability achieved, as well as the challenges faced towards a complete representation of dynamic mixed scores in the AscoGraph visual environment.
	</div>
	<pre id='bibtex2015-31' class='collapse proc-bibtex'>
@inproceedings{Burloiu_tenor2015,
  Address = {Paris, France},
  Author = { Grigore Burloiu and Arshia Cont },
  Title = {Non-overlapping, Time-coherent Visualisation of Action Commands in the AscoGraph Interactive Music User Interface},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {236--240},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
<div class='row tenor-paper'>
	<a href='proceedings/2015/36-Hajdu-DynamicNotation.pdf'><img src='img/pdficon.gif' alt='Download' class='proc-pdf img-responsive' width=28></a>
	<div class='proc-title'>Dynamic Notation – A Solution to the Conundrum of Non-Standard Music Practice</div>
	<div class='proc-auth'>Georg Hajdu</div>
	<span class='proc-button' data-toggle='collapse' data-target='#abstract2015-32'>Abstract</span> &nbsp; &nbsp;
	<span class='proc-button' data-toggle='collapse' data-target='#bibtex2015-32'>Bibtex</span>
	<div id='abstract2015-32' class='collapse proc-abstract'>
This paper discusses dynamic notation—a method allowing, in a notation environment, instant switching between different views or notation styles, thus creating a common ground for practitioners of non-standard music, such as composers, performers, conductors and scholars. A plugin structure for different notation styles based on a set of maps and queries executed during note entry and rendering, affecting music glyph choice and placement was implemented in the MaxScore Editor—a notation editor designed to run in Max or Ableton Live. We will give an in-depth analysis of the methods used for equidistant scales, non-octave tunings, music in just intonation as well as for instrument-specific layouts and will con-clude with a description of a scenario in which dynamic notation was used for the transcription and performance of Alexander Scriabin’s piano poem Vers la Flamme op. 72 by an ensemble of acoustic Bohlen-Pierce instruments.
	</div>
	<pre id='bibtex2015-32' class='collapse proc-bibtex'>
@inproceedings{Hajdu_tenor2015,
  Address = {Paris, France},
  Author = { Georg Hajdu },
  Title = {Dynamic Notation – A Solution to the Conundrum of Non-Standard Music Practice},
  Booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation -- TENOR'15},
  Pages = {241--248},
  Year = {2015},
  Editor = {Marc Battier and Jean Bresson and Pierre Couprie and Cécile Davy-Rigaux and Dominique Fober and Yann Geslin and Hugues Genevois and François Picard and Alice Tacaille},
  Publisher = {},
  ISBN = {978-2-9552905-0-7}
}
	</pre>
</div>
</div>
</section>


 <!-- ========================================================================= -->

    <aside class="bg-dark">
        <div class="container text-center">
            <div class="call-to-action">
                <a class ="page-scroll" href="#page-top"><img src="img/TENORgb.png"  width=150></a>
            </div>
        </div>
    </aside>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="vendor/scrollreveal/scrollreveal.min.js"></script>
    <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/creative.min.js"></script>

</body>

</html>
